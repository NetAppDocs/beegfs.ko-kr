<?xml version="1.0" encoding="UTF-8"?>
<blocks>
  <block id="014e0772632604acc6760e28c820cb22" category="summary">문제 해결 개요</block>
  <block id="818c6e601a24f72750da0f6c9b8ebe28" category="paragraph">Lorem ipsum dolor sit amet, detur adipiscing elit, SED do eiusmod tempor incidiudunt ut labore et dolore magna dia.</block>
  <block id="e95081b0e85f690a9bdcb41ea940c186" category="summary">NetApp 기반의 BeeGFS 솔루션을 구축하려면 해당 환경이 기술 요구사항을 충족하는지 확인하십시오.</block>
  <block id="de65efa2c0698ededf4229cafcca2d08" category="doc">기술 요구사항</block>
  <block id="47dee50ad0138b8f5ca70e40e86e6c04" category="section-title">하드웨어 요구 사항</block>
  <block id="d53750273c9ab2292caf240393c86d48" category="paragraph">다음 표에는 NetApp 기반 BeeGFS 솔루션의 단일 2세대 구성 요소 설계를 구현하는 데 필요한 하드웨어 구성요소가 나와 있습니다.</block>
  <block id="27d858ba39131558c9ade0aa37a22659" category="admonition">이 솔루션을 구체적으로 구축하는 데 사용되는 하드웨어 구성요소는 고객 요구사항에 따라 다를 수 있습니다.</block>
  <block id="e93f994f01c537c4e2f7d8528c3eb5e9" category="cell">카운트</block>
  <block id="16cc6ce48a597aebb8ab5132cb3523dc" category="cell">하드웨어 구성 요소</block>
  <block id="5a2ebfb8baa378cfcfcba58bbb1380c2" category="cell">요구 사항</block>
  <block id="d41d8cd98f00b204e9800998ecf8427e" category="doc"></block>
  <block id="c81e728d9d4c2f636f067f89cc14862c" category="paragraph">2</block>
  <block id="6c6f9283374bfbf220de6327277c1815" category="paragraph">BeeGFS 파일 노드.</block>
  <block id="2864e4eb2e0cb17f0531cd785e63c7da" category="paragraph">각 파일 노드는 예상 성능을 달성하기 위해 다음 구성을 충족하거나 초과해야 합니다.</block>
  <block id="31d64135897b5391e512521bf41f9777" category="paragraph">프로세서: *</block>
  <block id="b95b123279b2f800990f9c2191373708" category="list-text">2x AMD EPYC 7343 16C 3.2GHz.</block>
  <block id="4616efc57076900a6225244dcfc89027" category="list-text">2개의 NUMA 존으로 구성됩니다.</block>
  <block id="13519812c056b113bbb6f853259e7691" category="paragraph">* 메모리: *</block>
  <block id="2c271e30e1c41fa7fc170637cbe07507" category="list-text">256GB</block>
  <block id="4b0f34cee48d8b67ee838abeca68c9a6" category="list-text">16x 16GB TruDDR4 3200MHz(2Rx8 1.2V) RDIMM-A(더 적은 수의 큰 DIMM에 비해 더 작은 DIMM 선호).</block>
  <block id="3449cc07bd9fb49ca5e13dd993a70e88" category="list-text">메모리 대역폭을 최대화하도록 채워집니다.</block>
  <block id="9f5ef4bd76579737bfe585f29a5951e8" category="paragraph">* PCIe 확장: PCE Gen4 x16 슬롯 4개: *</block>
  <block id="f00f227030eb163a017a1730e0ddefb6" category="list-text">NUMA 존당 2개의 슬롯</block>
  <block id="d12719622b3ae7d145ba3994f18ac93f" category="list-text">각 슬롯은 Mellanox MCX653106A-HDAT 어댑터에 충분한 전력/냉각을 제공해야 합니다.</block>
  <block id="a631c0a4a9b408ccc2559c2a3323af51" category="paragraph">* 기타: *</block>
  <block id="61591a2035ff0c79f159e510d399af20" category="list-text">OS용 RAID 1에 구성된 2개의 1TB 7.2K SATA 드라이브(또는 이에 상응하는 드라이브)</block>
  <block id="47c626e648f05fcfc94552cad7e0f210" category="list-text">대역 내 OS 관리용 10GbE OCP 3.0 어댑터(또는 동급)</block>
  <block id="30a4226a3d02d27336f749ae5dcd893b" category="list-text">Out-of-Band Server Management용 Redfish API가 포함된 1GbE BMC</block>
  <block id="173ee7b6334b65c38509a87b47bd79da" category="list-text">이중 핫 스왑 전원 공급 장치 및 성능 팬</block>
  <block id="84edc2766d3f7158f313edb5aed216f7" category="list-text">스토리지 InfiniBand 스위치에 연결하는 데 필요한 경우 Mellanox 광 InfiniBand 케이블을 지원해야 합니다.</block>
  <block id="2d6de8e1dccd3e2e9834a5a60d4566de" category="paragraph">* Lenovo SR665: *</block>
  <block id="d89c6895636b2b8a24392a0f977e2684" category="list-text">사용자 지정 NetApp 모델에는 이중 포트 Mellanox ConnectX-6 어댑터를 지원하는 데 필요한 XClarity 컨트롤러 펌웨어의 필수 버전이 포함되어 있습니다. 주문 정보는 NetApp에 문의하십시오.</block>
  <block id="c9f0f895fb98ab9159f51fd0297e236d" category="cell">8</block>
  <block id="df57d52bbf8cf40e07c14985e453c567" category="cell">Mellanox ConnectX-6 HCA(파일 노드용)</block>
  <block id="ebf2a6ec614aa7ef6c7da2be9e2c23a7" category="list-text">MCX653106A-HDAT 호스트 채널 어댑터(HDR IB 200GB, 이중 포트 QSFP 56, PCIe4.0 x16)</block>
  <block id="151b6979304b49e9f2fa40146bc63177" category="cell">1m의 HDR InfiniBand 케이블(파일/블록 노드 직접 연결용)</block>
  <block id="334ee84af8f0aba772fc0297b7d99d85" category="list-text">MCP1650-H001E30(1m Mellanox Passive Copper 케이블, IB HDR, 최대 200Gbps, QSFP 56, 30AWG).</block>
  <block id="1d09a937487a970ae4b132b9d1bbd92e" category="paragraph">필요한 경우 파일 노드와 블록 노드 간의 더 긴 거리를 고려하여 길이를 조정할 수 있습니다.</block>
  <block id="3c947c9bfa7d34adb44f61243d2bdaf0" category="cell">HDR InfiniBand 케이블(파일 노드/스토리지 스위치 연결용)</block>
  <block id="826f9c9f2a5a5dd3ddf276fdf6370236" category="paragraph">파일 노드를 스토리지 리프 스위치에 연결하려면 적절한 길이의 InfiniBand HDR 케이블(QSFP 56 트랜시버)이 필요합니다. 가능한 옵션은 다음과 같습니다.</block>
  <block id="43f0edb9f1ba2bdb6e116f1a9ebc5efa" category="list-text">MCP1650-H002E26(2m Mellanox Passive Copper 케이블, IB HDR, 최대 200GB/s, QSFP 56, 30AWG).</block>
  <block id="e2c1cd9a1de33e9b1dfe101cbbeac58b" category="list-text">MFS1S00-H003E(3m Mellanox 활성 파이버 케이블, IB HDR, 최대 200GB/s, QSFP 56).</block>
  <block id="5fbc0fc6a38b0dbbeffcd2c2d4dcac9d" category="cell">E-Series 블록 노드</block>
  <block id="604f81d1187ffc116528d5f0ab32fb11" category="paragraph">EF600 컨트롤러 2개는 다음과 같이 구성됩니다.</block>
  <block id="577a9a467c2913dcad30956ec32e78e6" category="list-text">메모리: 256GB(컨트롤러당 128GB)</block>
  <block id="7e4c29cb3d75f6a12c915cb4eaaf3a1e" category="list-text">어댑터: 2포트 200GB/HDR(NVMe/IB)</block>
  <block id="d0fbc950f348eb754ea8bad25fabc0a7" category="list-text">드라이브: 원하는 용량과 일치하도록 구성됨</block>
  <block id="7ddb33edf227a18eb76201fcb9e2c9db" category="section-title">소프트웨어 요구 사항</block>
  <block id="440907229edb210984831982728c0047" category="paragraph">예측 가능한 성능 및 안정성을 위해 NetApp 기반 BeeGFS 솔루션의 릴리즈는 솔루션 구축에 필요한 소프트웨어 구성 요소의 특정 버전을 사용하여 테스트됩니다.</block>
  <block id="5fea6233624bde259c99b82e6d7de3c6" category="section-title">소프트웨어 배포 요구 사항</block>
  <block id="699b33acca98ab1d3eb0d684f59f1c98" category="paragraph">다음 표에는 Ansible 기반 BeeGFS 구축의 일부로 자동 구축되는 소프트웨어 요구사항이 나와 있습니다.</block>
  <block id="719d067b229178f03bcfa1da4ac4dede" category="cell">소프트웨어</block>
  <block id="34b6cd75171affba6957e308dcbd92be" category="cell">버전</block>
  <block id="eb57eb77389d7d4e71c5790c9c6ec1a7" category="cell">BeeGFS</block>
  <block id="9197ec103d780b6779cb78eec6afce31" category="cell">7.2.6</block>
  <block id="51cf7c858a71d06ee12a42cfbff97da7" category="cell">Corosync 를 참조하십시오</block>
  <block id="5d2d6ad0b2b4cf8622bcf4cddca922d1" category="cell">3.1.5-1</block>
  <block id="d95adee972ae170512bd3bdbce557054" category="cell">심장박동기</block>
  <block id="300cc3f7d5595a3ab5ad8f666e682b51" category="cell">2.1.0-8</block>
  <block id="0a0d34e3921098e12d40efeb9e5b64ff" category="cell">OpenSM을 참조하십시오</block>
  <block id="571ffe54d5507ffba520fd66014b973a" category="paragraph">OpenSM-5.9.0(mlnx_OFED 5.4-1.0.3.0부터)</block>
  <block id="fc9d1b1033b1fe0ed02e41584f187a0d" category="admonition">가상화를 활성화하기 위해 직접 연결에만 필요합니다.</block>
  <block id="13f2a3097f055e043d74b20940df2658" category="section-title">Ansible 제어 노드 요구사항</block>
  <block id="c3ee5ddf91e65773d3e9d27f9e627350" category="inline-link">Ansible 설명서</block>
  <block id="83d32979307efd813f41ef5070206fd3" category="paragraph">NetApp 기반 BeeGFS 솔루션은 Ansible 제어 노드에서 구축 및 관리됩니다. 자세한 내용은 를 참조하십시오<block ref="4410f583cbabaee2389115371eb2ab02" category="inline-link-rx"></block>.</block>
  <block id="158a122309f0454b31e4853755a5962a" category="paragraph">다음 표에 나와 있는 소프트웨어 요구사항은 아래 나열된 NetApp BeeGFS Ansible 컬렉션 버전과 관련이 있습니다.</block>
  <block id="d51d5ee15f404c2f4f7863bebcde1fac" category="cell">Ansible</block>
  <block id="c34646f8692ab9a9dce46b8b8b249892" category="cell">2.11 PIP를 통해 설치된 경우: Ansible-4.7.0 및 Ansible-Core&lt;2.12,&gt;=2.11.6</block>
  <block id="a7f5f35426b927411fc9231b56382173" category="cell">파이썬</block>
  <block id="47588d4b158a37889ddf44eeb8e88b0f" category="cell">3.9</block>
  <block id="d35d779fe31977939a0a72c5c962d2af" category="cell">추가 Python 패키지</block>
  <block id="77d3bd829df9097aa38d64335f6aad7f" category="cell">암호화 - 35.0.0, netaddr-0.8.0</block>
  <block id="6f82e755e888096a221d29f2d5410b52" category="cell">BeeGFS Ansible 컬렉션</block>
  <block id="272f0a04b740763e0a29316bc4af89a4" category="cell">3.0.0</block>
  <block id="5510cedb08df4208db0688e41cea716f" category="section-title">파일 노드 요구 사항</block>
  <block id="eae2868fd17cac4569887ad9ccca42c2" category="paragraph">RedHat Enterprise Linux</block>
  <block id="c902ad984234c1eef95b7912574d9aeb" category="paragraph">RedHat 8.4 서버의 물리적 및 고가용성(2 소켓).</block>
  <block id="1f8b1bc6c0a349e88a3353e347489a9a" category="admonition">파일 노드에는 유효한 RedHat Enterprise Linux Server 서브스크립션과 Red Hat Enterprise Linux 고가용성 애드온이 필요합니다.</block>
  <block id="2488fead2064d4aeb886afc1a0010ee7" category="cell">Linux 커널</block>
  <block id="d4b0f66130f05055ad49d7919514984a" category="cell">4.18.0-305.25.1.el8_4.x86_64</block>
  <block id="f6883581bd882ffdf705127738982586" category="cell">InfiniBand/RDMA 드라이버</block>
  <block id="3882d32c66e7e768145ecd8f104b0c08" category="cell">받은 편지함</block>
  <block id="0f8b40e8389c6b79812629492fb9facd" category="cell">ConnectX-6 HCA 펌웨어</block>
  <block id="4ebe5da399ec2e4a8aa42aee4a85eef5" category="cell">FW: 20.31.1014</block>
  <block id="1669d53b71fac20015fb08bdb7e0f816" category="cell">PXE: 3.6.0403</block>
  <block id="56f186085ad1743522ca2a29632d91eb" category="cell">UEFI: 14.24.0013</block>
  <block id="fbc534ed33feffdfe8fc56e7cde13e6e" category="section-title">EF600 블록 노드 요구사항</block>
  <block id="e791d47d690cbc6aa7c7f9434ebd2fa1" category="cell">SANtricity OS를 참조하십시오</block>
  <block id="aa64d564cff905bb777c7f6cceb9c9d3" category="cell">11.70.2</block>
  <block id="b384b3cf4ffa3a81a88e8687dd6ca028" category="cell">NVSRAM</block>
  <block id="2bd1a0272130dcc2055e0f904d00fe3c" category="cell">N6000-872834-D06.DLP</block>
  <block id="b89cb5f38b54c6181858af1281dcaeef" category="cell">드라이브 펌웨어</block>
  <block id="df4607ba320342072b2dc12271b08d2f" category="cell">사용 중인 드라이브 모델에 대한 최신 버전입니다.</block>
  <block id="024464eb7b3fd909a9746dff88c6b9c9" category="section-title">추가 요구 사항</block>
  <block id="61440af9eaf0ce02a7d08f34876b087d" category="paragraph">다음 표에 나열된 장비가 검증에 사용되었지만 필요에 따라 적절한 대안을 사용할 수 있습니다. 일반적으로 예기치 않은 문제를 방지하려면 최신 소프트웨어 버전을 실행하는 것이 좋습니다.</block>
  <block id="81a57f3c03234ff1f2a69dde51a4eb30" category="cell">설치된 소프트웨어</block>
  <block id="3ba6b98074aa537a4599a5717fc1667c" category="list-text">2x Mellanox MQM8700 200GB InfiniBand 스위치</block>
  <block id="5506d82b19c7fb79ef3ae9c724240c8e" category="list-text">펌웨어 3.9.2110</block>
  <block id="d80c6d0ee3d3645d6e79f023da5f811d" category="paragraph">* 1x Ansible 제어 노드(가상화): *</block>
  <block id="b5d77813b4d6bf45ad5812887dddc3b6" category="list-text">프로세서: 인텔(R) 제온(R) 골드 6146 CPU @ 3.20GHz</block>
  <block id="ed7e62a0a7749f5ecdeacff73f47cd74" category="list-text">메모리: 8GB</block>
  <block id="9b127271fc710f9ccddb6752d4706302" category="list-text">로컬 스토리지: 24GB</block>
  <block id="0da4148b13259a822cbef39b72084c99" category="list-text">CentOS Linux 8.4.2105</block>
  <block id="4c082b998d02b58acba9fe2b7c4fa784" category="list-text">커널 4.18.0-305.3.1.el8.x86_64</block>
  <block id="e213de1dde80716b46e639e6e4211241" category="paragraph">설치된 Ansible 및 Python 버전이 위 표의 버전과 일치합니다.</block>
  <block id="bc5f18e7f65533d407f6b5c4ee36f1a8" category="paragraph">* 10x BeeGFS 클라이언트(CPU 노드): *</block>
  <block id="ba4ebea566ef71314e819a2849f2df50" category="list-text">프로세서: 1x AMD EPYC 7302 16코어 CPU, 3.0GHz</block>
  <block id="e21bd6758a43c483b7d0071867188cf3" category="list-text">메모리: 128GB</block>
  <block id="6045a9bd677549ebf210bae5890c8473" category="list-text">네트워크: 2x Mellanox MCX653106A-HDAT(어댑터당 하나의 포트 연결).</block>
  <block id="73611f9a837b7a25dad3a9c5d1a98658" category="list-text">Ubuntu 20.04</block>
  <block id="5c102f668db12e3182739e89576e526b" category="list-text">커널: 5.4.0-100 - 일반</block>
  <block id="11c40f47f4b43c52533122c701bc0c0c" category="list-text">InfiniBand 드라이버: Mellanox OFED 5.4-1.0.3.0</block>
  <block id="03fa34a7812c6af1b694c2914333785b" category="paragraph">* 1x BeeGFS 클라이언트(GPU 노드): *</block>
  <block id="6299da9dcf5c047e5fda43f47d185352" category="list-text">프로세서: 2.25GHz에서 AMD EPYC 7742 64코어 CPU 2개</block>
  <block id="9278571d707ba27f73c7811c10c50142" category="list-text">메모리: 1TB</block>
  <block id="d4974e31435247f5311454d41461425a" category="paragraph">이 시스템은 NVIDIAs HGX A100 플랫폼을 기반으로 하며 4개의 A100 GPU를 포함합니다.</block>
  <block id="cef5ab698867f39ec4b495cba708da1a" category="summary">BeeGFS on NetApp 솔루션은 BeeGFS 병렬 파일 시스템을 NetApp EF600 스토리지 시스템과 결합하여 까다로운 워크로드에 대응할 수 있는 안정적이고 확장 가능하며 비용 효율적인 인프라를 제공합니다.</block>
  <block id="c0c4b60d27032c028c91440e9d3be949" category="doc">솔루션 개요</block>
  <block id="038a39033a8ecd147024e4510f646b8c" category="paragraph">이 설계에서는 최신 엔터프라이즈 서버 및 스토리지 하드웨어와 네트워크 속도를 통해 제공되는 성능 밀도와 듀얼 AMD EPYC 7003 “Milan” 프로세서를 갖춘 파일 노드 및 200GB(HDR) InfiniBand를 사용하는 직접 연결 PCIe 4.0을 지원하는 NVMe/IB 프로토콜을 사용하는 엔드 투 엔드 NVMe 및 NVMeOF를 제공하는 블록 노드 필요.</block>
  <block id="c6ff1c8ffcd7024a30e7240129bf57a8" category="section-title">NVA 프로그램</block>
  <block id="f109ec830b8ab112f8e89da398d4ca0f" category="paragraph">NetApp 솔루션의 BeeGFS는 NVA(NetApp Verified Architecture) 프로그램에 포함되어 있으며, 특정 워크로드 및 사용 사례에 대한 참조 구성 및 사이징 지침을 고객에게 제공합니다. NVA 솔루션은 구축 위험을 최소화하고 시장 출시 기간을 단축할 수 있도록 철저한 테스트와 설계를 거쳤습니다.</block>
  <block id="2a3b399798aa16ecfbc1425cc560bfad" category="section-title">사용 사례</block>
  <block id="9a250aa43ea6738ca4cd441c42e26b4e" category="paragraph">NetApp 기반 BeeGFS 솔루션에는 다음 사용 사례가 적용됩니다.</block>
  <block id="f743e786ba2a29eb033d8f7e1e2101d3" category="inline-link">AI용 BeeGFS: 팩션과 픽션 비교</block>
  <block id="b761cb5be0f07b26af56bda6c19cf90a" category="list-text">머신 러닝(ML), 딥 러닝(DL), 대규모 자연어 처리(NLP), 자연어 이해(NLU)를 비롯한 인공 지능(AI) 자세한 내용은 을 참조하십시오<block ref="e0ec3865f791595484686c9b79436d0e" category="inline-link-rx"></block>.</block>
  <block id="3476c4aa4908c2b49f576f13d95d657a" category="inline-link">BeeGFS가 HPC를 넘어서는 이유</block>
  <block id="4becc7ac7e53ca421f06307e37478c8a" category="list-text">MPI(메시지 전달 인터페이스) 및 기타 분산 컴퓨팅 기술에 의해 가속되는 응용 프로그램을 포함한 고성능 컴퓨팅(HPC). 자세한 내용은 을 참조하십시오<block ref="3f795d4ce44ed51872cb7704a4553f2a" category="inline-link-rx"></block>.</block>
  <block id="89b4dd8e856627d44ffe8d3d0066cd98" category="list-text">애플리케이션 워크로드의 특징:</block>
  <block id="c9ccfce7935790c9fd0d9ccf98da5177" category="list-text">1GB 이상의 파일을 읽거나 쓰는 중입니다</block>
  <block id="680e47afa4860ce2ac4a078a0d466121" category="list-text">여러 클라이언트(10s, 100s 및 1000)에서 동일한 파일을 읽거나 쓰는 경우</block>
  <block id="56e0e65d3207ad1f0f7efb003935c936" category="list-text">테라바이트급 또는 페타바이트급의 데이터 세트</block>
  <block id="f36d694578bdc30f9cfa5faeb163df61" category="list-text">크기가 큰 파일과 작은 파일을 혼합하여 사용할 수 있도록 최적화되는 단일 스토리지 네임스페이스가 필요한 환경</block>
  <block id="e654f7a86a4458b9cd662267e0f29b52" category="section-title">이점</block>
  <block id="abc4f101e3891d158ab6ad80a3568c46" category="paragraph">NetApp에서 BeeGFS를 사용할 때의 주요 이점은 다음과 같습니다.</block>
  <block id="f1161b5399c6f13433f0d7ef82e26dfc" category="list-text">검증된 하드웨어 설계를 통해 하드웨어 및 소프트웨어 구성요소를 완벽하게 통합하여 예측 가능한 성능과 안정성을 보장합니다.</block>
  <block id="d678167c236b5d1af08b550c5038cccb" category="list-text">Ansible을 사용한 구축 및 관리로 단순성과 일관성 확보</block>
  <block id="82a72442e588bfcf2e472da1d9834f2a" category="inline-link">NetApp E-Series 솔루션을 모니터링하는 프레임워크 소개</block>
  <block id="e30389e6b0882b87124e5401375e84e3" category="list-text">E-Series Performance Analyzer 및 BeeGFS 플러그인을 사용하여 제공되는 모니터링 및 관찰 가능성 자세한 내용은 을 참조하십시오<block ref="5fd4bf3409228b006228517662906ac3" category="inline-link-rx"></block>.</block>
  <block id="fc20f26327fc88da82154f6c09f6991d" category="list-text">데이터 내구성과 가용성을 제공하는 공유 디스크 아키텍처를 갖춘 고가용성</block>
  <block id="d47615808883de28c6943d206bf0d2cb" category="inline-link">Kubernetes에서 BeeGFS를 만나 보십시오. 미래 지향형 투자 이야기입니다</block>
  <block id="7f62321e8e75c63a1fe94a4d41435dac" category="list-text">컨테이너 및 Kubernetes를 사용하여 최신 워크로드 관리 및 오케스트레이션 지원 자세한 내용은 을 참조하십시오<block ref="3ba4b256f7ab4762b0c431fc1809aa9b" category="inline-link-rx"></block>.</block>
  <block id="cf03dce6d27c37ae2bf803a5ad8ddb93" category="section-title">HA 아키텍처</block>
  <block id="5c306284db745339f153886fd666ba5f" category="paragraph">NetApp 기반의 BeeGFS는 NetApp 하드웨어로 완벽하게 통합된 솔루션을 생성하여 공유 디스크 HA(고가용성) 아키텍처를 지원하여 BeeGFS 엔터프라이즈 에디션의 기능을 확장합니다.</block>
  <block id="5481b5a39e7ecc68d8956711964cffcb" category="admonition">BeeGFS 커뮤니티 에디션은 무료로 사용할 수 있지만, 이 엔터프라이즈 에디션은 NetApp과 같은 파트너로부터 프로페셔널 지원 구독 계약을 구매해야 합니다. Enterprise Edition에서는 복원력, 할당량 적용 및 스토리지 풀을 비롯한 몇 가지 추가 기능을 사용할 수 있습니다.</block>
  <block id="d1d1e6e3c28393c984fbb987be60324d" category="paragraph">다음 그림에서는 공유 안 함 및 공유 디스크 HA 아키텍처를 비교하여 보여 줍니다.</block>
  <block id="2840bfa899c06356961cfdc8e84723c3" category="paragraph"><block ref="2840bfa899c06356961cfdc8e84723c3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="52feb691d73302501483cced28704021" category="inline-link">NetApp에서 지원하는 BeeGFS에 대한 고가용성 발표</block>
  <block id="0bd36571bea371893d99d201b7835845" category="paragraph">자세한 내용은 을 참조하십시오<block ref="eb50143d83b72cd897fd47297781957c" category="inline-link-rx"></block>.</block>
  <block id="733ba000742537e7a4435573aca51393" category="inline-link">Ansible 갤럭시</block>
  <block id="6ec27f578410cadd1a5e4b274d75cdb2" category="inline-link">NetApp의 E-Series GitHub를 참조하십시오</block>
  <block id="d643841fe27d769d39ef1865b69cb48b" category="paragraph">NetApp 기반 BeeGFS는 GitHub 및 Ansible Galaxy(BeeGFS 컬렉션)에서 호스팅되는 Ansible 자동화를 통해 제공 및 구축됩니다<block ref="6e6b4aec10f34b8873e2101fed073d9a" category="inline-link-rx"></block> 및<block ref="6e9ef2e0fff4844f9560394ab05a51e9" category="inline-link-rx"></block>)를 클릭합니다. Ansible은 BeeGFS 구성 요소를 조립하는 데 사용되는 하드웨어에서 주로 테스트되지만, 지원되는 Linux 배포를 사용하여 거의 모든 x86 기반 서버에서 실행되도록 구성할 수 있습니다.</block>
  <block id="dcd417571f5073f074067e7d0d445a2e" category="inline-link">E-Series 스토리지를 통해 BeeGFS 구축</block>
  <block id="cb8de1e2639bc0378b3714cf6ba35837" category="paragraph">자세한 내용은 을 참조하십시오<block ref="8af04fa161ecb5f3ec4feab8d52e96c8" category="inline-link-rx"></block>.</block>
  <block id="e69ebf3ec790efafa5cfc7b6502ccfe4" category="summary">BeeGFS on NetApp 솔루션에는 검증된 워크로드를 지원하는 데 필요한 특정 장비, 케이블링, 구성을 결정하는 데 사용되는 아키텍처 설계 고려사항이 포함되어 있습니다.</block>
  <block id="ebd8431a0b14e9588377860f5d21d80b" category="doc">아키텍처 개요</block>
  <block id="dc3f25ceea15d952c20a612e806039b4" category="section-title">빌딩 블록 아키텍처</block>
  <block id="f968e1fab577166d28baa278b7fbec71" category="paragraph">스토리지 요구 사항에 따라 BeeGFS 파일 시스템을 다양한 방식으로 구축 및 확장할 수 있습니다. 예를 들어, 주로 작은 파일을 많이 사용하는 사용 사례에서는 메타데이터 성능과 용량이 더 큰 반면, 큰 파일이 적은 사용 사례에서는 실제 파일 콘텐츠에 대해 더 많은 스토리지 용량과 성능을 선호할 수 있습니다. 이러한 여러 가지 고려 사항은 병렬 파일 시스템 구축의 여러 가지 차원을 영향을 주므로 파일 시스템을 설계하고 구축하는 작업이 더 복잡해집니다.</block>
  <block id="a0f56902d72268743383af795844da43" category="paragraph">이러한 문제를 해결하기 위해 NetApp은 이러한 각 차원을 확장하는 데 사용되는 표준 구성 요소 아키텍처를 설계했습니다. 일반적으로 BeeGFS 빌딩 블록은 다음 세 가지 구성 프로파일 중 하나로 구축됩니다.</block>
  <block id="cbebd598c304febe3d9ce528a39f79ca" category="list-text">BeeGFS 관리, 메타데이터 및 스토리지 서비스를 포함한 단일 기본 구성 요소입니다</block>
  <block id="f606793c59d48b54b2b3a18a70dd823d" category="list-text">BeeGFS 메타데이터 및 스토리지 구성 요소입니다</block>
  <block id="5d36a489380874ed227d193957d972de" category="list-text">BeeGFS 스토리지 전용 구성 요소입니다</block>
  <block id="3679eaa30562d3f5040cb64c625a3455" category="paragraph">이 세 가지 옵션 간의 하드웨어 변경 사항은 BeeGFS 메타데이터에 더 작은 드라이브를 사용하는 것입니다. 그렇지 않으면 모든 구성 변경 사항이 소프트웨어를 통해 적용됩니다. 또한 Ansible을 구축 엔진으로 사용하면 특정 구성 요소에 대해 원하는 프로필을 설정하여 구성 작업을 간단하게 수행할 수 있습니다.</block>
  <block id="0623572375a27997b16aa8f259513278" category="paragraph">자세한 내용은 을 참조하십시오 <block ref="27bdb301347b8d7fa8a057384825ba6a" category="inline-xref-macro-rx"></block>.</block>
  <block id="e3b101a8b62b6541bfde340117b3f92b" category="section-title">파일 시스템 서비스</block>
  <block id="26e699f65c8724efd549a1445c4b9eb3" category="paragraph">BeeGFS 파일 시스템에는 다음과 같은 주요 서비스가 포함됩니다.</block>
  <block id="a9effde6a4743049a20cd75e19532999" category="list-text">관리 서비스.* 다른 모든 서비스를 등록하고 모니터링합니다.</block>
  <block id="edd29dd37a407bf6bdd3dcefe97db0d5" category="list-text">* 스토리지 서비스. * 데이터 청크 파일이라고 하는 분산 사용자 파일 콘텐츠를 저장합니다.</block>
  <block id="dc134a7a2e4d2cbe6789c47709b38b35" category="list-text">* 메타데이터 서비스. * 파일 시스템 레이아웃, 디렉토리, 파일 특성 등을 추적합니다.</block>
  <block id="bfd4d1f28f912adef70ff502946f2d7a" category="list-text">* 클라이언트 서비스. * 파일 시스템을 마운트하여 저장된 데이터에 액세스합니다.</block>
  <block id="94ab5c559c66cc4fc4b2e1c1ed4b00a3" category="paragraph">다음 그림에서는 NetApp E-Series 시스템에 사용된 BeeGFS 솔루션 구성 요소 및 관계를 보여 줍니다.</block>
  <block id="bfcf7994ec645acbf0e62ec0cc0d8135" category="paragraph"><block ref="bfcf7994ec645acbf0e62ec0cc0d8135" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9ac96964e53d6a8061e16551c85e7b05" category="paragraph">BeeGFS는 병렬 파일 시스템으로서 여러 서버 노드에서 파일을 스트라이핑하여 읽기/쓰기 성능과 확장성을 극대화합니다. 서버 노드는 함께 작동하여 일반적으로 _clients_라고 하는 다른 서버 노드에서 동시에 마운트하고 액세스할 수 있는 단일 파일 시스템을 제공합니다. 이러한 클라이언트는 NTFS, XFS 또는 ext4와 같은 로컬 파일 시스템과 유사하게 분산 파일 시스템을 보고 사용할 수 있습니다.</block>
  <block id="2cd4f3c05097f81722656ab8de9b6a25" category="paragraph">지원되는 다양한 Linux 배포판에서 4개의 기본 서비스를 실행하고 InfiniBand(IB), OPA(Omni-Path), RoCE(RDMA over Converged Ethernet)를 비롯한 TCP/IP 또는 RDMA 지원 네트워크를 통해 통신합니다. BeeGFS 서버 서비스(관리, 스토리지 및 메타데이터)는 사용자 공간 데몬이며, 클라이언트는 네이티브 커널 모듈(패치리스)입니다. 모든 구성요소를 재부팅하지 않고 설치 또는 업데이트할 수 있으며 동일한 노드에서 서비스 조합을 실행할 수 있습니다.</block>
  <block id="006d93ef4f9eec646f24191298096ff5" category="section-title">검증된 노드</block>
  <block id="c96c4db6ed51cc2193de3faf12adec4b" category="paragraph">NetApp 기반 BeeGFS 솔루션에는 NetApp EF600 스토리지 시스템(블록 노드) 및 Lenovo ThinkSystem SR665 서버(파일 노드)의 검증된 노드가 포함됩니다.</block>
  <block id="27413f72a901dfdce9c9f5b55bb8de24" category="section-title">블록 노드: EF600 스토리지 시스템</block>
  <block id="c9423adc70506c44748bf2f624d7f901" category="paragraph">NetApp EF600 All-Flash 어레이는 일관된 거의 실시간에 가까운 데이터 액세스를 제공하는 동시에 모든 워크로드를 동시에 지원합니다. AI 및 HPC 애플리케이션에 데이터를 지속적으로 신속하게 제공하기 위해 EF600 스토리지 시스템은 하나의 엔클로저에 최대 2백만 개의 캐시된 읽기 IOPS, 100마이크로초 미만의 응답 시간, 42GBps 순차적 읽기 대역폭을 제공합니다.</block>
  <block id="651e200415759284120b2ec1a66b1a96" category="section-title">파일 노드: Lenovo ThinkSystem SR665 서버</block>
  <block id="6b9e4d337aab66ffe52d7442d4de33cd" category="paragraph">SR665는 PCIe 4.0을 지원하는 2소켓 2U 서버입니다. 이 솔루션의 요구사항을 충족하도록 구성하면 직접 연결된 E-Series 노드에서 제공하는 처리량 및 IOP와 잘 어울리도록 구성에서 BeeGFS 파일 서비스를 실행할 수 있는 충분한 성능을 제공합니다.</block>
  <block id="18bc6212071e7cb1cca90788a40a9301" category="inline-link">Lenovo 웹 사이트</block>
  <block id="81024062a06a8ee37394167df6e2e925" category="paragraph">Lenovo SR665에 대한 자세한 내용은 를 참조하십시오<block ref="2cce034b75e116efa73dc639a17202fa" category="inline-link-rx"></block>.</block>
  <block id="4b2aed7f56892904807d2a0dba262f91" category="section-title">검증된 하드웨어 설계</block>
  <block id="9e33e1f9796877cc85735e8b785ca26f" category="paragraph">다음 그림에 나와 있는 솔루션의 구성 요소는 BeeGFS 파일 계층에 2개의 듀얼 소켓 PCIe 4.0 지원 서버를 사용하고 블록 계층으로 2개의 EF600 스토리지 시스템을 사용합니다.</block>
  <block id="9aff371c3d72ae246b764db116d45c50" category="paragraph"><block ref="9aff371c3d72ae246b764db116d45c50" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5c48dcdddb94107a7a67762c9d1dbe6f" category="admonition">각 구성 요소에 BeeGFS 파일 노드가 2개 포함되어 있으므로 페일오버 클러스터에 쿼럼을 설정하려면 최소 2개의 구성 요소가 필요합니다. 2노드 클러스터를 구성할 수 있지만 이 구성에는 페일오버가 발생하지 않도록 할 수 있는 제한이 있습니다. 2노드 클러스터가 필요한 경우 세 번째 장치를 Tiebreaker로 통합할 수 있습니다(단, 이 설계에서는 다루지 않음).</block>
  <block id="6a07b0ff8ee12bcea9aba90004bdf2e9" category="paragraph">각 구성 요소는 파일 및 블록 계층에 대한 장애 도메인을 분리하는 2계층 하드웨어 설계를 통해 고가용성을 제공합니다. 각 계층은 독립적으로 페일오버될 수 있으므로 복원력을 높이고 계단식 고장 위험을 줄일 수 있습니다. HDR InfiniBand를 NVMeOF와 함께 사용하면 전체 이중화 및 충분한 링크 초과 할당으로 파일 노드와 블록 노드 간에 높은 처리량과 최소 지연 시간을 제공하여 시스템이 부분적으로 성능 저하 상태일 때도 분리되는 설계를 병목 현상이 발생하지 않습니다.</block>
  <block id="3c08ab3aeeb113b43a410e04cd194da5" category="paragraph">BeeGFS on NetApp 솔루션은 구축 환경의 모든 구성 요소에서 실행됩니다. 구축된 첫 번째 구성 요소는 BeeGFS 관리, 메타데이터 및 스토리지 서비스(기본 구성 요소라고도 함)를 실행해야 합니다. 이후의 모든 구성 요소는 소프트웨어를 통해 BeeGFS 메타데이터 및 스토리지 서비스를 실행하거나 스토리지 서비스만 실행하도록 구성됩니다. 각 구성 요소에 서로 다른 구성 프로필을 사용할 수 있으므로 동일한 기본 하드웨어 플랫폼 및 구성 요소 설계를 사용하여 파일 시스템 메타데이터 또는 스토리지 용량과 성능을 확장할 수 있습니다.</block>
  <block id="8c75634d2e6f2b333be16514a845f21a" category="paragraph">최대 5개의 빌딩 블록이 독립 실행형 Linux HA 클러스터에 결합되어 클러스터 리소스 관리자(페이스 메이커)당 적절한 리소스 수를 확보하고 클러스터 구성원을 동기화 상태로 유지하는 데 필요한 메시징 오버헤드를 줄입니다(Corosync). 충분한 구성원이 쿼럼을 설정할 수 있도록 클러스터당 최소 2개의 빌딩 블록을 사용하는 것이 좋습니다. 이러한 독립 실행형 BeeGFS HA 클러스터 중 하나 이상이 결합되어 클라이언트가 단일 스토리지 네임스페이스로 액세스할 수 있는 BeeGFS 파일 시스템(다음 그림에 표시)을 생성합니다.</block>
  <block id="68f8e190e5b0a73975772032f02e616d" category="paragraph"><block ref="68f8e190e5b0a73975772032f02e616d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2656fcaf8e3676a2cbef703871ecdf24" category="paragraph">궁극적으로 랙당 구성 요소의 수는 해당 사이트의 전력 및 냉각 요구 사항에 따라 달라지지만, 이 솔루션은 스토리지/데이터 네트워크에 사용되는 2개의 1U InfiniBand 스위치를 위한 공간을 제공하면서 단일 42U 랙에 최대 5개의 구성 요소를 구축할 수 있도록 설계되었습니다. 각 구성 요소마다 8개의 IB 포트(이중화를 위해 스위치당 4개)가 필요하므로, 5개의 구성 요소는 40포트 HDR InfiniBand 스위치(예: NVIDIA QM8700)에 포트의 절반을 남겨 FAT 트리 또는 이와 유사한 비차단 토폴로지를 구현할 수 있습니다. 이렇게 구성하면 네트워킹 병목 현상 없이 스토리지 또는 컴퓨팅/GPU 랙 수를 확장할 수 있습니다. 필요에 따라 스토리지 패브릭 공급업체의 권장 사항에서 초과 할당된 스토리지 패브릭을 사용할 수 있습니다.</block>
  <block id="70fe669a3a23094d7db9486a417dbef3" category="paragraph">다음 이미지는 80노드 FAT 트리 토폴로지를 보여줍니다.</block>
  <block id="2fcf68f5d15d3841e3d288e4c8a6107c" category="paragraph"><block ref="2fcf68f5d15d3841e3d288e4c8a6107c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d6a8fb7565b3c37b0228984862a3977c" category="paragraph">Ansible을 NetApp 기반의 BeeGFS 구축을 위한 배포 엔진으로 사용하여 관리자는 최신 인프라를 코드 사례로 사용하여 전체 환경을 유지할 수 있습니다. 이렇게 하면 복잡한 시스템이 될 수 있는 일이 크게 단순화되어 관리자가 한 곳에서 구성을 정의 및 조정한 다음, 환경 확장규모에 관계없이 일관되게 적용할 수 있습니다. BeeGFS 컬렉션은 에서 구할 수 있습니다<block ref="6e6b4aec10f34b8873e2101fed073d9a" category="inline-link-rx"></block> 및<block ref="6e9ef2e0fff4844f9560394ab05a51e9" category="inline-link-rx"></block>.</block>
  <block id="c8a0fcd1a15bb039926f56fd15ce82e9" category="summary">NetApp 솔루션의 BeeGFS에 적용되는 용어 및 개념</block>
  <block id="5d146c3fd3b69782d69f66b386b88a4c" category="doc">용어 및 개념</block>
  <block id="5710fc980ad3cc07a2d53a30f8e42802" category="paragraph">다음 용어와 개념은 NetApp 기반 BeeGFS 솔루션에 적용됩니다.</block>
  <block id="cf5f3091e30dee6597885d8c0e0c357f" category="cell">기간</block>
  <block id="b5a7adde1af5c87d7fd797b6245c2a39" category="cell">설명</block>
  <block id="0a40e3c91a3a55c9a37428c6d194d0e5" category="paragraph">AI</block>
  <block id="10a99475af71a950df10ae4fb41e6b27" category="paragraph">인공 지능.</block>
  <block id="206b11a774f63418bae21625e6f6d2fb" category="paragraph">Ansible 인벤토리</block>
  <block id="4278d92c9bdf11d430a86f440cffbb06" category="paragraph">원하는 BeeGFS HA 클러스터를 설명하는 데 사용되는 YAML 파일이 포함된 디렉토리 구조.</block>
  <block id="396262ee936f3d3e26ff0e60bea6cae0" category="paragraph">BMC</block>
  <block id="20e7cb5fddc6ef60deff83e38954fc9c" category="paragraph">베이스보드 관리 컨트롤러. 서비스 프로세서라고도 합니다.</block>
  <block id="399cda935f5cb9e0b94eaf42309257fb" category="paragraph">블록 노드</block>
  <block id="56977f2bee9d2716e5224e95ceb72839" category="paragraph">기술을 자세히 소개합니다.</block>
  <block id="fac04ca68a48af91f0290001604a2463" category="paragraph">클라이언트</block>
  <block id="f5ce9f5cb682a1f863d5a8c51ac28683" category="paragraph">DL</block>
  <block id="3a113e532fcdd400cdf83ef62ac9d9de" category="paragraph">딥 러닝.</block>
  <block id="c404903bef63acba3e3abe370e09474f" category="paragraph">파일 노드</block>
  <block id="2118e5d99e7b7d309a8f82e52f89ab22" category="paragraph">BeeGFS 파일 서버</block>
  <block id="594c16ca0695f6665d7cf4971707adf6" category="paragraph">HA</block>
  <block id="b5c55115b0714618209ee9459023bad1" category="paragraph">고가용성.</block>
  <block id="a25baf723f95fbcbceae8399b638f108" category="paragraph">HIC</block>
  <block id="2d5307a091565cb524b7c0a2c48a1588" category="paragraph">호스트 인터페이스 카드.</block>
  <block id="2f569257101cf136a49d983584bfc44f" category="paragraph">HPC</block>
  <block id="9a3968cd0518e869657fa99f060cd8f2" category="paragraph">고성능 컴퓨팅.</block>
  <block id="06a52007ec390481940877b63a4b7c61" category="paragraph">HPC 스타일의 워크로드</block>
  <block id="221d47451f4f42c2e516a414798b6e1e" category="paragraph">HPC 스타일 워크로드는 일반적으로 여러 컴퓨팅 노드 또는 GPU에서 동일한 데이터 세트에 병렬로 액세스하여 분산된 컴퓨팅 또는 교육 작업을 진행하는 것이 특징입니다. 이러한 데이터 세트는 단일 파일에 대한 동시 액세스를 방지하는 기존 하드웨어 병목 현상을 제거하기 위해 여러 물리적 스토리지 노드에 스트라이핑되어야 하는 대용량 파일로 구성되는 경우가 많습니다.</block>
  <block id="d01fd9b01e9dde8bd3dc247afbfb7218" category="paragraph">ML</block>
  <block id="65abbc2190f8ea8522de3b7df3397302" category="paragraph">머신 러닝.</block>
  <block id="85587c49afa2ea2adacd4bbcdb57d064" category="paragraph">NLP</block>
  <block id="1e8218217ed7a37de1bd5f394a253db8" category="paragraph">자연어 처리.</block>
  <block id="04808383df00e6501c912f8fae661f73" category="paragraph">NLU</block>
  <block id="f0f701867a5e02fa406b05e22df7ae03" category="paragraph">자연어 이해.</block>
  <block id="af33781ae5dd2f5ffb194a90989038a8" category="paragraph">NVA</block>
  <block id="4119dd754c8118aa6a1bb36f194a2f52" category="paragraph">NVA(NetApp Verified Architecture) 프로그램은 특정 워크로드 및 사용 사례에 대한 참조 구성 및 사이징 지침을 제공합니다. 이러한 솔루션은 철저한 테스트를 거쳤으며, 구축 위험을 최소화하고 출시 기간을 단축할 수 있도록 설계되었습니다.</block>
  <block id="51bfd24e79e0939d84e9230980db5f18" category="summary">BeeGFS on NetApp 솔루션은 현재 세대 간 설계의 2세대입니다.</block>
  <block id="fa0de4179a84e742d2d88028d16bf137" category="doc">디자인 세대</block>
  <block id="51c16b7415d506b9bbcedd7241c7c1c0" category="paragraph">1세대 및 2세대 모두에는 BeeGFS 파일 시스템과 NVMe EF600 스토리지 시스템을 통합한 기본 아키텍처가 포함되어 있습니다. 그러나 2세대 제품에는 다음과 같은 추가적인 이점이 포함되어 있습니다.</block>
  <block id="20667306535e51f69f34371b95abfd0b" category="list-text">2U 랙 공간만 추가하여 성능과 용량을 두 배로 향상</block>
  <block id="edcc56d654a1a9362699f309c738a185" category="list-text">공유 디스크, 2계층 하드웨어 설계를 기반으로 한 고가용성(HA</block>
  <block id="189fdda096d5b994e140eac128f464e1" category="section-title">2세대 설계</block>
  <block id="145c927b5996411105e8a05381bfab75" category="section-title">최초의 세대별 설계</block>
  <block id="41ae1cb2edd9d144116e252e5f5c4e54" category="paragraph">NetApp 기반의 1세대 BeeGFS는 NetApp EF600 NVMe 스토리지 시스템, BeeGFS 병렬 파일 시스템, NVIDIA DGX ™ A100 시스템 및 NVIDIA ® Mellanox ® Quantum ™ QM8700 200Gbps IB 스위치를 사용하는 머신 러닝(ML) 및 인공 지능(AI) 워크로드용으로 설계되었습니다. 또한, 이 설계에서는 스토리지 및 컴퓨팅 클러스터 인터커넥트 패브릭을 위한 200Gbps InfiniBand(IB)를 사용하여 고성능 워크로드를 위한 완벽한 IB 기반 아키텍처를 제공합니다.</block>
  <block id="8c2de6dc6972aa428c25b73867ee0c6c" category="inline-link-macro">NVIDIA DGX A100 Systems 및 BeeGFS를 지원하는 NetApp EF-Series AI</block>
  <block id="cb0e1ee82028e21bcb25d1cedee42a90" category="paragraph">1세대 제품에 대한 자세한 내용은 를 참조하십시오 <block ref="7c75f12548abfaad3f9a226ecdfc54d3" category="inline-link-macro-rx"></block>.</block>
  <block id="745f22cbd412f2eab6c6bf95417e8b09" category="doc">이 사이트에 포함된 내용</block>
  <block id="fb7e8abee0ed4186f8c4b871d0ea6ac3" category="inline-link-macro">설계 개요</block>
  <block id="42f8643eb52a942747937327c72c8361" category="inline-link-macro">구축 개요</block>
  <block id="fefc21957cc1bbb1f6a7704d95ad5e0d" category="summary">2세대 NetApp BeeGFS 빌딩 블록 설계를 사용하여 NetApp에서 검증된 파일 및 블록 노드에 BeeGFS를 구축할 수 있습니다.</block>
  <block id="ef200d7e9d983785df6b4e01fa65bf59" category="section-title">Ansible 컬렉션 및 역할</block>
  <block id="31f2ceaa03965649e2e37df5634511e7" category="paragraph">Ansible을 사용하여 NetApp 솔루션에 BeeGFS를 구축할 수 있습니다. 이는 애플리케이션 구축을 자동화하는 데 사용되는 일반적인 IT 자동화 엔진입니다. Ansible은 구축할 BeeGFS 파일 시스템을 모델링하는 인벤토리로 통칭되는 일련의 파일을 사용합니다.</block>
  <block id="87d27d52f7fc81e8a134f2e3d2a57ecf" category="inline-link">NetApp E-Series BeeGFS 컬렉션</block>
  <block id="f4bf5484498b52d77cb39955020e5321" category="paragraph">Ansible을 사용하면 NetApp과 같은 기업에서 Ansible Galaxy의 컬렉션을 사용하여 기본 제공 기능을 확장할 수 있습니다(참조)<block ref="8dd9c2247c6151110981020f59a5fca3" category="inline-link-rx"></block>)를 클릭합니다. 컬렉션에는 E-Series 볼륨 만들기와 같이 특정 기능 또는 작업을 수행하는 모듈과 여러 모듈 및 기타 역할을 호출할 수 있는 역할이 포함되어 있습니다. 이 자동화된 방식을 통해 BeeGFS 파일 시스템 및 기본 HA 클러스터를 구축하는 데 필요한 시간을 줄일 수 있습니다. 또한, 기존 파일 시스템을 확장하기 위해 구성 요소를 간단하게 추가할 수 있습니다.</block>
  <block id="4aa1cf90ffa01d3b63825bad839d9e29" category="inline-link-macro">Ansible 인벤토리에 대해 알아보십시오</block>
  <block id="1325754275d5677e560f21035bc1ac47" category="paragraph">자세한 내용은 을 참조하십시오 <block ref="dd39ef1fcc2e17fe1fe509b7ac2d5dea" category="inline-link-macro-rx"></block>.</block>
  <block id="5b3ae76175242b9c0c63ba5668657f49" category="admonition">NetApp 솔루션에 BeeGFS를 구축하는 데 다양한 단계가 포함되므로 NetApp에서는 수동으로 솔루션 구축을 지원하지 않습니다.</block>
  <block id="6201cef3e5bb8f42f2aa1876b8c1f544" category="section-title">BeeGFS 구성 요소에 대한 구성 프로필입니다</block>
  <block id="3c411e2f06cd1b5275d2be84bb18a641" category="paragraph">배포 절차는 다음과 같은 구성 프로파일을 다룹니다.</block>
  <block id="3c1ad21a1c1a2804f8ace80b84822bfe" category="list-text">관리, 메타데이터 및 스토리지 서비스를 포함하는 하나의 기본 구성 요소입니다.</block>
  <block id="416ad52da618754efb3680e957b1a048" category="list-text">메타데이터와 스토리지 서비스가 포함된 두 번째 구성 요소입니다.</block>
  <block id="11047a79bd1eab4d52ba658a48a430e8" category="list-text">스토리지 서비스만 포함하는 세 번째 구성 요소입니다.</block>
  <block id="886066871646e69724c15beede051aa6" category="paragraph">이러한 프로필을 통해 NetApp BeeGFS 구성 요소에 대한 권장 구성 프로필 전체 범위를 볼 수 있습니다. 각 구축에 필요한 메타데이터 및 스토리지 구성 요소 수 또는 스토리지 서비스 전용 구성 요소는 용량 및 성능 요구사항에 따라 절차에 따라 달라질 수 있습니다.</block>
  <block id="20cf8ff34f34ae23669e586d1092a0f9" category="section-title">배포 단계 개요</block>
  <block id="9d863a0564ad86180bde2b2a6c27a6ed" category="paragraph">배포에는 다음과 같은 고급 작업이 포함됩니다.</block>
  <block id="fd2f8c173ade715231c21c932686e38b" category="list-title">하드웨어 구축</block>
  <block id="f08d36149d715ffbb8eca9f7159e0d27" category="list-text">각 구성 요소를 물리적으로 조립합니다.</block>
  <block id="abd55e01ead6dac45d997ad9c82c8019" category="inline-link-macro">하드웨어 구축</block>
  <block id="65353eb96f13d02029086d1790108e3c" category="list-text">랙 및 케이블 하드웨어. 자세한 절차는 를 참조하십시오 <block ref="19367e6e5e194f2806703eb905741326" category="inline-link-macro-rx"></block>.</block>
  <block id="b9205e876aa43217d9358621cf2c6187" category="list-title">소프트웨어 구축</block>
  <block id="359f84c66084d8c8c9d4cb7ca3945bcd" category="inline-link-macro">파일 및 블록 노드 설정</block>
  <block id="f8367dab28e2315251df9dcf227916b5" category="list-text"><block ref="4cfaa56cb8da11f04e7ee8ae6dd86bcc" category="inline-link-macro-rx"></block>.</block>
  <block id="ee63db10faeceba4efb3b03145e0ec26" category="list-text">파일 노드에서 BMC IP를 구성합니다</block>
  <block id="aa51221099b00aa6e09e3cb6b1b03f47" category="list-text">지원되는 운영 체제를 설치하고 파일 노드에서 관리 네트워킹을 구성합니다</block>
  <block id="a75b117cd8d7af9205b2185d8afb8537" category="list-text">블록 노드에서 관리 IP를 구성합니다</block>
  <block id="14f10d91a4d4d076d9f025fdb6134949" category="inline-link-macro">Ansible 제어 노드를 설정합니다</block>
  <block id="b81f7e6126c9f5040f05685e56e57af1" category="list-text"><block ref="6848fc9a1ed48359bab6d9326922d03c" category="inline-link-macro-rx"></block>.</block>
  <block id="51d961299f8aa9bb882574aae2a219eb" category="inline-link-macro">성능을 위해 시스템 설정을 조정합니다</block>
  <block id="9312585e52fd3b0a0898c7f73fdfd8cc" category="list-text"><block ref="dbe1843153b6696d3dd846d3a25ea7b2" category="inline-link-macro-rx"></block>.</block>
  <block id="2903652ee31835883feeb469228b4406" category="inline-link-macro">Ansible 인벤토리를 작성합니다</block>
  <block id="914b8eb4568f7c438e1d415af01c2787" category="list-text"><block ref="dbbcb9482f49ee969cddb7f10864cbd0" category="inline-link-macro-rx"></block>.</block>
  <block id="c8f38adfaba8270e793616e0556571c7" category="inline-link-macro">BeeGFS 구성 요소에 대한 Ansible 인벤토리를 정의합니다</block>
  <block id="2640957ad14de18b2d308da5e116b4a0" category="list-text"><block ref="56ee4018bb6227ffe39900ebf12f2472" category="inline-link-macro-rx"></block>.</block>
  <block id="d21cb96c35176f0f0ea13876f354d072" category="inline-link-macro">Ansible을 사용하여 BeeGFS 구축</block>
  <block id="a8169193bd5718bbe78111b3a1f874d7" category="list-text"><block ref="dffbd1bc941e2f4395de7cba04c6653b" category="inline-link-macro-rx"></block>.</block>
  <block id="096a6674c1f4ef681d88a6eb229299b7" category="inline-link-macro">BeeGFS 클라이언트를 구성합니다</block>
  <block id="f159952d71e33cd0a1ffbb2bcc4ce2ad" category="list-text"><block ref="75197807ccb18c9f99e8f2a2a3443aea" category="inline-link-macro-rx"></block>.</block>
  <block id="d6dd015562e1d088d87d28007ecfa541" category="admonition">배포 절차에는 텍스트를 파일로 복사해야 하는 몇 가지 예제가 포함되어 있습니다. 특정 배포에 대해 수정하거나 수정할 수 있는 모든 사항에 대해 "#" 또는 "//" 문자로 표시된 인라인 코멘트에 세심한 주의를 기울이십시오. 예를 들어, ``begfs_ha_ntp_server_pool:# 이것은 설명의 예입니다! "pool 0.pool.ntp.org iburst maxsources 3" - "pool 1.pool.ntp.org iburst maxsources 3"</block>
  <block id="d8ca15234a274a841f06a1d429141054" category="summary">각 서버의 BMC(베이스보드 관리 컨트롤러)에서 네트워킹을 구성하고 각 컨트롤러의 관리 포트를 구성합니다.</block>
  <block id="1cfd8029b1372ddacb436890446b43fd" category="doc">파일 노드 및 블록 노드 설정</block>
  <block id="d900235d99f416c3bfda0461cbb71f26" category="paragraph">대부분의 소프트웨어 구성 작업은 NetApp에서 제공하는 Ansible 컬렉션을 사용하여 자동화되지만, 각 서버의 BMC(베이스보드 관리 컨트롤러)에서 네트워킹을 구성하고 각 컨트롤러의 관리 포트를 구성해야 합니다.</block>
  <block id="02f510b4f0f01c83fb0898c7c21472f3" category="section-title">파일 노드 설정</block>
  <block id="58ee770c560ec650edbb0731c6882d53" category="list-text">각 서버의 BMC(베이스보드 관리 컨트롤러)에서 네트워킹을 구성합니다.</block>
  <block id="75ae096871a25daf3dcd5da902c66ecf" category="inline-link">Lenovo ThinkSystem 설명서</block>
  <block id="501998f9bebe4eeda8377a94578e9255" category="paragraph">검증된 Lenovo SR665 파일 노드의 네트워킹을 구성하는 방법은 를 참조하십시오<block ref="3a3ba9924e08a04d2eb4947b4cdb2550" category="inline-link-rx"></block>.</block>
  <block id="0c112c89dd8c3ce2b92d5e4844ea4641" category="admonition">서비스 프로세서라고도 하는 베이스보드 관리 컨트롤러(BMC)는 다양한 서버 플랫폼에 내장되어 운영 체제가 설치되어 있지 않거나 액세스할 수 없는 경우에도 원격 액세스를 제공할 수 있는 대역외 관리 기능의 일반 이름입니다. 공급업체는 일반적으로 고유한 브랜딩으로 이 기능을 마케팅합니다. 예를 들어, Lenovo SR665에서 BMC는 _Lenovo XClarity Controller(XCC)_라고 합니다.</block>
  <block id="290a84841d7341364c4abf862a74583f" category="list-text">최대 성능을 위해 시스템 설정을 구성합니다.</block>
  <block id="04c7f6322804081c61ca0d88cef85904" category="paragraph">UEFI 설정(이전의 BIOS)을 사용하거나 많은 BMC에서 제공하는 Redfish API를 사용하여 시스템 설정을 구성합니다. 시스템 설정은 파일 노드로 사용되는 서버 모델에 따라 달라집니다.</block>
  <block id="354f37da23eacae1fc163775964a0a2e" category="paragraph">검증된 Lenovo SR665 파일 노드에 대한 시스템 설정을 구성하는 방법은 을 참조하십시오 <block ref="dbe1843153b6696d3dd846d3a25ea7b2" category="inline-link-macro-rx"></block>.</block>
  <block id="7e57b24d8418675e1eb9185b3a783ef7" category="list-text">Red Hat 8.4를 설치하고 Ansible 제어 노드의 SSH 연결을 포함하여 운영 체제를 관리하는 데 사용되는 호스트 이름과 네트워크 포트를 구성합니다.</block>
  <block id="63b34e32fcac1724c46edd575672332b" category="paragraph">지금은 InfiniBand 포트에 IP를 구성하지 마십시오.</block>
  <block id="e9074e57167186919a163cd099187dd0" category="admonition">엄밀히 요구되지는 않지만, 이후의 섹션에서는 호스트 이름이 순차적으로 번호가 매겨진 것으로 간주하고(예: h1-hn) 홀수 호스트와 짝수 번호의 호스트에서 완료해야 하는 작업을 참조합니다.</block>
  <block id="0123fb5bcbcd68deb7c43ec913e70705" category="inline-link">RHEL 시스템을 등록하고 가입하는 방법</block>
  <block id="29f7e22c9a0b8d15ea802eee7a5e07cf" category="inline-link">업데이트 제한 방법</block>
  <block id="da5ddad82ac3e5b8ada040f6f5d0b4b1" category="list-text">RedHat 서브스크립션 관리자를 사용하여 공식 Red Hat 리포지토리에서 필수 패키지 설치를 허용하고 지원되는 Red Hat 버전('Ssubscription-manager release-set=8.4')으로 업데이트를 제한하려면 시스템을 등록하고 가입합니다. 자세한 내용은 을 참조하십시오<block ref="2e2e1be81972e19947d90393d5319b6e" category="inline-link-rx"></block> 및 <block ref="bbd834e2960f33a50fb102fd4d31a6d9" category="inline-link-rx"></block>.</block>
  <block id="577885e812bad7e4780317a271722339" category="list-text">고가용성을 위해 필요한 패키지가 포함된 Red Hat 리포지토리를 활성화합니다.</block>
  <block id="3c438be737391744e2fed6f73c418638" category="inline-link-macro">기술 요구 사항</block>
  <block id="f12bdbd9e0ff4f2d314f49b8ae9d6e79" category="list-text">모든 ConnectX-6 HCA 펌웨어를 에서 권장하는 버전으로 업데이트합니다 <block ref="27ecbcefd12957257b84a6d4c5608591" category="inline-link-macro-rx"></block>.</block>
  <block id="de2787072a70ede6b3c4b90ff28fe789" category="inline-link">mlxup - 업데이트 및 쿼리 유틸리티</block>
  <block id="febfb51b621938c49980eee52ab6a373" category="section-title">블록 노드 설정</block>
  <block id="1dab115fdeed11b46ad9a32f690cfc8a" category="paragraph">각 컨트롤러의 관리 포트를 구성하여 EF600 블록 노드를 설정합니다.</block>
  <block id="0631592349fc286da7627270b9c9b359" category="list-text">각 EF600 컨트롤러의 관리 포트를 구성합니다.</block>
  <block id="3f7c08d9f511dbd36a44bc681e25e3bf" category="inline-link">E-Series 문서 센터 를 참조하십시오</block>
  <block id="83398f0ded44dc933df951171f29b604" category="paragraph">포트 구성에 대한 지침은 로 이동하십시오<block ref="4719a190e5f3bfbda84ab0e6295af1ef" category="inline-link-rx"></block>.</block>
  <block id="a1cdd0715dd7993c1664eea6d7f39810" category="list-text">필요에 따라 각 시스템의 스토리지 어레이 이름을 설정합니다.</block>
  <block id="6c8f452018d59ce25e69f9d3f8851b32" category="paragraph">이름을 설정하면 이후 섹션에서 각 시스템을 쉽게 참조할 수 있습니다. 어레이 이름 설정에 대한 지침은 로 이동하십시오<block ref="4719a190e5f3bfbda84ab0e6295af1ef" category="inline-link-rx"></block>.</block>
  <block id="561abcc4bd5f30a9d5ee1e4c64d9a10d" category="admonition">엄밀히 요구되지는 않지만, 후속 주제는 스토리지 배열 이름이 순차적으로 번호가 매겨진 것으로 간주하고(예: C1-CN) 홀수 대 짝수 번호의 시스템에서 완료해야 하는 단계를 참조합니다.</block>
  <block id="1b6582c92d5f0e47bd102f2e16686662" category="summary">구축을 시작하기 전에, Ansible을 사용하여 2세대 BeeGFS 구성 요소 설계를 사용하여 NetApp 솔루션에서 BeeGFS를 구성 및 구축하는 방법을 이해해야 합니다.</block>
  <block id="91177a5a4b0c27f810e6deb9395eef4a" category="inline-link">NetApp E-Series BeeGFS GitHub를 참조하십시오</block>
  <block id="489a8841f96385c3fca8ff239dc24250" category="paragraph">Ansible 인벤토리는 파일 및 블록 노드의 구성을 정의하며 구축할 BeeGFS 파일 시스템을 나타냅니다. 인벤토리는 원하는 BeeGFS 파일 시스템을 설명하는 호스트, 그룹 및 변수를 포함합니다. 샘플 재고는 에서 다운로드할 수 있습니다<block ref="5f5a4f2bb780d1d47d6a1c5865c757e8" category="inline-link-rx"></block>.</block>
  <block id="2b030b2e370bebb88648070cda0b66eb" category="section-title">Ansible 모듈 및 역할</block>
  <block id="2c237568ac6f7bc2fd09645044287519" category="paragraph">Ansible 인벤토리에서 설명한 구성을 적용하려면 NetApp E-Series Ansible 컬렉션에서 제공하는 다양한 Ansible 모듈 및 역할, 특히 BeeGFS HA 7.2 역할(에서 제공)을 사용하십시오<block ref="aa2af16a93b1d617ca7c38eef1d0c556" category="inline-link-rx"></block>)를 구축하는 것이 좋습니다.</block>
  <block id="27633c2a48532dabf935531ba52193df" category="paragraph">NetApp E-Series Ansible 컬렉션에서 각 역할은 NetApp 솔루션 기반의 BeeGFS를 완벽하게 구축하는 데 있습니다. 이 역할은 NetApp E-Series SANtricity, 호스트 및 BeeGFS 컬렉션을 사용하여 HA(High Availability)를 통해 BeeGFS 파일 시스템을 구성할 수 있습니다. 그런 다음 스토리지를 프로비저닝하고 매핑하고 클러스터 스토리지를 사용할 준비가 되었는지 확인할 수 있습니다.</block>
  <block id="ca467fdffa66288bc6eeca1d49467e2e" category="paragraph">역할에 맞는 심층적인 문서가 제공되지만, 구축 절차에서는 제2세대 BeeGFS 구성 요소 설계를 사용하여 NetApp 검증 아키텍처를 구축하는 데 역할을 사용하는 방법에 대해 설명합니다.</block>
  <block id="7c1be9d0f9dc743e2a1540004da3eb1d" category="admonition">Ansible에 대한 사전 경험이 사전 필수 요소가 될 수 있도록 구축 단계에서 자세한 정보를 제공하려고 하지만, Ansible 및 관련 용어에 친숙해야 합니다.</block>
  <block id="e9b6dfb59ebbe3c2a8e47b9bec2ada24" category="section-title">BeeGFS HA 클러스터의 인벤토리 레이아웃</block>
  <block id="5585bfe6d81b9366f1160e16fcf3464f" category="paragraph">Ansible 인벤토리 구조를 사용하여 BeeGFS HA 클러스터를 정의합니다.</block>
  <block id="ea969b9d9b8b0a66432c22ea23412c18" category="paragraph">이전 Ansible 경험을 가진 사람이라면 누구나 BeeGFS HA 역할이 각 호스트에 적용되는 변수(또는 팩트)를 검색하는 맞춤형 방법을 구현한다는 점을 알고 있어야 합니다. 이는 여러 서버에서 실행될 수 있는 리소스를 설명하는 Ansible 인벤토리를 작성하는 작업을 단순화하기 위해 필요합니다.</block>
  <block id="fcf695220ea603b6d461ed9aaa63c323" category="paragraph">Ansible 재고는 일반적으로 'host_vars'와 'group_vars'에 있는 파일과 특정 그룹(또는 다른 그룹에 잠재적으로 그룹)에 호스트를 할당하는 재고 .yml 파일로 구성됩니다.</block>
  <block id="927527f499c87b83ee052f9a293c0293" category="admonition">본 하위 섹션의 내용을 포함하는 파일을 만들지 마십시오. 이 내용은 예제로만 제공됩니다.</block>
  <block id="a7a48a32496dcd14ea6f94f7d89ab599" category="paragraph">이 구성은 구성 프로필을 기반으로 사전 결정됩니다. 하지만 다음과 같이 Ansible 인벤토리로 모든 내용을 레이아웃하는 방법을 전반적으로 이해해야 합니다.</block>
  <block id="9d92e1d6c46a5db6f99457758b8c71dc" category="paragraph">각 서비스에 대해 해당 구성을 설명하는 group_vars 아래에 추가 파일이 생성됩니다.</block>
  <block id="7c98bb1c0d887b40b12614cc2cce909e" category="inline-link">NetApp은 Ansible을 사용하여 BeeGFS에 대한 HA 구축을 가속화합니다</block>
  <block id="2c3ce0f08dbef62630d61052bdd46f20" category="paragraph">이 레이아웃을 통해 각 리소스에 대한 BeeGFS 서비스, 네트워크 및 스토리지 구성을 단일 위치에서 정의할 수 있습니다. BeeGFS 역할은 이러한 인벤토리 구조를 기반으로 각 파일 및 블록 노드에 필요한 구성을 집계합니다. 자세한 내용은 다음 블로그 게시물을 참조하십시오.<block ref="500a149f08c7164c80066a24197a4f46" category="inline-link-rx"></block>.</block>
  <block id="bab8955d49a06dc041f1cf99ae3c65aa" category="admonition">각 서비스의 BeeGFS 숫자 및 문자열 노드 ID는 그룹 이름을 기준으로 자동으로 구성됩니다. 따라서 그룹 이름이 고유해야 하는 일반적인 Ansible 요구 사항 외에도 BeeGFS 서비스를 나타내는 그룹은 해당 그룹이 나타내는 BeeGFS 서비스 유형에 고유한 번호로 끝나야 합니다. 예를 들어, meta_01 및 stor_01은 허용되지만 metadata_01 및 meta_01은 허용되지 않습니다.</block>
  <block id="1d62eb925570a160f6a58cd18984f578" category="summary">BeeGFS 솔루션에는 검증 테스트를 기반으로 한 성능 및 용량 사이징에 대한 권장 사항이 포함되어 있습니다.</block>
  <block id="137e4d3e0bc5586af6fc7ca9441511e1" category="doc">사이징 지침</block>
  <block id="6166a42aac4e50811124dbb35631ea78" category="paragraph">빌딩 블록 아키텍처의 목표는 특정 BeeGFS 시스템의 요구 사항을 충족하기 위해 여러 빌딩 블록을 추가하여 간편하게 사이징할 수 있는 솔루션을 구축하는 것입니다. 아래 지침에 따라 환경 요구 사항을 충족하는 데 필요한 BeeGFS 빌딩 블록의 양과 유형을 예측할 수 있습니다.</block>
  <block id="a752ca5f8ca9bd168c12fc180ff734e3" category="paragraph">이러한 추정치는 최상의 성능을 제공하는 것으로, 가상 벤치마킹 애플리케이션은 실제 애플리케이션이 사용할 수 없는 방식으로 기본 파일 시스템의 사용을 최적화하기 위해 작성 및 사용됩니다.</block>
  <block id="800f4a301937e5493aaaddfe77e10dd5" category="section-title">성능 사이징</block>
  <block id="6875300666b544ca98e406bd6ca73da1" category="paragraph">다음 표에는 권장되는 성능 사이징이 나와 있습니다.</block>
  <block id="83d4567aaaf81ff58ab394c3ad02accc" category="cell">구성 프로파일</block>
  <block id="58a15ea9e5c981b498a5c119456b9dd9" category="cell">1MiB 읽기</block>
  <block id="968dfca19c742301bc400a7c883b1594" category="cell">1MiB의 쓰기입니다</block>
  <block id="8cf5b688a1a209b630cab18001501c76" category="cell">메타데이터 + 스토리지</block>
  <block id="5d44d1f7b753dee2968cad82eef2f1dd" category="cell">62GiBps</block>
  <block id="a5a649e4dec54d9f61f1cfc632dab412" category="cell">21GiBps</block>
  <block id="dfab8e8b566f2d091e7ecb4b4d65060b" category="cell">스토리지만 해당</block>
  <block id="1d955116a3bafb864bcf6755485fce7e" category="cell">64GiBps</block>
  <block id="419cfc02b324dc7d8faefa90ed608fb0" category="inline-link">시스템 요구 사항</block>
  <block id="e618e38f89f153e374a90674c51efb8f" category="paragraph">메타데이터 용량 사이징 예상치는 "경험 규칙"을 기반으로 하며, 이 경우 500GB의 용량으로 BeeGFS에서 약 1억 5천만 개의 파일을 저장할 수 있습니다. (자세한 내용은 BeeGFS 설명서를 참조하십시오<block ref="d422b619831c270410797364c04b1fb2" category="inline-link-rx"></block>참조)</block>
  <block id="903cd75262aca9ec0b3a831bccc18869" category="paragraph">액세스 제어 목록, 디렉터리별 디렉토리 및 파일 수와 같은 기능을 사용하면 메타데이터 공간이 얼마나 빨리 소비되는지를 알 수 있습니다. 스토리지 용량 추정치는 RAID 6 및 XFS 오버헤드와 함께 사용 가능한 드라이브 용량을 고려합니다.</block>
  <block id="9490db12574d3954607c7e9d91d28809" category="section-title">메타데이터 + 스토리지 구성 요소에 대한 용량 사이징</block>
  <block id="015d2cd8138605f0cec20c9dffe04a93" category="paragraph">다음 표에는 메타데이터와 스토리지 구성 요소에 권장되는 용량 사이징이 나와 있습니다.</block>
  <block id="b897bc1ea15940ab83faf02e07b143bf" category="cell">드라이브 크기(2+2 RAID 1) 메타데이터 볼륨 그룹</block>
  <block id="fa4beb4be6de6614b0cd1460e8d33b1f" category="cell">메타데이터 용량(파일 수)</block>
  <block id="070e4137f478af27755d228dba080d41" category="cell">드라이브 크기(8 + 2 RAID 6) 스토리지 볼륨 그룹</block>
  <block id="785d80cc95b60fc3365e05e3ae013331" category="cell">스토리지 용량(파일 콘텐츠)</block>
  <block id="be3ca1ec15ca4657e5ca3ec84a561090" category="cell">1.92TB</block>
  <block id="71839d6e6fb59e239ad941d08b5e2519" category="cell">3.84TB</block>
  <block id="a98c228c0d8903ba6926546f64321cc4" category="cell">7.68TB</block>
  <block id="1f04a7c587f50d269f44d43229c966ac" category="cell">15.3TB</block>
  <block id="a966f153f6f429bbd39c3ac2390ef970" category="admonition">메타데이터 및 스토리지 구성 요소의 크기를 조정할 때 더 작은 드라이브를 메타데이터 볼륨 그룹에 사용하는 것과 스토리지 볼륨 그룹을 사용하는 것을 통해 비용을 절감할 수 있습니다.</block>
  <block id="f9fb1e607e840d5610c34a9f15da540e" category="section-title">스토리지 전용 구성 요소에 대한 용량 사이징</block>
  <block id="cd9db38cfde636fa7c304f8e67d8708d" category="paragraph">다음 표에는 스토리지 전용 구성 요소에 대한 경험 많은 용량 사이징이 나와 있습니다.</block>
  <block id="4f7d0f08c61d0cc981b973ba853e2c6f" category="cell">59.89TB</block>
  <block id="22f3cf273453d70fdc724d513005c81d" category="cell">119.80TB</block>
  <block id="e4c2850d67996ecfe5e0b56e9637a470" category="cell">251.89TB</block>
  <block id="f7c8918f0c24047e89e5842785e7b8ef" category="cell">538.55TB</block>
  <block id="3cf8b9e44b7a1eb7154f2b777094e670" category="admonition">글로벌 파일 잠금이 활성화되지 않은 경우 기본(첫 번째) 구성 요소에서 관리 서비스를 포함할 때 발생하는 성능 및 용량 오버헤드가 최소화됩니다.</block>
  <block id="5b361b4897c4847c08b3d13bf3b66b8d" category="summary">컴퓨팅 또는 GPU 노드와 같이 BeeGFS 파일 시스템에 액세스해야 하는 모든 호스트에 BeeGFS 클라이언트를 설치하고 구성합니다. 이 작업에서는 Ansible 및 BeeGFS 컬렉션을 사용할 수 있습니다.</block>
  <block id="c855016387ccd14e80b0628a2da5609b" category="paragraph">컴퓨팅 또는 GPU 노드와 같이 BeeGFS 파일 시스템에 액세스해야 하는 모든 호스트에 BeeGFS 클라이언트를 설치하고 구성해야 합니다. 이 작업에서는 Ansible 및 BeeGFS 컬렉션을 사용할 수 있습니다.</block>
  <block id="f3a29486bed19a90f2da6d007818b427" category="list-title">단계</block>
  <block id="f4bf34ee26e45437b7b34ee3858d3f39" category="list-text">필요한 경우, Ansible 제어 노드에서 BeeGFS 클라이언트로 구성하려는 각 호스트에 대해 암호 없는 SSH를 설정합니다.</block>
  <block id="c9793ac6c6a163b585094181979efe25" category="paragraph">'ssh-copy-id &lt;user&gt;@&lt;HOSTNAME_OR_IP&gt;'를 참조하십시오</block>
  <block id="05c8acf59a637c421ef21a4a37d674de" category="list-text">'host_vars/'에서 다음 내용으로 이름이 '&lt;HOSTNAME&gt;.yml'인 각 BeeGFS 클라이언트에 대한 파일을 만들어 사용자 환경에 맞는 올바른 정보로 자리 표시자 텍스트를 채웁니다.</block>
  <block id="eb92eeb67c4903777d624fd51e30acfa" category="admonition">현재 각 클라이언트에서 두 개의 InfiniBand 인터페이스를 구성해야 하며, 각 인터페이스는 두 스토리지 IPoIB 서브넷에 하나씩 있어야 합니다. 여기에 나열된 각 BeeGFS 서비스에 대해 서브넷 및 권장 범위의 예를 사용하는 경우 클라이언트는 "100.127.1" 범위에서 하나의 인터페이스를 구성해야 합니다. 100.127.99.255까지, 100.128.1로. 0에서 100.128까지. 99.255".</block>
  <block id="ca6b4577e851d5587e19a3d017db68b1" category="list-text">새 파일 'client_inventory.yml'를 만든 다음 맨 위에 다음 매개 변수를 입력합니다.</block>
  <block id="ec6e88f08b026e04d1ce5f5f31493b21" category="inline-link">Ansible Vault로 콘텐츠 암호화</block>
  <block id="d424a4948912165baf5c9641ad4de044" category="admonition">암호를 일반 텍스트로 저장하지 마십시오. 대신 Ansible Vault를 사용하십시오(의 Ansible 설명서 참조)<block ref="69d38d4b5deda302461f6461c5317006" category="inline-link-rx"></block>) 또는 플레이북이 실행될 때 '--Ask-when-pass' 옵션을 사용합니다.</block>
  <block id="8f27eda73b5d4e7594b05bed1b90a053" category="list-text">'client_inventory.yml' 파일에서 Beegfs_clients' 그룹 아래에 BeeGFS 클라이언트로 구성해야 하는 모든 호스트를 나열한 다음 BeeGFS 클라이언트 커널 모듈을 구축하는 데 필요한 추가 구성을 지정합니다.</block>
  <block id="42d868a1eb5776ce2eb9b95938bcc056" category="inline-link">RDMA 지원</block>
  <block id="675bf44585d9e9ed71a38bde5f37fb5f" category="admonition">Mellanox OFED 드라이버를 사용하는 경우, "begfs_client_OFED_include_path"가 Linux 설치를 위한 올바른 "헤더 포함 경로"를 가리키는지 확인하십시오. 자세한 내용은 의 BeeGFS 설명서를 참조하십시오<block ref="ad551773fffeead9219b565416da2397" category="inline-link-rx"></block>.</block>
  <block id="b9d3c4e1c18127cf36ad951b208d45bb" category="list-text">client_inventory.yml 파일에 미리 정의된 VAR의 하단에 마운트할 BeeGFS 파일 시스템을 나열합니다.</block>
  <block id="0ebb92016a1cd310802bb6e22bcd491c" category="admonition">Beegfs_client_config는 테스트된 설정을 나타냅니다. 모든 옵션에 대한 종합적인 개요는 netapp_eseries.beegfs` 컬렉션의 "begfs_client" 역할에 포함된 설명서를 참조하십시오. 여기에는 여러 개의 BeeGFS 파일 시스템을 마운트하거나 동일한 BeeGFS 파일 시스템을 여러 번 마운트하는 방법에 대한 세부 정보가 포함됩니다.</block>
  <block id="853c95fff114a0396695a5a34c4f78f1" category="list-text">새 'client_Playbook.yml' 파일을 만든 후 다음 매개 변수를 입력합니다.</block>
  <block id="8ae73b3fcef5fc8f1a73e62c987915e6" category="admonition">필요한 IB/RDMA 드라이버와 IP를 해당 IPoIB 인터페이스에 이미 설치한 경우 'NetApp_eseries.host' 수집 및 'IPoIB' 역할을 가져오지 마십시오.</block>
  <block id="598ee1856218e19bf329d8bece215061" category="list-text">클라이언트를 설치 및 구축하고 BeeGFS를 마운트하려면 다음 명령을 실행합니다.</block>
  <block id="999070faf3729384137acf10348ed589" category="list-text">BeeGFS 파일 시스템을 운영 환경에 배치하기 전에 모든 클라이언트에 로그인하고 "begfs-fsck--checkfs"를 실행하여 모든 노드에 연결할 수 있고 보고된 문제가 없는지 확인하는 것이 좋습니다.</block>
  <block id="883ccbea6264c3d9c8ea56267b290a0a" category="summary">NetApp 기반 BeeGFS에 대한 소프트웨어 구성에는 BeeGFS 네트워크 구성 요소, EF600 블록 노드, BeeGFS 파일 노드, 리소스 그룹, BeeGFS 서비스가 포함됩니다.</block>
  <block id="e366b0b441e75fcafac2db7ff979a799" category="doc">소프트웨어 구성</block>
  <block id="dea1b03288253149cb4c55f3c4f10e3e" category="section-title">BeeGFS 네트워크 구성</block>
  <block id="391f99769ce2b9374f0421ace7ce5ac5" category="paragraph">BeeGFS 네트워크 구성은 다음과 같은 구성 요소로 이루어집니다.</block>
  <block id="f05f92f283e258444df8e73ac9508c74" category="list-text">* 부동 IP * 부동 IP는 동일한 네트워크의 모든 서버로 동적으로 라우팅될 수 있는 일종의 가상 IP 주소입니다. 여러 서버가 동일한 부동 IP 주소를 소유할 수 있지만, 특정 시간에 한 서버에서만 활성화될 수 있습니다.</block>
  <block id="76a7e91177d008d5a202ef507a9049d7" category="paragraph">각 BeeGFS 서버 서비스에는 BeeGFS 서버 서비스의 실행 위치에 따라 파일 노드 간에 이동할 수 있는 고유한 IP 주소가 있습니다. 이러한 부동 IP 구성을 통해 각 서비스가 다른 파일 노드로 독립적으로 페일오버할 수 있습니다. 클라이언트는 특정 BeeGFS 서비스의 IP 주소를 알고 있으면 됩니다. 이 경우 현재 해당 서비스를 실행 중인 파일 노드를 알 필요가 없습니다.</block>
  <block id="527f436644c629cc1f2330d74c5c29b4" category="list-text">* BeeGFS 서버 다중 홈 구성 * 솔루션의 밀도를 높이기 위해 각 파일 노드에는 동일한 IP 서브넷에 구성된 IP를 가진 여러 스토리지 인터페이스가 있습니다.</block>
  <block id="5a19238d05fdcdb09e439e41a0a94349" category="paragraph">기본적으로 하나의 인터페이스에 대한 요청은 동일한 서브넷에 있는 경우 다른 인터페이스에서 응답할 수 있기 때문에 Linux 네트워킹 스택에서 이 구성이 예상대로 작동하는지 확인하기 위해 추가 구성이 필요합니다. 다른 단점 외에도 이 기본 동작으로 인해 RDMA 연결을 적절하게 설정하거나 유지할 수 없습니다.</block>
  <block id="e7a28f6c997a9c0eba41eb574b5f829c" category="paragraph">Ansible 기반 배포에서는 부동 IP가 시작 및 중지되는 시기와 함께 RP(역방향 경로) 및 ARP(주소 해상도 프로토콜) 동작 조임을 처리하고, 다중 홈 네트워크 구성이 제대로 작동하도록 해당 IP 경로 및 규칙을 동적으로 생성합니다.</block>
  <block id="99e50b7bb7e3ca73eb910eaf99c6f100" category="list-text">* BeeGFS 클라이언트 다중 레일 구성 * _Multi-RAIL_은 애플리케이션이 여러 개의 독립적인 네트워크 "레일"을 사용하여 성능을 향상시키는 기능을 의미합니다.</block>
  <block id="24cb2caf398043c3ad552915f0ec2b22" category="paragraph">BeeGFS는 RDMA 연결을 위해 RDMA를 사용할 수 있지만, BeeGFS는 IPoIB를 사용하여 RDMA 연결 검색 및 설정을 간소화합니다. BeeGFS 클라이언트가 여러 InfiniBand 인터페이스를 사용할 수 있도록 하려면 각 클라이언트를 다른 서브넷에 있는 IP 주소로 구성한 다음 각 서브넷에 있는 BeeGFS 서버 서비스의 절반에 대해 기본 인터페이스를 구성할 수 있습니다.</block>
  <block id="89b4732ecad8d523a7b684af09ad56ee" category="paragraph">다음 다이어그램에서는 밝은 녹색으로 강조 표시된 인터페이스가 하나의 IP 서브넷(예: 100.127.0.0/16)에 있고 어두운 녹색 인터페이스는 다른 서브넷(예: 100.128.0.0/16)에 있습니다.</block>
  <block id="12ec3f7db1a39d49d76e159a6fc9be24" category="paragraph">다음 그림에서는 여러 BeeGFS 클라이언트 인터페이스에서 트래픽의 균형을 조정하는 방법을 보여 줍니다.</block>
  <block id="8336bf936a644f2a0962fc710a65d3db" category="paragraph"><block ref="8336bf936a644f2a0962fc710a65d3db" category="inline-image-macro-rx" type="image"></block></block>
  <block id="02eef1a6d9aefa452755edb315057e27" category="paragraph">BeeGFS의 각 파일은 일반적으로 여러 스토리지 서비스에 걸쳐 스트라이핑되기 때문에 다중 레일 구성을 통해 클라이언트는 단일 InfiniBand 포트보다 더 많은 처리량을 달성할 수 있습니다. 예를 들어, 다음 코드 샘플은 클라이언트가 두 인터페이스 간에 트래픽의 균형을 조정할 수 있도록 하는 일반적인 파일 스트라이핑 구성을 보여 줍니다.</block>
  <block id="7a11ff2c7aa2ff0eccecba650f1db9f5" category="paragraph">두 개의 IPoIB 서브넷을 사용하는 것은 논리적인 구분입니다. 필요한 경우 단일 물리적 InfiniBand 서브넷(스토리지 네트워크)을 사용할 수 있습니다.</block>
  <block id="315faf76d806cf96ff685ed2e65a9d16" category="inline-link">BeeGFS RDMA 지원</block>
  <block id="96002ab5a7c353b76ef0cc2e390f7131" category="admonition">단일 IPoIB 서브넷에서 여러 IB 인터페이스를 사용할 수 있도록 BeeGFS 7.3.0에 멀티 레일 지원이 추가되었습니다. BeeGFS 7.3.0을 GA 전에 NetApp 기반 BeeGFS 솔루션의 설계가 개발되었으며, BeeGFS 클라이언트에서 두 개의 IB 인터페이스를 사용하는 두 개의 IP 서브넷을 보여 줍니다. 다중 IP 서브넷 접근 방식의 한 가지 장점은 BeeGFS 클라이언트 노드에서 멀티호밍을 구성할 필요가 없기 때문입니다(자세한 내용은 참조)<block ref="bb2f67f854c27129a1f13b908e56ca65" category="inline-link-rx"></block>)를 클릭합니다.</block>
  <block id="b28b500a27afaa858536ee53a4c02d91" category="section-title">EF600 블록 노드 구성</block>
  <block id="6e88eb560b5c117f0226888b924af1c5" category="paragraph">블록 노드는 동일한 드라이브 세트에 대한 공유 액세스를 가진 2개의 액티브/액티브 RAID 컨트롤러로 구성됩니다. 일반적으로 각 컨트롤러는 시스템에 구성된 볼륨의 절반을 소유하지만 필요에 따라 다른 컨트롤러를 인수할 수 있습니다.</block>
  <block id="674757e2095af366602187ca856f8ec4" category="paragraph">파일 노드의 다중 경로 소프트웨어는 각 볼륨에 대한 최적화된 활성 경로를 결정하고 케이블, 어댑터 또는 컨트롤러에 장애가 발생할 경우 대체 경로로 자동으로 이동합니다.</block>
  <block id="458cd7cdbda7e7a38853eae8ce0e9662" category="paragraph">다음 다이어그램은 EF600 블록 노드의 컨트롤러 레이아웃을 보여 줍니다.</block>
  <block id="896dfe770f6add65f01e361850b05b91" category="paragraph"><block ref="896dfe770f6add65f01e361850b05b91" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b4adca73c8e2d619dedc4eb6a42bc966" category="paragraph">공유 디스크 HA 솔루션을 지원하기 위해 볼륨은 두 파일 노드에 매핑되므로 필요에 따라 서로 테이크오버할 수 있습니다. 다음 다이어그램은 BeeGFS 서비스 및 기본 볼륨 소유권이 최대 성능을 위해 구성되는 방법의 예를 보여 줍니다. 각 BeeGFS 서비스 왼쪽에 있는 인터페이스는 클라이언트 및 기타 서비스가 연락하는 데 사용하는 기본 인터페이스를 나타냅니다.</block>
  <block id="3a7342602381a86e862da535061f4da7" category="paragraph"><block ref="3a7342602381a86e862da535061f4da7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d1bff1512ad9e19d6469659f6a916a7e" category="paragraph">앞의 예에서 클라이언트 및 서버 서비스는 인터페이스 i1b를 사용하여 스토리지 서비스 1과 통신하는 것을 선호합니다. 스토리지 서비스 1은 인터페이스 i1a를 기본 경로로 사용하여 첫 번째 블록 노드의 컨트롤러 A에 있는 해당 볼륨(storage_tgt_101, 102)과 통신합니다. 이 구성은 InfiniBand 어댑터에서 사용할 수 있는 양방향 PCIe 대역폭을 완벽하게 사용하고 PCIe 4.0에서 사용할 수 있는 것보다 듀얼 포트 HDR InfiniBand 어댑터에서 더 나은 성능을 제공합니다.</block>
  <block id="f4fa0385d373373f4ab191231ead5909" category="section-title">BeeGFS 파일 노드 구성</block>
  <block id="5e2d5eb9f991b81a298fb57212c715fe" category="paragraph">BeeGFS 파일 노드는 HA(High-Availability) 클러스터로 구성되어 여러 파일 노드 간에 BeeGFS 서비스의 페일오버를 지원합니다.</block>
  <block id="f409d0a0c329860646597bbcc45fcc4b" category="inline-link">고가용성 애드온을 위한 Red Hat 교육</block>
  <block id="48a9bfc91c9cb5a8f6f7fc37080d3b95" category="paragraph">HA 클러스터 설계는 널리 사용되는 두 가지 Linux HA 프로젝트, 즉 클러스터 멤버십을 위한 Corosync 및 클러스터 리소스 관리를 위한 Pacemaker를 기반으로 합니다. 자세한 내용은 을 참조하십시오<block ref="a896e9cb42c24f9ab5c574f54ad83b08" category="inline-link-rx"></block>.</block>
  <block id="79b70ba13b6d273b53c66d816a15830d" category="paragraph">NetApp은 클러스터가 지능적으로 BeeGFS 리소스를 시작하고 모니터링할 수 있도록 여러 OCF(Open Cluster Framework) 리소스 에이전트를 저술하고 확장했습니다.</block>
  <block id="ff07f4dbc22a6f0ecb4a11bfb6136d40" category="section-title">BeeGFS HA 클러스터</block>
  <block id="7a189557128751d94f2d8bca38ccf462" category="paragraph">일반적으로, HA를 사용하거나 사용하지 않고 BeeGFS 서비스를 시작할 때 다음과 같은 몇 가지 리소스를 사용해야 합니다.</block>
  <block id="3f1f71800ded6b59769a66de67dd7d86" category="list-text">서비스에 연결할 수 있는 IP 주소이며 일반적으로 Network Manager에서 구성합니다.</block>
  <block id="03eb5c90128e244e904f61d22569b4af" category="list-text">BeeGFS에서 데이터를 저장하기 위한 타겟으로 사용되는 기본 파일 시스템입니다.</block>
  <block id="510de0f837e4aacf9e6eb3c08926bcff" category="paragraph">일반적으로 이러한 항목은 '/etc/fstab'에 정의되어 있으며 systemd에 의해 마운트됩니다.</block>
  <block id="49990dbe44b62019deed5be9f5c437a3" category="list-text">다른 리소스가 준비되면 BeeGFS 프로세스를 시작하는 시스템 서비스입니다.</block>
  <block id="4f26c3922778ca3d5247b1281f6843af" category="paragraph">추가 소프트웨어가 없으면 이러한 리소스는 단일 파일 노드에서만 시작됩니다. 따라서 파일 노드가 오프라인이 되면 BeeGFS 파일 시스템의 일부를 액세스할 수 없습니다.</block>
  <block id="c60a1b018b03670c1a1a93baf9da5d45" category="paragraph">여러 노드에서 각 BeeGFS 서비스를 시작할 수 있으므로, Pacemaker는 각 서비스와 종속 리소스가 한 번에 하나의 노드에서만 실행되도록 해야 합니다. 예를 들어, 두 노드가 동일한 BeeGFS 서비스를 시작하려고 하면 둘 다 기본 타겟의 동일한 파일에 쓰려고 하면 데이터 손상이 발생할 위험이 있습니다. 이러한 시나리오를 피하기 위해, 페이스 메이커의 Corosync를 사용하여 전체 클러스터의 상태를 모든 노드에 걸쳐 안정적으로 유지하고 쿼럼을 설정합니다.</block>
  <block id="a96d4ad8c651d8ff21de193227e20f4d" category="paragraph">클러스터에서 장애가 발생하면 심장박동기가 반응하여 다른 노드에서 BeeGFS 리소스를 다시 시작합니다. 일부 시나리오에서는 심박조율기가 장애가 발생한 원래 노드와 통신하지 못하여 리소스가 중지되었는지 확인할 수 없습니다. 다른 곳에서 BeeGFS 리소스를 다시 시작하기 전에 노드가 다운되었는지 확인하려면 심장박동기가 장애가 있는 노드를 분리합니다. 즉, 전원을 제거하는 것이 좋습니다.</block>
  <block id="ad22605bb834d1c650f3b2f1e5c76401" category="paragraph">심박조율기가 PDU(Power Distribution Unit)를 사용하여 노드를 펜싱하거나 서버 BMC(Baseboard Management Controller)를 Redfish와 같은 API와 함께 사용하여 오픈 소스 펜싱 에이전트를 많이 사용할 수 있습니다.</block>
  <block id="05273fb3cfbaf5190eee8cfc0c3e0597" category="paragraph">BeeGFS가 HA 클러스터에서 실행 중인 경우 모든 BeeGFS 서비스 및 기본 리소스는 리소스 그룹의 페이스 메이커를 통해 관리됩니다. 각 BeeGFS 서비스 및 해당 서비스가 의존하는 리소스가 리소스 그룹으로 구성되어 리소스가 올바른 순서로 시작 및 중지되어 동일한 노드에 배치됩니다.</block>
  <block id="de25b213ff1f6f931a4d9c0f59bbed69" category="paragraph">각 BeeGFS 리소스 그룹에 대해 심장박동기는 특정 노드에서 BeeGFS 서비스에 더 이상 액세스할 수 없을 때 장애 조건을 감지하고 페일오버를 지능적으로 트리거하는 사용자 지정 BeeGFS 모니터링 리소스를 실행합니다.</block>
  <block id="e33abb1ba19f563eaa662796e8b3021b" category="paragraph">다음 그림에서는 심장박동기 제어 BeeGFS 서비스 및 종속성을 보여 줍니다.</block>
  <block id="bedf97f40f223046eb65b7acad7c0a92" category="paragraph"><block ref="bedf97f40f223046eb65b7acad7c0a92" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5346cef6f7de3aac02ebdfc1ae9b6f27" category="inline-link">멀티 모드에 대한 BeeGFS 문서</block>
  <block id="c4ae8913dc1f6c9fed7961516b16defd" category="admonition">동일한 유형의 여러 BeeGFS 서비스를 동일한 노드에서 시작할 수 있도록 다중 모드 구성 방법을 사용하여 BeeGFS 서비스를 시작하도록 페이스 메이커를 구성합니다. 자세한 내용은 를 참조하십시오<block ref="bc179f675bb7a303402ecb902ab09448" category="inline-link-rx"></block>.</block>
  <block id="553c30108a127bc2c66537e58970be9e" category="paragraph">BeeGFS 서비스는 여러 노드에서 시작할 수 있어야 하므로 각 서비스의 구성 파일('/etc/beegfs'에 있음)은 해당 서비스의 BeeGFS 타겟으로 사용되는 E-Series 볼륨 중 하나에 저장됩니다. 따라서 특정 BeeGFS 서비스에 대한 데이터와 함께 서비스를 실행해야 하는 모든 노드에서 해당 구성을 액세스할 수 있습니다.</block>
  <block id="39f54b8b12af6ae0edd74b4db43d9959" category="summary">NetApp의 BeeGFS에 대한 하드웨어 구성에는 파일 노드 및 네트워크 케이블 연결이 포함됩니다.</block>
  <block id="a80f40a4cf172e4461c613d2afc0bade" category="doc">하드웨어 구성</block>
  <block id="a6f76304e97d4b2df31a130d24073f88" category="section-title">파일 노드 구성</block>
  <block id="8e9473694bc8ee293e1f6c4f730ab4ed" category="paragraph">파일 노드에는 동일한 수의 PCIe 슬롯 및 메모리에 대한 로컬 액세스를 포함하는 별도의 NUMA 존으로 구성된 2개의 CPU 소켓이 있습니다.</block>
  <block id="81fb4a697d99bad44c068f68db513e26" category="paragraph">InfiniBand 어댑터는 적절한 PCI 라이저 또는 슬롯에 설치되어야 사용 가능한 PCIe 레인 및 메모리 채널에 걸쳐 작업 부하가 분산됩니다. 개별 BeeGFS 서비스에 대한 작업을 특정 NUMA 노드에 완전히 격리하여 워크로드의 균형을 조정합니다. 목표는 두 개의 독립적인 단일 소켓 서버처럼 각 파일 노드에서 유사한 성능을 얻는 것입니다.</block>
  <block id="26dc1928abfabc3027cfa2e4f0b2f57f" category="paragraph">다음 그림에서는 파일 노드 NUMA 구성을 보여 줍니다.</block>
  <block id="84d47488591b2b0cb81b407a80494c91" category="paragraph"><block ref="84d47488591b2b0cb81b407a80494c91" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cc560c8656cb52d0c2376a0dbb2ac436" category="paragraph">BeeGFS 프로세스는 사용된 인터페이스가 동일한 존에 있도록 특정 NUMA 존에 고정됩니다. 이렇게 구성하면 소켓 간 연결을 통한 원격 액세스가 필요하지 않습니다. 소켓 간 연결은 QPI 또는 GMI2 링크라고도 합니다. 최신 프로세서 아키텍처에서도 HDR InfiniBand와 같은 고속 네트워킹을 사용할 때 병목 현상이 발생할 수 있습니다.</block>
  <block id="037505dd545df2577c95982dd52a9497" category="section-title">네트워크 케이블 연결 구성</block>
  <block id="2efc6e5efcfc3424383b80badbc6f2f8" category="paragraph">구성 요소 내에서 각 파일 노드는 총 4개의 중복 InfiniBand 연결을 사용하여 2개의 블록 노드에 연결됩니다. 또한 각 파일 노드에는 InfiniBand 스토리지 네트워크에 대한 4개의 이중화된 접속이 있습니다.</block>
  <block id="c2b0d4abc479963299ef11f7007b04d9" category="paragraph">다음 그림에서 주목하십시오.</block>
  <block id="ccebd32ee2768501ecf2042e521d090c" category="list-text">녹색으로 표시된 모든 파일 노드 포트는 스토리지 패브릭에 접속하는 데 사용되며, 다른 모든 파일 노드 포트는 블록 노드에 직접 연결됩니다.</block>
  <block id="01be869a64586dc6df5d40be148742a7" category="list-text">특정 NUMA 존에 있는 2개의 InfiniBand 포트는 동일한 블록 노드의 A 및 B 컨트롤러에 연결됩니다.</block>
  <block id="92d102b77ed7526653d6ed77bc5f9297" category="list-text">NUMA 노드 0의 포트는 항상 첫 번째 블록 노드에 연결됩니다.</block>
  <block id="41d34f3f75f0a6f23825fec8c1f6b167" category="list-text">NUMA 노드 1의 포트는 두 번째 블록 노드에 연결됩니다.</block>
  <block id="058a7d9db61c859b343066aa0c6cd3c7" category="paragraph"><block ref="058a7d9db61c859b343066aa0c6cd3c7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="109d8b81996cf829eba8acc62259eaee" category="admonition">이중화 스위치가 있는 스토리지 네트워크의 경우 녹색으로 표시된 포트가 한 스위치에 연결되고 어두운 녹색으로 표시된 포트는 다른 스위치에 연결해야 합니다.</block>
  <block id="1109e0767ef0b323f02f85cdaa9a589d" category="paragraph">그림에 표시된 케이블 연결 구성을 통해 각 BeeGFS 서비스는 다음을 수행할 수 있습니다.</block>
  <block id="12e9ec8c0cb3aa87bfb400a73712d79b" category="list-text">BeeGFS 서비스를 실행 중인 파일 노드에 관계없이 동일한 NUMA 존에서 실행합니다.</block>
  <block id="488f6220ee8bab2e1e3621f7f99b598c" category="list-text">장애 발생 위치에 관계없이 프런트엔드 스토리지 네트워크와 백엔드 블록 노드에 대한 보조 최적 경로 제공</block>
  <block id="e2ae85c4e917fafc3b545710dcc3fdf1" category="list-text">블록 노드의 파일 노드 또는 컨트롤러에 유지 관리가 필요한 경우 성능 영향을 최소화합니다.</block>
  <block id="76af1dbb7a81b9258eeb702dd63164e2" category="paragraph">PCIe 양방향 대역폭을 최대한 활용하려면 각 InfiniBand 어댑터의 포트 하나를 스토리지 패브릭에 연결하고 다른 포트는 블록 노드에 연결해야 합니다. HDR InfiniBand 포트의 이론적인 최대 속도는 25GBps입니다(신호 및 기타 오버헤드는 고려하지 않음). PCIe 4.0 x16 슬롯의 최대 단일 방향 대역폭은 32GBps이며 이론적으로 50GBps 대역폭을 처리할 수 있는 이중 포트 InfiniBand 어댑터가 통합된 파일 노드를 구현할 때 잠재적인 병목 현상이 발생합니다.</block>
  <block id="33f3e0c9879fd051eb380c62267a24cf" category="paragraph">다음 그림은 전체 PCIe 양방향 대역폭을 활용하는 데 사용되는 케이블링 설계를 보여줍니다.</block>
  <block id="5a81a38e29a457f16f6a1a9146cb73de" category="paragraph"><block ref="5a81a38e29a457f16f6a1a9146cb73de" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1a72dacfce92d062255a929bbb18fc8d" category="paragraph">각 BeeGFS 서비스에 대해 동일한 어댑터를 사용하여 클라이언트 트래픽에 사용되는 기본 포트를 해당 서비스 볼륨의 기본 소유자인 블록 노드 컨트롤러의 경로와 연결합니다. 자세한 내용은 을 참조하십시오 <block ref="1ce6299bc86692b3e97783bdba904848" category="inline-link-macro-rx"></block>.</block>
  <block id="0dfb05d4ea761122194fbafcd7f3a5eb" category="summary">BeeGFS on NetApp 솔루션의 2세대 설계는 3가지 구성 요소 구성 프로필을 사용하여 검증되었습니다.</block>
  <block id="57448c4b7cf64af279b612502ae49c08" category="doc">설계 검증</block>
  <block id="dd444e75087c1912fb6b2f9435eec0ba" category="paragraph">구성 프로파일에는 다음이 포함됩니다.</block>
  <block id="ba33770125b7249843843e3524e48e5e" category="list-text">BeeGFS 관리, 메타데이터 및 스토리지 서비스를 포함한 단일 기본 구성 요소입니다.</block>
  <block id="dc0ae690014a6e4ed1d17d728fce2e3a" category="list-text">BeeGFS 메타데이터와 스토리지 구성 요소</block>
  <block id="f789cf74ad54c463cf1827c970b695c0" category="list-text">BeeGFS 스토리지 전용 구성 요소입니다.</block>
  <block id="c7dfb273d9605bd7640f597b869aef23" category="paragraph">빌딩 블록은 2개의 Mellanox Quantum InfiniBand(MQM8700) 스위치에 연결되었습니다. 10개의 BeeGFS 클라이언트도 InfiniBand 스위치에 연결되었으며 통합 벤치마크 유틸리티를 실행하는 데 사용되었습니다.</block>
  <block id="f27d4d7620b1158ad830c498a6faf1c5" category="paragraph">다음 그림에서는 NetApp 솔루션의 BeeGFS 검증을 위해 사용되는 BeeGFS 구성을 보여 줍니다.</block>
  <block id="c76715003b58d0566ea40579fbf2b849" category="paragraph"><block ref="c76715003b58d0566ea40579fbf2b849" category="inline-image-macro-rx" type="image"></block></block>
  <block id="dfa0c76fc554fa6837cfe216381eb3df" category="section-title">BeeGFS 파일 스트라이핑</block>
  <block id="73bf7a09a102bdf9e2984ff15f2e62cc" category="paragraph">병렬 파일 시스템의 이점은 여러 스토리지 대상 간에 개별 파일을 스트라이핑하는 기능입니다. 이 기능은 동일하거나 다른 기본 스토리지 시스템의 볼륨을 나타낼 수 있습니다.</block>
  <block id="f781a67c7f55c5a3d6d505e3569ff3c3" category="inline-link">스트라이핑</block>
  <block id="0102b96fad09ea07b9b6c943ac48e706" category="inline-link">스트라이핑 API</block>
  <block id="be4c29766b20870006df2b27be87994e" category="paragraph">BeeGFS에서는 디렉토리 및 파일별로 스트라이핑을 구성하여 각 파일에 사용되는 타겟 수를 제어하고 각 파일 스트라이프에 사용되는 청크 크기(또는 블록 크기)를 제어할 수 있습니다. 따라서 서비스를 재구성하거나 다시 시작할 필요 없이 파일 시스템에서 다양한 유형의 워크로드와 I/O 프로필을 지원할 수 있습니다. "begfs -ctl" 명령줄 도구 또는 스트라이핑 API를 사용하는 응용 프로그램을 사용하여 스트라이프 설정을 적용할 수 있습니다. 자세한 내용은 의 BeeGFS 설명서를 참조하십시오<block ref="d307c57bb94d8613bf23053de378d367" category="inline-link-rx"></block> 및<block ref="d53017212bcf8a78d44d2efbf061a88a" category="inline-link-rx"></block>.</block>
  <block id="706c7a765e77b694cee17941887ccaaf" category="paragraph">최상의 성능을 얻기 위해 테스트 중에 스트라이프 패턴을 조정하고 각 테스트에 사용된 매개 변수를 기록하였습니다.</block>
  <block id="a40727fe75676638a1b87009fafed260" category="section-title">IOR 대역폭 테스트: 여러 클라이언트</block>
  <block id="a4c77786e4208d299fbf0c491eb99106" category="inline-link">HPC GitHub를 참조하십시오</block>
  <block id="8b2e6032c8801b379e2fd75991ebb452" category="paragraph">IOR 대역폭 테스트는 OpenMPI를 사용하여 합성 I/O 생성기 툴 IOR(에서 제공)의 병렬 작업을 실행했습니다<block ref="323e2ec03a214c41088a20e514e0a41e" category="inline-link-rx"></block>) 10개 클라이언트 노드 전체에서 하나 이상의 BeeGFS 구성 요소로 이동합니다. 달리 명시되지 않은 한:</block>
  <block id="219cae8db1869355f9c480a2fe2c5d6d" category="list-text">모든 테스트는 1MiB 전송 크기의 직접 I/O를 사용했습니다.</block>
  <block id="de2223ae9c343f387e4a3549abf2a4fc" category="list-text">BeeGFS 파일 스트라이핑은 1MB 청크 크기 및 파일당 하나의 타겟으로 설정되었습니다.</block>
  <block id="8aa2f9ce00cbab54a4479ba40f638773" category="paragraph">다음 매개 변수는 IOR에 사용되었습니다. 세그먼트 수는 구성 요소 1개의 경우 애그리게이트 파일 크기를 5TiB로, 3개의 구성 요소는 40TiB로 유지하도록 조정되었습니다.</block>
  <block id="a404b853baec85523834a070479317ea" category="paragraph">다음 그림에서는 단일 BeeGFS 기반(관리, 메타데이터 및 스토리지) 구성 요소를 사용한 IOR 테스트 결과를 보여 줍니다.</block>
  <block id="f93ba433079ca784ff0a18a8928d24db" category="paragraph"><block ref="f93ba433079ca784ff0a18a8928d24db" category="inline-image-macro-rx" type="image"></block></block>
  <block id="578da280bb783045852047cd081f65fd" category="paragraph">다음 그림에서는 단일 BeeGFS 메타데이터 + 스토리지 구성 요소를 사용한 IOR 테스트 결과를 보여 줍니다.</block>
  <block id="db43f39b8c5d5c4ef9f8938eb09db411" category="paragraph"><block ref="db43f39b8c5d5c4ef9f8938eb09db411" category="inline-image-macro-rx" type="image"></block></block>
  <block id="720f0ab0184643d51a1197789875c393" category="paragraph">다음 그림에서는 단일 BeeGFS 스토리지 전용 구성 요소를 사용한 IOR 테스트 결과를 보여 줍니다.</block>
  <block id="13e0e7c553ecdbe3ea238e89713a4a47" category="paragraph"><block ref="13e0e7c553ecdbe3ea238e89713a4a47" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e3b081c19738d20e5f52be67ac8d0361" category="paragraph">다음 그림에서는 세 개의 BeeGFS 구성 요소가 포함된 IOR 테스트 결과를 보여 줍니다.</block>
  <block id="04344e81ce55b155d052b799f4737621" category="paragraph"><block ref="04344e81ce55b155d052b799f4737621" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9abc8771b8098ae505a1ff386b580ef3" category="paragraph">예상한 대로 기본 구성 요소과 후속 메타데이터 + 스토리지 구성 요소 간의 성능 차이는 무시할 수 있습니다. 메타데이터 + 스토리지 구성 요소 및 스토리지 전용 구성 요소를 비교하면 스토리지 대상으로 사용되는 추가 드라이브로 인해 읽기 성능이 약간 향상됩니다. 그러나 쓰기 성능에는 큰 차이가 없습니다. 더 높은 성능을 얻기 위해 여러 구성 요소를 함께 추가하여 성능을 선형 방식으로 확장할 수 있습니다.</block>
  <block id="7465e2f5afc6bc7ebff6ea05e19d52d3" category="section-title">IOR 대역폭 테스트: 단일 클라이언트</block>
  <block id="4cb463d8f88ac93de9fecb82d125d05c" category="paragraph">IOR 대역폭 테스트는 OpenMPI를 사용하여 단일 고성능 GPU 서버를 사용하여 여러 IOR 프로세스를 실행하여 단일 클라이언트에서 얻을 수 있는 성능을 탐색했습니다.</block>
  <block id="6a2583bcd41d0a03702444d541162685" category="paragraph">이 테스트는 클라이언트가 Linux 커널 페이지 캐시('tuneFileCacheType=NATIVE')를 사용하도록 구성된 경우 BeeGFS의 다시 읽기 동작 및 성능을 기본 '버퍼링' 설정과 비교합니다.</block>
  <block id="0123881fd1c799161bf0cc847d402a42" category="paragraph">네이티브 캐싱 모드는 클라이언트의 Linux 커널 페이지 캐시를 사용하므로 네트워크를 통해 다시 전송되는 것이 아니라 로컬 메모리에서 다시 읽기 작업을 수행할 수 있습니다.</block>
  <block id="2748a8672e1df7ff75dc04c3e0086a44" category="paragraph">다음 다이어그램은 BeeGFS 빌딩 블록 3개와 단일 클라이언트를 사용한 IOR 테스트 결과를 보여 줍니다.</block>
  <block id="d07c2b895ad73e3adadd62d9b20eb243" category="paragraph"><block ref="d07c2b895ad73e3adadd62d9b20eb243" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2e301b61d3683cc584633009bafffa70" category="admonition">이러한 테스트를 위한 BeeGFS 스트라이핑은 파일당 타겟 8개가 포함된 1MB 청크 크기로 설정되었습니다.</block>
  <block id="8c5eae70f19670232111d1823b5edb56" category="paragraph">기본 버퍼링 모드에서 쓰기 및 초기 읽기 성능이 향상되지만, 동일한 데이터를 여러 번 다시 읽는 워크로드의 경우 네이티브 캐싱 모드에서 성능이 크게 향상됩니다. 이렇게 향상된 다시 읽기 성능은 여러 번의 Epoch에서 동일한 데이터 세트를 여러 번 다시 읽는 딥 러닝과 같은 워크로드에 중요합니다.</block>
  <block id="e9f3e979fd823256ea73296f49e954da" category="section-title">메타데이터 성능 테스트</block>
  <block id="e3195dd21dbd9ee2c6c42f0c8a6c7128" category="paragraph">Metadata 성능 테스트는 IOR의 일부로 포함된 MDTest 도구를 사용하여 BeeGFS의 메타데이터 성능을 측정했습니다. 이 테스트에서는 OpenMPI를 사용하여 10개의 클라이언트 노드 모두에서 병렬 작업을 실행했습니다.</block>
  <block id="44ece23db4ca31ae5b81205ad387af00" category="paragraph">다음 매개 변수는 총 프로세스 수가 2배속 단계에서 10개에서 320으로 조정되고 파일 크기가 4K인 벤치마크 테스트를 실행하는 데 사용되었습니다.</block>
  <block id="b872c01a040702b121dc5f52261e99e0" category="paragraph">메타데이터 성능은 먼저 메타데이터 + 스토리지 구성 요소 하나를 측정한 후 추가 구성 요소를 추가하여 성능이 얼마나 향상되는지를 보여 줍니다.</block>
  <block id="c6c65b36c5c466822447bc4c94abd80c" category="paragraph">다음 다이어그램은 하나의 BeeGFS 메타데이터 + 스토리지 구성 요소가 포함된 MDTest 결과를 보여 줍니다.</block>
  <block id="a5ab5340467c6b4a3a4a7920c54ae8f3" category="paragraph"><block ref="a5ab5340467c6b4a3a4a7920c54ae8f3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5d4514dbb64a843f08caa7fe8140c121" category="paragraph">다음 다이어그램은 BeeGFS 메타데이터 + 스토리지 구성 요소 두 개가 포함된 MDTest 결과를 보여 줍니다.</block>
  <block id="aec56a0b02b345d6f601383808523dc6" category="paragraph"><block ref="aec56a0b02b345d6f601383808523dc6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6bcc55d27d7ea16e6df55e7ec18fd377" category="section-title">기능 검증</block>
  <block id="b15005270887e63f3c777c3722631021" category="paragraph">이 아키텍처의 검증 과정에서 NetApp은 다음을 비롯한 여러 기능 테스트를 수행했습니다.</block>
  <block id="008151af32cff92eed6431ca4cf43500" category="list-text">스위치 포트를 비활성화하여 단일 클라이언트 InfiniBand 포트에 장애 발생</block>
  <block id="73b83d70be21d004da6e079b00bb5948" category="list-text">스위치 포트를 비활성화하여 단일 서버 InfiniBand 포트에 장애 발생</block>
  <block id="f7b8ad51ce1aad4a6e15c6583fcbdd55" category="list-text">BMC를 사용하여 즉시 서버 전원을 끕니다.</block>
  <block id="6148d6995d77c1b8b1bfd4c6f299162b" category="list-text">노드를 대기 노드에 배치하고 다른 노드에 대한 서비스 장애 조치를 원활히 합니다.</block>
  <block id="1cc77e3527f4ac004c8a5cdb5cac049e" category="list-text">노드를 다시 온라인 상태로 전환하고 원래 노드에 서비스를 페일백합니다.</block>
  <block id="908463015e2671e9d90b06353dabae03" category="list-text">PDU를 사용하여 InfiniBand 스위치 중 하나의 전원을 끕니다. BeeGFS 클라이언트에 설정된 'sysSessionChecksEnabled:false' 매개 변수를 사용하여 스트레스 테스트가 진행되는 동안 모든 테스트가 수행되었습니다. I/O에 대한 오류나 운영 중단이 관찰되지 않았습니다.</block>
  <block id="c49182dc0c7a70b9cd2e10853d9ec6c7" category="inline-link">변경 로그</block>
  <block id="788a9659515e495b379621cac9040872" category="admonition">알려진 문제가 있습니다( 참조)<block ref="9892b1a82a523d642c4ee2c76b765b8b" category="inline-link-rx"></block>) 기본 인터페이스('connInterfacesFile'에 정의된 대로) 손실 또는 BeeGFS 서버 장애로 인해 BeeGFS 클라이언트/서버 RDMA 연결이 예기치 않게 중단되거나 활성 클라이언트 I/O가 최대 10분 동안 중단되어 다시 시작할 수 있습니다. 이 문제는 계획된 유지 관리를 위해 BeeGFS 노드가 정상적으로 대기 상태가 되거나 TCP가 사용 중인 경우 발생하지 않습니다.</block>
  <block id="7c6326491c77a63417df94790ba07083" category="inline-link">NetApp을 포함한 NVIDIA DGX SuperPOD</block>
  <block id="2bf773d42bef6909b232e854a16b3ec1" category="summary">5개의 빌딩 블록 이상으로 확장할 수 있도록 심장박동기 및 Corosync를 구성합니다.</block>
  <block id="22892d2f5bfdfba001a02572258cca62" category="doc">5가지 구성 요소 이상으로 확장</block>
  <block id="cfd24c157d6cd9f200eb8c3cf68ee7ed" category="paragraph">5개의 빌딩 블록(10개의 파일 노드) 이상으로 확장하기 위해 페이스 메이커 및 Corosync를 구성할 수 있습니다. 그러나 더 큰 클러스터에는 결점이 있으며, 결국 심장박동기 및 Corosync로 인해 최대 32개의 노드가 필요합니다.</block>
  <block id="9e59383f4d4ca677923852ae81323178" category="paragraph">NetApp은 최대 10개 노드까지 BeeGFS HA 클러스터를 테스트했습니다. 따라서 개별 클러스터를 이 제한을 초과하여 확장하는 것은 권장되거나 지원되지 않습니다. 하지만 BeeGFS 파일 시스템은 여전히 10개 노드 이상으로 확장되어야 하며 NetApp은 BeeGFS on NetApp 솔루션에서 이 점을 고려했습니다.</block>
  <block id="72799e21cef92db3ad98f7c0a923e398" category="paragraph">각 파일 시스템에서 구성 요소의 하위 집합이 포함된 여러 HA 클러스터를 구축함으로써 기본 HA 클러스터링 메커니즘에 대한 권장 제한 또는 하드 제한과는 별개로 전체 BeeGFS 파일 시스템을 확장할 수 있습니다. 이 시나리오에서는 다음을 수행합니다.</block>
  <block id="5c3bc488def3e9ba17589e3a75fdd5c0" category="list-text">추가 HA 클러스터를 나타내는 새 Ansible 인벤토리를 생성한 다음 다른 관리 서비스 구성 생략합니다. 대신 각 추가 클러스터 ha_cluster.yml의 "begfs_ha_mgmtd_floating_ip" 변수를 첫 번째 BeeGFS 관리 서비스의 IP에 지정합니다.</block>
  <block id="321f3f6b80bc5f9c02e358e120fa74b0" category="list-text">동일한 파일 시스템에 HA 클러스터를 추가할 때는 다음 사항을 확인하십시오.</block>
  <block id="32e66ce3c599bce3fc21c5a5943b6f4d" category="list-text">BeeGFS 노드 ID는 고유합니다.</block>
  <block id="50b9a2f3bd2dc22b582e6e66d12bf0ff" category="list-text">group_vars의 각 서비스에 해당하는 파일 이름은 모든 클러스터에서 고유합니다.</block>
  <block id="6219a68f7552d8328f7fc5df8510ffc3" category="list-text">BeeGFS 클라이언트 및 서버 IP 주소는 모든 클러스터에서 고유합니다.</block>
  <block id="16d3c50a6b84c7701cadfdf721b74007" category="list-text">추가 클러스터를 구축 또는 업데이트하기 전에 BeeGFS 관리 서비스가 포함된 첫 번째 HA 클러스터가 실행되고 있습니다.</block>
  <block id="6f94cb93f82c2013e179dc630a5dd715" category="list-text">각 HA 클러스터에 대한 인벤토리를 각각 자체 디렉토리 트리에서 유지 관리합니다.</block>
  <block id="079e1a9e099799d390c677577618ecce" category="paragraph">하나의 디렉토리 트리에서 여러 클러스터의 인벤토리 파일을 혼합하려고 하면 BeeGFS HA 역할이 특정 클러스터에 적용된 구성을 집계하는 방식에 문제가 발생할 수 있습니다.</block>
  <block id="f4250b17c613a290cad4edf8e2bab3fd" category="admonition">새 HA 클러스터를 생성하기 전에 각 HA 클러스터를 5개의 구성 요소로 확장할 필요가 없습니다. 대부분의 경우 클러스터당 더 적은 수의 구성 요소를 사용하는 것이 더 쉽게 관리할 수 있습니다. 한 가지 접근 방식은 각 단일 랙의 구성 요소를 HA 클러스터로 구성하는 것입니다.</block>
  <block id="d1da0cd6852302b521f35aeee065f5ea" category="summary">NetApp 솔루션에 BeeGFS를 구축할 때는 모범 사례 지침을 따르십시오.</block>
  <block id="38b622e4d5c9d918330c81663f61a4e3" category="doc">모범 사례를 검토합니다</block>
  <block id="d780de93793370946b2449b88a29b5ea" category="section-title">표준 규약</block>
  <block id="2028bcc5ed7fdc8ba437b0150866ff2c" category="paragraph">Ansible 인벤토리 파일을 물리적으로 조립하고 생성할 때는 다음 표준 규칙을 따르십시오(자세한 내용은 을 참조하십시오 <block ref="ecd3f3fdba3715697adf284eecd1c932" category="inline-link-macro-rx"></block>)를 클릭합니다.</block>
  <block id="b4d19c971bd6ad93985147c0ce9477c8" category="list-text">파일 노드 호스트 이름은 랙 상단에 더 적은 숫자가 있고 하단에 더 높은 숫자가 있는 순서대로 번호가 지정됩니다(H01-HN).</block>
  <block id="0a4e8ee6eb2b3c9ae6b2864c18db1a80" category="paragraph">예를 들어, 이름 지정 규칙 '[location][row][rack]hN'은 'ictad22h01'과 같습니다.</block>
  <block id="7bf4bcec78c083e165c31432234ebef8" category="list-text">각 블록 노드는 각각 고유한 호스트 이름을 가진 두 개의 스토리지 컨트롤러로 구성됩니다.</block>
  <block id="1d6d5c920cb7d130fd45d8ced35ebec2" category="paragraph">스토리지 어레이 이름은 Ansible 인벤토리의 일부로 전체 블록 스토리지 시스템을 나타내는 데 사용됩니다. 스토리지 배열 이름은 순서대로 번호(A01-AN)로 지정되어야 하며, 개별 컨트롤러의 호스트 이름은 해당 명명 규칙에서 파생됩니다.</block>
  <block id="213b6742fe86c9b7a08c68d5206d723a" category="paragraph">예를 들어, "ictad22a01"이라는 블록 노드는 일반적으로 "ictad22a01-a"와 "ictad22a01-b"와 같이 각 컨트롤러에 대해 구성된 호스트 이름을 가질 수 있지만, Ansible 재고에서는 "ictad22a01"이라고 합니다.</block>
  <block id="a902add826ee667d7f067acb8b49432f" category="list-text">동일한 빌딩 블록 내의 파일 및 블록 노드는 동일한 번호 지정 체계를 공유하며, 랙의 서로 인접해 있으며 두 파일 노드 모두 위에 있고 두 블록 노드 바로 아래에 있습니다.</block>
  <block id="2761f73c104511b8aaeef2eb6c84f3d3" category="paragraph">예를 들어 첫 번째 빌딩 블록에서 파일 노드 H01 및 H02는 모두 블록 노드 A01 및 A02에 직접 연결됩니다. 위에서 아래로 호스트 이름은 H01, H02, A01 및 A02입니다.</block>
  <block id="33324ee77729f51ada2c5446c9c21488" category="list-text">빌딩 블록은 호스트 이름을 기준으로 순차적으로 설치되므로 번호가 낮은 호스트 이름은 랙 상단에, 번호가 높은 호스트 이름은 하단에 표시됩니다.</block>
  <block id="afdf73d1fa37280d63c602fa6be27740" category="paragraph">이는 랙 스위치 상단으로 연결되는 케이블의 길이를 최소화하고 문제 해결을 단순화하기 위한 표준 배포 방법을 정의하는 것입니다. 랙 안정성 문제로 인해 이것이 허용되지 않는 데이터 센터의 경우, 맨 아래부터 랙을 채우는 역작업이 허용됩니다.</block>
  <block id="b4c0fb3649e4f85d78611d90d2d2d308" category="section-title">InfiniBand 스토리지 네트워크 구성</block>
  <block id="815b2630d684df2f4894bd753d3a1fcb" category="paragraph">각 파일 노드의 InfiniBand 포트 중 절반은 블록 노드에 직접 연결하는 데 사용됩니다. 나머지 절반은 InfiniBand 스위치에 연결되며 BeeGFS 클라이언트-서버 연결에 사용됩니다. BeeGFS 클라이언트 및 서버에 사용되는 IPoIB 서브넷의 크기를 결정할 때 예상되는 컴퓨팅/GPU 클러스터 및 BeeGFS 파일 시스템 확장을 고려해야 합니다. 권장 IP 범위를 벗어나야 하는 경우, 단일 빌딩 블록의 각 직접 접속은 고유한 서브넷을 가지며 클라이언트-서버 접속에 사용되는 서브넷과 중복되지 않는다는 점에 유의하십시오.</block>
  <block id="a4f2d907e6fd183bbbc4d275c08b7a9a" category="section-title">직접 연결</block>
  <block id="07a0544547e3cceec6f669bd25c6a605" category="paragraph">각 빌딩 블록 내의 파일 및 블록 노드는 항상 직접 연결에 다음 표의 IP를 사용합니다.</block>
  <block id="d9938c4beed355ac7387d03d8f191c9e" category="admonition">이 주소 지정 체계는 다음 규칙을 따릅니다. 세 번째 옥텟은 항상 홀수이거나 짝수이며, 이는 파일 노드가 홀수인지 아니면 짝수인지에 따라 다릅니다.</block>
  <block id="b55e37e80a68661366be8c4377b13489" category="cell">파일 노드</block>
  <block id="90c8d508b315842cddaf605e8e068d6f" category="cell">IB 포트</block>
  <block id="75ba8d70e3692ba200f0e0df37b4d2ae" category="cell">IP 주소입니다</block>
  <block id="d7f9ab96aecba4fb98ecf8831eb0a462" category="cell">블록 노드</block>
  <block id="b9549a36d11b47e2d2f9389f6363ff8e" category="cell">물리적 IP</block>
  <block id="0d01a155a448abaa8ab4b0bdd3ea5e54" category="cell">가상 IP</block>
  <block id="e9813c434db44aa063e37598de3ed515" category="cell">홀수(h1)</block>
  <block id="9d928738606162dca1d244ffcbdf0036" category="cell">i1a</block>
  <block id="8f337c973339dd7093883bd28ddb6588" category="cell">192.168.1.10</block>
  <block id="495cb471115cc2dbd5c60736f989aa8c" category="cell">홀수(C1)</block>
  <block id="e36314e624d2b2ca257e1f1ecb381f93" category="cell">2A</block>
  <block id="d984a05fa268b7cc6ac052a38960aeb2" category="cell">192.168.1.100</block>
  <block id="80f8cac1e092ca14301921951cf77f91" category="cell">192.168.1.101</block>
  <block id="c7a617044afee64ec7d511879e8b194c" category="cell">i2a</block>
  <block id="d731a116ccfe40ce4a5adb1bf565d785" category="cell">192.168.3.10</block>
  <block id="a9aeb028763672267b98adb1e61f06ca" category="cell">192.168.3.100</block>
  <block id="868e778e153cfafee02c89678e31e3e4" category="cell">192.168.3.101</block>
  <block id="b723decd732b31d828ae939f8f8c81fb" category="cell">i3a</block>
  <block id="28013a9391888f81944ead3ec1401cb0" category="cell">192.168.5.10</block>
  <block id="cfb1a9d899157fd3919c08dceff7fe61" category="cell">짝수(C2)</block>
  <block id="8945c747c6a4da714083579891b2495a" category="cell">192.168.5.100</block>
  <block id="538f8a364ff4308c16dbf7a80a554b5f" category="cell">192.168.5.101</block>
  <block id="d4d9efce9a26c8551723c677f65e1284" category="cell">i4a</block>
  <block id="7e7269d72492d715bbd00efdcdec7e0a" category="cell">192.168.7.10</block>
  <block id="1fbf861a0f4d9494682cfff33756b7aa" category="cell">192.168.7.100</block>
  <block id="7a1a4e2ee2757f302d47c7e3cdc8fcc3" category="cell">192.168.7.101</block>
  <block id="1442135832b351ed9b2f3b91f2393ec7" category="cell">짝수(H2)</block>
  <block id="0522334c503ae8e87d77104f7b27ba17" category="cell">192.168.2.10</block>
  <block id="f8bc2fbe2c937ea5b5e8839cbea69491" category="cell">2B</block>
  <block id="28de33b5199547c2f026595b7175a940" category="cell">192.168.2.100</block>
  <block id="d006845bf7fd39e054131ca6f76c2c47" category="cell">192.168.2.101</block>
  <block id="3a1cc00317003b20386d92ca13328e3d" category="cell">192.168.4.10</block>
  <block id="ccce62893693ca1e63992fa77159dce3" category="cell">192.168.4.100</block>
  <block id="eab39d2ba2b7a903ccf8cef112e1d506" category="cell">192.168.4.101</block>
  <block id="02def76181eddeab3ec0492be002417d" category="cell">192.168.6.10</block>
  <block id="d4b42e0f0d80e9c910e062f49b48b5f5" category="cell">192.168.6.100</block>
  <block id="f23edf799227dfd20d80544836aad8e9" category="cell">192.168.6.101</block>
  <block id="5e0ca78bea1b6ed4af93b1b1c5d7c573" category="cell">192.168.8.10</block>
  <block id="3581177979a7b934a2accd3f5f999444" category="cell">192.168.8.100</block>
  <block id="49213c8f0e8758438d7a69e2789a8b7d" category="cell">192.168.8.101</block>
  <block id="39927fda75baba1d602f4ac8906cb4ef" category="section-title">BeeGFS 클라이언트-서버 IPoIB 주소 지정 체계(서브넷 2개)</block>
  <block id="db65743173e4ff7d9ed62df6220dc4a4" category="paragraph">BeeGFS 클라이언트가 두 개의 InfiniBand 포트를 사용할 수 있도록 하려면 각 서브넷에서 기본 IP로 구성된 BeeGFS 서버 서비스의 절반을 사용하여 IPoIB 서브넷 두 개가 필요합니다. 이를 통해 클라이언트가 두 개의 InfiniBand 포트를 사용하여 파일 시스템에 대한 이중화 및 처리량을 극대화할 수 있습니다.</block>
  <block id="5e98efce8292b94590f3ca502c1d8697" category="paragraph">각 파일 노드에서 여러 BeeGFS 서버 서비스(관리, 메타데이터 또는 스토리지)를 실행합니다. 각 서비스가 다른 파일 노드로 독립적으로 페일오버할 수 있도록 각 서비스마다 고유한 IP 주소가 구성되며 이 주소는 두 노드 간에 자유롭게 움직일 수 있습니다(LIF라고도 함).</block>
  <block id="4db8c0036deb36a38e4df4660af9ed06" category="paragraph">필수 사항은 아니지만 이 구축 환경에서 이러한 연결에 다음 IPoIB 서브넷 범위가 사용 중인 것으로 가정하며 다음 규칙을 적용하는 표준 주소 지정 체계를 정의합니다.</block>
  <block id="8d41eefa8441a4ca177fe0f2676a9512" category="list-text">두 번째 옥텟은 파일 노드 InfiniBand 포트가 홀수인지 또는 짝수인지에 따라 항상 홀수이거나 짝수 입니다.</block>
  <block id="6482f8ef9c5ff1d8a971601fcad837d6" category="list-text">BeeGFS 클러스터 IP는 항상 xxx입니다. 127.100.yyy 또는 xxx.128.100.yyy.</block>
  <block id="3aed58e1cc4af0e5cda8b7e10e2fd863" category="admonition">대역 내 OS 관리에 사용되는 인터페이스 외에도 클러스터 심장 박동 및 동기화를 위한 Corosync에서 추가 인터페이스를 사용할 수 있습니다. 따라서 단일 인터페이스가 손실되어도 전체 클러스터가 다운되지 않습니다.</block>
  <block id="d95a2f19c705379e32f8030de274d07e" category="list-text">BeeGFS Management 서비스는 항상 xxx.yyy.101.0 또는 xxx.yyy.102.0 중 입니다.</block>
  <block id="29cd1587ba2833db9af29eac16f0d72b" category="list-text">BeeGFS 메타데이터 서비스는 항상 xxx.yyy.101.zzz 또는 xxx.yyy.102.zzz입니다.</block>
  <block id="60c1357dfcd221c354054e43ac815018" category="list-text">BeeGFS 스토리지 서비스는 항상 xxx.yyy.103.zzz 또는 xxx.yyy.103.zzz로 제공됩니다.</block>
  <block id="be092b10130fe0c97dd9358f0c131935" category="list-text">100.xxx.1.1 ~ 100.xxx.99.255 범위의 주소는 고객용으로 예약되어 있습니다.</block>
  <block id="3ac8c958d4c77187295fd53646229e9e" category="paragraph">다음 표에는 서브넷 A:100.127.0.0/16의 범위가 나와 있습니다.</block>
  <block id="261addf78c7b2c961032b3dd08ba0b1f" category="cell">목적</block>
  <block id="8433249cf732856c8ef7700f591da923" category="cell">InfiniBand 포트입니다</block>
  <block id="5c43713485260d7759e7710e65d5b181" category="cell">IP 주소 또는 범위입니다</block>
  <block id="32e90ecbd165097494e967a23490ee41" category="cell">BeeGFS 클러스터 IP입니다</block>
  <block id="16bfa5161249dae15f8c441a34126387" category="cell">i1b</block>
  <block id="fcb936b16dcf3c23dec73fa21c9c16f1" category="cell">100.127.100.1-100.127.100.255</block>
  <block id="ae709a18a45df821c97f171d87abda05" category="cell">BeeGFS 관리</block>
  <block id="ca46d9d01d96136b3bd1dea0bce8b99f" category="cell">100.127.101.0</block>
  <block id="c7725fe17ccf0fe6dfa72467bca22d07" category="cell">BeeGFS 메타데이터</block>
  <block id="2aaea2be17c5c489bc5ec00da30f01e0" category="cell">i1b 또는 i3b</block>
  <block id="5474dd17966e980dee3133c4fdddcf29" category="cell">100.127.101.1 - 100.127.101.255</block>
  <block id="d01488abddf6343d229f4a687a740a9d" category="cell">BeeGFS 스토리지</block>
  <block id="43c64dcbdc9c36edb0a78b932e87b96c" category="cell">100.127.103.1 - 100.127.103.255</block>
  <block id="7b0215ed75674e2bc6f9d23b5db3a59a" category="cell">BeeGFS 클라이언트</block>
  <block id="12ad67de237d3ee3ee2ca3ed39a93826" category="cell">(클라이언트에 따라 다름)</block>
  <block id="88bd43ac89ad7875c3db7323b9879d13" category="cell">100.127.1.1 - 100.127.99.255</block>
  <block id="00ee8ecc0f95892eb58786ee6e94e4e7" category="paragraph">다음 표에는 서브넷 B:100.128.0.0/16의 범위가 나와 있습니다.</block>
  <block id="42e7db8b69b0d0451fe5e7e94d271956" category="cell">i4b</block>
  <block id="672e53647fb3fbb550b46ac1eaaad363" category="cell">100.128.100.1-100.128.100.255</block>
  <block id="50641838fba9970d18ab721f2d775331" category="cell">i2b</block>
  <block id="6240652cf0cb3a0056e31569edba6f3e" category="cell">100.128.102.0</block>
  <block id="6bbae520cb1416f9508d58010c4df4a0" category="cell">i2b 또는 i4b</block>
  <block id="3ac8689fd677355ec3c1098b78d717dd" category="cell">100.128.102.1-100.128.102.255</block>
  <block id="61b0ff8b431abb2cad4481cab938c338" category="cell">100.128.104.1 - 100.128.104.255</block>
  <block id="83dc7e1fb9aa3660d2fc0ccb6e72bd1a" category="cell">100.128.1.1-100.128.99.255</block>
  <block id="cd42d4848d52f3ad668601f29b839282" category="admonition">위 범위에 있는 모든 IP가 이 NetApp 검증 아키텍처에 사용되는 것은 아닙니다. 또한 IP 주소를 사전 할당하여 일관된 IP 주소 지정 체계를 사용하여 파일 시스템을 쉽게 확장할 수 있는 방법을 보여 줍니다. 이 스키마에서는 BeeGFS 파일 노드 및 서비스 ID가 잘 알려진 IP 범위의 네 번째 옥텟과 일치합니다. 필요한 경우 파일 시스템을 255개 노드 또는 서비스 이상으로 확장할 수 있습니다.</block>
  <block id="ce0a47ccdc84e9c90b9185aea530a07b" category="summary">BeeGFS 병렬 파일 시스템을 NetApp EF600 스토리지 시스템과 결합하는 NetApp 솔루션 기반 BeeGFS를 지원하려면 특정 장비, 케이블링, 구성이 필요합니다.</block>
  <block id="7cac973d2abc65a232606799a99be23c" category="paragraph">자세한 내용:</block>
  <block id="6ee419ed5a936cfed45771da0b746c94" category="list-text"><block ref="6ee419ed5a936cfed45771da0b746c94" category="inline-link-macro-rx"></block></block>
  <block id="1ce6299bc86692b3e97783bdba904848" category="list-text"><block ref="1ce6299bc86692b3e97783bdba904848" category="inline-link-macro-rx"></block></block>
  <block id="2c39c30b16a5c14e4b3bd73361f541c5" category="list-text"><block ref="2c39c30b16a5c14e4b3bd73361f541c5" category="inline-link-macro-rx"></block></block>
  <block id="b7f5b93ad68dd5ab95107b85145443e8" category="list-text"><block ref="b7f5b93ad68dd5ab95107b85145443e8" category="inline-link-macro-rx"></block></block>
  <block id="9db3ca538820d0cfb7b44ef80f16ca98" category="inline-link-macro">성능 튜닝</block>
  <block id="a51906ad0f905e303cf3b09d82ec1db0" category="list-text"><block ref="a51906ad0f905e303cf3b09d82ec1db0" category="inline-link-macro-rx"></block></block>
  <block id="730b718214a170296ed598158264e021" category="summary">BeeGFS 솔루션에는 검증 테스트를 기반으로 한 성능 조정을 위한 권장 사항이 포함되어 있습니다.</block>
  <block id="a49e13cf9bc8e242e7b828e3c9016699" category="paragraph">BeeGFS가 즉시 사용 가능한 우수한 성능을 제공하기는 하지만, NetApp은 성능을 극대화하기 위해 일련의 권장 튜닝 매개 변수를 개발했습니다. 이 매개 변수는 기본 E-Series 블록 노드의 기능과 공유 디스크 HA 아키텍처에서 BeeGFS를 실행하는 데 필요한 특수 요구사항을 모두 고려합니다.</block>
  <block id="6900084f28039c00033899865271a4b5" category="section-title">파일 노드의 성능 튜닝</block>
  <block id="7ed4e287a78a4cc348d1e60d143ceda8" category="paragraph">구성할 수 있는 조정 매개변수는 다음과 같습니다.</block>
  <block id="d8eb1bf5eeddb34869fa0aee2c5c3be0" category="list-text">* 파일 노드의 UEFI/BIOS에서 시스템 설정. * 성능을 극대화하려면 파일 노드로 사용하는 서버 모델에서 시스템 설정을 구성하는 것이 좋습니다. 시스템 설정(UEFI/BIOS) 또는 베이스보드 관리 컨트롤러(BMC)에서 제공하는 Redfish API를 사용하여 파일 노드를 설정할 때 시스템 설정을 구성합니다.</block>
  <block id="bb2fcb1abe8d0829558e398d9acb4589" category="inline-link-macro">성능을 위해 파일 노드 시스템 설정을 조정합니다</block>
  <block id="adecdfd501fe0c9f7674b95abecb661b" category="paragraph">시스템 설정은 파일 노드로 사용하는 서버 모델에 따라 달라집니다. 사용 중인 서버 모델에 따라 설정을 수동으로 구성해야 합니다. 검증된 Lenovo SR665 파일 노드에 대한 시스템 설정을 구성하는 방법은 을 참조하십시오 <block ref="891cfd1f8dbb99c09432be0144a5be81" category="inline-link-macro-rx"></block>.</block>
  <block id="6721128d9ea380f9965cc220f28619e1" category="list-text">* 필수 구성 매개 변수에 대한 기본 설정 * 필수 구성 매개 변수는 BeeGFS 서비스의 구성 방법과 E-Series 볼륨(블록 장치)의 포맷 및 마운트에 영향을 미칩니다. 이러한 필수 구성 매개 변수는 다음과 같습니다.</block>
  <block id="93de4dab2e303d649f94f0880095e6ef" category="list-text">BeeGFS 서비스 구성 매개 변수입니다</block>
  <block id="c5b3473e89672cc155d0436c6e60bd52" category="inline-link">BeeGFS 서비스 구성 매개 변수입니다</block>
  <block id="bf8b3766586fac2207dd5c620d7b308d" category="paragraph">필요에 따라 구성 매개 변수의 기본 설정을 재정의할 수 있습니다. 특정 워크로드 또는 사용 사례에 맞게 조정할 수 있는 매개 변수는 를 참조하십시오<block ref="d22612d773394e50d7efa2e9719d459e" category="inline-link-rx"></block>.</block>
  <block id="334a50f926a902a241ecfae54f3cce32" category="list-text">볼륨 포맷팅 및 마운팅 매개 변수는 권장 기본값으로 설정되며 고급 사용 사례에만 조정해야 합니다. 기본값은 다음을 수행합니다.</block>
  <block id="4b9b870ed7f3db8f28c2ddcf4d3bd986" category="list-text">기본 볼륨의 RAID 구성 및 세그먼트 크기와 함께 타겟 유형(예: 관리, 메타데이터 또는 스토리지)을 기준으로 초기 볼륨 포맷을 최적화합니다.</block>
  <block id="9f641b3b08e18d35b2219dee293e2038" category="list-text">심박동조율기가 각 볼륨을 마운트하는 방법을 조정하여 변경 사항이 즉시 E-시리즈 블록 노드로 플러시되도록 합니다. 이렇게 하면 활성 쓰기가 진행 중일 때 파일 노드가 실패할 때 데이터 손실을 방지할 수 있습니다.</block>
  <block id="72247689b02927b1ceac4fb69e6c9954" category="inline-link">볼륨 포맷 및 마운팅 구성 매개 변수</block>
  <block id="71ba07d5377dd195ceff5f6dbddc08dc" category="paragraph">특정 워크로드 또는 사용 사례에 맞게 조정할 수 있는 매개 변수는 를 참조하십시오<block ref="2996b969524b278e7da0cf1bb77d8754" category="inline-link-rx"></block>.</block>
  <block id="728ecec149994e53980e0103b04d3e1b" category="list-text">* 파일 노드에 설치된 Linux OS의 시스템 설정. * 의 4단계에서 Ansible 인벤토리를 작성할 때 기본 Linux OS 시스템 설정을 재정의할 수 있습니다 <block ref="ecd3f3fdba3715697adf284eecd1c932" category="inline-link-macro-rx"></block>.</block>
  <block id="c5d80eb8c0726de2a9804385295dc0e3" category="paragraph">기본 설정을 사용하여 NetApp 기반 BeeGFS 솔루션을 검증했지만 특정 워크로드 또는 사용 사례에 맞게 수정할 수 있습니다. 변경할 수 있는 Linux OS 시스템 설정의 예는 다음과 같습니다.</block>
  <block id="b56281fe1e5f14da49b6d1d4c6ad0cd9" category="list-text">E-Series 블록 장치의 I/O 큐</block>
  <block id="43a8170c4aebbb467c4d4b59d77a7662" category="paragraph">BeeGFS 타겟으로 사용되는 E-Series 블록 디바이스에서 I/O 큐를 구성하여 다음을 수행할 수 있습니다.</block>
  <block id="ce0213a2bd6755f2eacf9574b2b56dda" category="list-text">장치 유형(NVMe, HDD 등)에 따라 스케줄링 알고리즘을 조정합니다.</block>
  <block id="c78d3d0bdafa5fc5623e3d56a9cc33ce" category="list-text">미결 요청 수를 늘립니다.</block>
  <block id="b785a1945e736aa8340d2e4bde128b82" category="list-text">요청 크기를 조정합니다.</block>
  <block id="a9a2c451a0c5c7939a07afe7cd297216" category="list-text">미리 읽기 동작 최적화</block>
  <block id="f39721f45b17814f0740b3c066ca0b66" category="list-text">가상 메모리 설정.</block>
  <block id="552afad9cf059c34e2ed8d24ff34fc12" category="paragraph">최적의 스트리밍 성능을 위해 가상 메모리 설정을 조정할 수 있습니다.</block>
  <block id="aa8e8d4d1817c4e08c70cd3c1b4c89b9" category="list-text">CPU 설정</block>
  <block id="423dd652f980ba19cb7fb7f577576270" category="paragraph">최대 성능을 위해 CPU 주파수 조절기 및 기타 CPU 구성을 조정할 수 있습니다.</block>
  <block id="eb2cf8d186779ea110100038f3ec2e90" category="list-text">읽기 요청 크기입니다.</block>
  <block id="17dd6d5b67055565e29c50f8150ce378" category="paragraph">Mellanox HCA의 최대 읽기 요청 크기를 늘릴 수 있습니다.</block>
  <block id="ba4dcc8d5b46a4c30176506ef828aea4" category="section-title">블록 노드의 성능 튜닝</block>
  <block id="4f59030dbd3da04d4b74738f5149fffb" category="paragraph">특정 BeeGFS 빌딩 블록에 적용되는 구성 프로필을 기준으로 블록 노드에 구성된 볼륨 그룹이 약간 변경됩니다. 예를 들어, 24-드라이브 EF600 블록 노드는 다음과 같습니다.</block>
  <block id="841fc343eee01328e222ebada200ca5d" category="list-text">BeeGFS 관리, 메타데이터 및 스토리지 서비스를 비롯한 단일 기본 구성 요소:</block>
  <block id="bbea55f4794f89e45fe7c40eaf8ca3ee" category="list-text">BeeGFS 관리 및 메타데이터 서비스를 위한 1 x 2 + 2 RAID 10 볼륨 그룹</block>
  <block id="92f2b7b47db52c081f552bd884a78ae7" category="list-text">BeeGFS 스토리지 서비스용 2x 8+2 RAID 6 볼륨 그룹</block>
  <block id="4f4960028dfd13311a5679d2450101d1" category="list-text">BeeGFS 메타데이터 + 스토리지 구성 요소:</block>
  <block id="fdd7b1bdaea27f32d5925fd1a957fce4" category="list-text">BeeGFS 메타데이터 서비스용 2 + 2 RAID 10 볼륨 그룹 1개</block>
  <block id="196fdf9280847a2a4a9ddd0b8520bdfb" category="list-text">BeeGFS 스토리지 전용 구성 요소:</block>
  <block id="632ac8eccac17a8789dd33202130e509" category="list-text">BeeGFS 스토리지 서비스용 10+2 RAID 6 볼륨 그룹 2개</block>
  <block id="014e85e7f3bbdad1ad6f193e82d21755" category="inline-link-macro">배포 지침</block>
  <block id="39b751cb17d740944bc5071eba1abda2" category="admonition">BeeGFS는 스토리지 대비 관리 및 메타데이터를 위해 스토리지 공간이 훨씬 적게 요구되므로 RAID 10 볼륨 그룹에 더 작은 드라이브를 사용하는 옵션이 있습니다. 작은 드라이브는 가장 바깥쪽 드라이브 슬롯에 장착해야 합니다. 자세한 내용은 를 참조하십시오 <block ref="92eed053ec15880d36275e60ab80275b" category="inline-link-macro-rx"></block>.</block>
  <block id="1708794637b71b8aadfa80d503ccc505" category="paragraph">이러한 모든 설정은 Ansible 기반 배포를 통해 구성되며, 다음은 성능/동작을 최적화하기 위해 일반적으로 권장되는 몇 가지 다른 설정과 함께 제공됩니다.</block>
  <block id="b02fbba0a56e144e15b688980d01275a" category="list-text">글로벌 캐시 블록 크기를 32KiB로 조정하고 요구 기반 캐시 플러시를 80%로 조정합니다.</block>
  <block id="c70b65aef502812d5a0e8a4b173334d9" category="list-text">자동 로드 밸런싱 비활성화(컨트롤러 볼륨 할당이 의도한 대로 유지되는지 확인)</block>
  <block id="94966bf9df1a2fb2442d06d53723f28e" category="list-text">읽기 캐싱 설정 및 미리 읽기 캐싱 해제</block>
  <block id="65f3cbabf1e92d0ce2d27d87d85a3c5a" category="list-text">미러링으로 쓰기 캐시를 설정하고 배터리 백업이 필요하므로 블록 노드 컨트롤러의 장애가 발생해도 캐시가 유지됩니다.</block>
  <block id="dfb95cf8b58d92dcb47401bae0964c5d" category="list-text">드라이브가 볼륨 그룹에 할당되는 순서를 지정하여 사용 가능한 드라이브 채널 간에 I/O의 균형을 조정합니다.</block>
  <block id="2260cb128d87141c6a0a2c06c043def7" category="summary">일반 Ansible 인벤토리 구조를 정의한 후 BeeGFS 파일 시스템의 각 구성 요소에 대한 구성을 정의합니다.</block>
  <block id="b8bb1668a8a0007267670827d99f76b5" category="paragraph">이러한 구축 지침은 관리, 메타데이터 및 스토리지 서비스를 포함한 기본 구성 요소로 구성된 파일 시스템, 메타데이터 및 스토리지 서비스를 포함하는 두 번째 구성 요소, 세 번째 스토리지 전용 구성 요소로 이루어진 파일 시스템을 구축하는 방법을 보여 줍니다.</block>
  <block id="bc4ca1def58917532e653ebf4c3c5f15" category="paragraph">이 단계에서는 전체 BeeGFS 파일 시스템의 요구 사항을 충족하도록 NetApp BeeGFS 구성 요소를 구성하는 데 사용할 수 있는 모든 일반 구성 프로필을 보여 주기 위한 것입니다.</block>
  <block id="053cdc4e7aa5884fba5be0b7e80bcb5c" category="admonition">이 섹션과 후속 섹션에서 필요에 따라 조정하여 구축할 BeeGFS 파일 시스템을 나타내는 인벤토리를 생성합니다. 특히, 스토리지 네트워크에 대해 각 블록 또는 파일 노드를 나타내는 Ansible 호스트 이름과 원하는 IP 주소 지정 스키마를 사용하여 BeeGFS 파일 노드 및 클라이언트의 수에 맞게 확장할 수 있도록 합니다.</block>
  <block id="e00187948ca315221e5e284a4312f83f" category="section-title">1단계: Ansible 인벤토리 파일을 만듭니다</block>
  <block id="cbdf4dddad7bf23198edcbf2c8721659" category="list-text">새 'inventory.yml' 파일을 만든 다음, 필요에 따라 'eseries_storage_systems' 아래에 있는 호스트를 대체하여 구축의 블록 노드를 나타냅니다. 이름은 host_VAR/&lt;filename&gt;.yml에 사용되는 이름과 일치해야 합니다.</block>
  <block id="742c9db30f264a7d33e72383a817b4f5" category="paragraph">다음 섹션에서는 클러스터에서 실행할 BeeGFS 서비스를 나타내는 "ha_cluster" 아래에 Ansible 그룹을 추가로 생성합니다.</block>
  <block id="066251bf9494493f76299f6f40a80df6" category="section-title">2단계: 관리, 메타데이터 및 스토리지 구성 요소에 대한 인벤토리를 구성합니다</block>
  <block id="5320d481bd8442fec42afcaded2a8d49" category="paragraph">클러스터 또는 기본 구성 요소에서 첫 번째 구성 요소는 메타데이터 및 스토리지 서비스와 함께 BeeGFS 관리 서비스를 포함해야 합니다.</block>
  <block id="a54299a446e0a2e17f57383db8e31dc6" category="list-text">inventory.yml에서 ha_cluster:Children 아래에 다음 매개 변수를 입력합니다.</block>
  <block id="fd84d0d4501e2eca409dc18043cf1492" category="list-text">'group_vars/mgmt.yml' 파일을 생성하고 다음을 포함합니다.</block>
  <block id="bcc9cdaf60435f4d091a1bfdac879201" category="list-text">group_vars/ 아래에서 다음 템플릿을 사용하여 META_08을 통해 자원 그룹 META_01에 대한 파일을 만든 다음 아래 표를 참조하여 각 서비스에 대한 자리 표시자 값을 입력합니다.</block>
  <block id="3df790a0a0a3be54d9cbac91d4bc35e1" category="inline-link">NetApp EF600 어레이 소개</block>
  <block id="4ada98602970473e524def1d48723bd6" category="admonition">볼륨 크기는 전체 스토리지 풀(볼륨 그룹이라고도 함)의 백분율로 지정됩니다. SSD 오버 프로비저닝을 위해 각 풀에 여유 용량을 남겨 두는 것이 좋습니다(자세한 내용은 참조)<block ref="dfc1025f9a756c10e6b0cbe0f4bc500a" category="inline-link-rx"></block>)를 클릭합니다. 스토리지 풀 'begfs_m1_m2_m5_m6'도 관리 서비스를 위해 풀 용량의 1%를 할당합니다. 따라서 스토리지 풀의 메타데이터 볼륨에 대해 1.92TB 또는 3.84TB 드라이브를 사용할 때 Beegfs_M1_m2_M5_M6의 경우 이 값을 21.25로 설정하고, 7.65TB 드라이브의 경우 이 값을 22.25로 설정하고, 15.3TB 드라이브의 경우 이 값을 23.75로 설정합니다.</block>
  <block id="34082694d21dbdcfc31e6e32d9fb2b9f" category="cell">파일 이름입니다</block>
  <block id="60aaf44d4b562252c04db7f98497e9aa" category="cell">포트</block>
  <block id="b1cddc6c78e92a26b8976dc97327d412" category="cell">유동 IP</block>
  <block id="72159601fc6c3d952cc9825d610ddd68" category="cell">NUMA 영역</block>
  <block id="40cf615dcacf5ec5faf6a3cdf1ff5a6e" category="cell">스토리지 풀</block>
  <block id="cdd25d91a2d0aca59a80f91cfe9af9de" category="cell">소유 컨트롤러</block>
  <block id="f4d0c8022be4f31d06814c33705037ff" category="cell">meta_01.yml</block>
  <block id="1f7aa6705d5b742085538c627f6f9c2b" category="cell">8015</block>
  <block id="01098d2436a5e4cf506036d6aca3c6b9" category="cell">i1b: 100.127.101.1 / 16 i2b: 100.128.102.1 / 16</block>
  <block id="cfcd208495d565ef66e7dff9f98764da" category="cell">0</block>
  <block id="ca9fd584227ff345bca2ef90d5c56e63" category="cell">ictad22a01</block>
  <block id="7ef878b8d47cf2658a8b7e4c1b8f133d" category="cell">Beegfs_m1_m2_m5_m6</block>
  <block id="7fc56270e7a70fa81a5935b72eacbe29" category="cell">A</block>
  <block id="60b1afbaab870bf5621ed87ae12559fe" category="cell">meta_02.yml</block>
  <block id="62d2b7ba91f34c0ac08aa11c359a8d2c" category="cell">8025</block>
  <block id="e04871f7c2f611e8ad3e026ef33ce958" category="cell">i2b:100.128.102.2/16 i1b:100.127.101.2/16</block>
  <block id="9d5ed678fe57bcca610140957afab571" category="cell">B</block>
  <block id="3ce592406a461bfadfa5ab1f08c5c506" category="cell">meta_03.yml</block>
  <block id="a2b8a85a29b2d64ad6f47275bf1360c6" category="cell">8035</block>
  <block id="e04d4c629001763b33c4ff8b9896d667" category="cell">i3b:100.127.101.3/16 i4b:100.128.102.3/16</block>
  <block id="c4ca4238a0b923820dcc509a6f75849b" category="cell">1</block>
  <block id="e2113f2adde9ccc87fb733b80de62a05" category="cell">ictad22a02</block>
  <block id="c229ea898f8c27aeb40c65332e30db3f" category="cell">Beegfs_m3_M4_M7_M8</block>
  <block id="7f6482de225123824ca5b23c1cf79f05" category="cell">meta_04.yml</block>
  <block id="704cddc91e28d1a5517518b2f12bc321" category="cell">8045</block>
  <block id="0d343c87415ff2c30cb55d5962ced8e2" category="cell">i4b:100.128.102.4/16 i3b:100.127.101.4/16</block>
  <block id="833a23c43dc9c206a593873d80d04903" category="cell">meta_05.yml</block>
  <block id="444b0d9a802792791bb9a2da568b463d" category="cell">8055</block>
  <block id="685d00be66f443c6c339b81cc66fa4a3" category="cell">i1b: 100.127.101.5 / 16 i2b: 100.128.102.5 / 16</block>
  <block id="38774c8cd9de3fd76c7df6b0746f2f2b" category="cell">meta_06.yml</block>
  <block id="320e4df890a1a620573db8170f39a093" category="cell">8065</block>
  <block id="f084a55203c0946ef5605449dede3354" category="cell">i2b:100.128.102.6/16 i1b:100.127.101.6/16</block>
  <block id="5a681b3e1f7ad2d965284e36f4f6b7d3" category="cell">meta_07.yml</block>
  <block id="ede529dfcbb2907e9760eea0875cdd12" category="cell">8075</block>
  <block id="59a587289a0c0568b62bb3b0beb25710" category="cell">i3b:100.127.101.7 / 16 i4b:100.128.102.7 / 16</block>
  <block id="a9cc3f3ebc7a8daedf369af06faba518" category="cell">META_08.월</block>
  <block id="5011bf6d8a37692913fce3a15a51f070" category="cell">8085</block>
  <block id="183b03ffff0f1c540c2bcc4fa7645e8f" category="cell">i4b:100.128.102.8/16 i3b:100.127.101.8/16</block>
  <block id="89f0938aa83de82ca99f8b06297ed69c" category="list-text">group_vars/ 아래에서 다음 템플릿을 사용하여 'tor_08'을 통해 리소스 그룹 tor_01에 대한 파일을 만든 다음 예제를 참조하여 각 서비스의 자리 표시자 값을 입력합니다.</block>
  <block id="9b62ac6b206ab6cafe8dafa0990559c7" category="inline-link-macro">권장되는 스토리지 풀 오버 프로비저닝 비율</block>
  <block id="ab2ec57b0e9afdc73bcc69a962ee35c4" category="admonition">올바른 크기는 을 참조하십시오 <block ref="152d8bea233357f34ffa00ccf219bae3" category="inline-link-macro-rx"></block>.</block>
  <block id="b627976db3394ccf24342632cef6f4f1" category="cell">STOR_01.대칭</block>
  <block id="40f4da34bbe180214c23b9e55da4f772" category="cell">8013</block>
  <block id="2fcc40eb936b77784739bed3cda30225" category="cell">i1b: 100.127.103.1 / 16 i2b: 100.128.104.1 / 16</block>
  <block id="5ef33d06ff783e8453c10b95db8c1253" category="cell">Beegfs_s1_s2</block>
  <block id="70963f6e36ca66556bef5f6ae74ad0ad" category="cell">STOR_02.월</block>
  <block id="1ecdec353419f6d7e30857d00d0312d1" category="cell">8023</block>
  <block id="bf4e53a6c43ad511c5f730de94f1c989" category="cell">i2b:100.128.104.2 / 16 i1b:100.127.103.2 / 16</block>
  <block id="a4253b13d64a7017467d335c0c147ed3" category="cell">STOR_03.월</block>
  <block id="fc5b3186f1cf0daece964f78259b7ba0" category="cell">8033</block>
  <block id="d2f781a145f7598ae80a6ed6a34a297d" category="cell">i3b:100.127.103.3 / 16 i4b:100.128.104.3 / 16</block>
  <block id="a3cc9ef3e643fd2d2e1b6c2672b1c361" category="cell">Beegfs_S3_S4</block>
  <block id="d471f1c4be4f658b822b7cfcfc808efa" category="cell">STOR_04.yml</block>
  <block id="5bd529d5b07b647a8863cf71e98d651a" category="cell">8043</block>
  <block id="87b35387416f5837e6e2523744e368f9" category="cell">i4b:100.128.104.4/16 i3b:100.127.103.4/16</block>
  <block id="6a0625f228a1c5802a3d0ca970c7ebac" category="cell">STOR_05.월</block>
  <block id="dfccdb8b1cc7e4dab6d33db0fef12b88" category="cell">8053</block>
  <block id="457859c18e2dfb216c95ea335da7fdc9" category="cell">i1b: 100.127.103.5 / 16 i2b: 100.128.104.5 / 16</block>
  <block id="2ac54a6d92aca96fef8d0eac5b813f34" category="cell">Beegfs_S5_S6</block>
  <block id="09da1a861f10d113069c5e1da9d2decd" category="cell">STOR_06.대칭</block>
  <block id="8d1f1aac0dd8a76b49e8bbdda0c7c98c" category="cell">8063</block>
  <block id="1bd035750c97cc091a94b72035e34013" category="cell">i2b:100.128.104.6/16 i1b:100.127.103.6/16</block>
  <block id="cf124e58023b3726106af9c8718a48ed" category="cell">STOR_07.월</block>
  <block id="ffa9b486ad206c638c657b7ed335635c" category="cell">8073</block>
  <block id="d319c022fb006d05c63de544a768c7b5" category="cell">i3b:100.127.103.7 / 16 i4b:100.128.104.7 / 16</block>
  <block id="3e96e523215f928a3915e79e1451e2e7" category="cell">Beegfs_S7_s8</block>
  <block id="0e4b036746af52a755e4b546698b2b61" category="cell">STOR_08.월</block>
  <block id="20ef119e812e178ecb44efa448b57ebc" category="cell">8083</block>
  <block id="abf8898bf8b809341f1a690241343288" category="cell">i4b:100.128.104.8 / 16 i3b:100.127.103.8/16</block>
  <block id="80e0c052ed9f2bde54c56adb04f880f1" category="section-title">3단계: 메타데이터 + 스토리지 구성 요소에 대한 인벤토리를 구성합니다</block>
  <block id="9e701ac8f2dd669a0e51464b4d8e3331" category="paragraph">다음 단계에서는 BeeGFS 메타데이터 + 스토리지 구성 요소에 대한 Ansible 인벤토리를 설정하는 방법을 설명합니다.</block>
  <block id="ff1cbf3210fb9b21912445c6ea8cb9f6" category="list-text">'inventory.yml'에서 기존 설정 아래에 다음 파라미터를 입력합니다.</block>
  <block id="628d1b90e1a21bbcec24af78377f8297" category="list-text">group_vars/ 아래에서 다음 템플릿을 사용하여 META_16을 통해 자원 그룹 META_09 파일을 만든 다음 예제를 참조하여 각 서비스의 자리 표시자 값을 입력합니다.</block>
  <block id="bc5e8003da73758b95c46194672943bb" category="admonition">올바른 크기는 을 참조하십시오 <block ref="152d8bea233357f34ffa00ccf219bae3" category="inline-link-macro-rx"></block>.</block>
  <block id="9c6de3c786b8c9c409de2fd8070e5072" category="cell">META_09.대칭</block>
  <block id="4bcb81674e1186a66143fec42901c209" category="cell">i1b: 100.127.101.9 / 16 i2b: 100.128.102.9 / 16</block>
  <block id="a54f967fcc27024d3780cfad23300dd8" category="cell">ictad22a03</block>
  <block id="2ea9f3181dbee99d651a0d6c53be4a36" category="cell">Beegfs_m9_M10_M13_M14</block>
  <block id="f370a281056494e99bcade5ddef17b26" category="cell">META_10.월</block>
  <block id="89d68a1b94d4d1c926944117a136dad1" category="cell">i2b:100.128.102.10/16 i1b:100.127.101.10/16</block>
  <block id="27f563eed2131061540c21a6239b43d8" category="cell">meta_11.yml</block>
  <block id="6239aa390b35659bc861841760941247" category="cell">i3b:100.127.101.11 / 16 i4b:100.128.102.11 / 16</block>
  <block id="af2f976032e920d54c9455a8e1fd675d" category="cell">ictad22a04</block>
  <block id="7c335ef1ce51db644c52518580d45d49" category="cell">Beegfs_M11_M12_M15_M16</block>
  <block id="a2a3007e91ab84d40e9453997468f1ad" category="cell">META_12.월</block>
  <block id="a65f2e74154cdd3870324bbed77b4bd5" category="cell">i4b:100.128.102.12/16 i3b:100.127.101.12/16</block>
  <block id="14c79c2a227a377885225e0f4dcf53b0" category="cell">META_13.월</block>
  <block id="b6b9f36adb7974a0f6d17412ec3fee68" category="cell">i1b:100.127.101.13/16 i2b:100.128.102.13/16</block>
  <block id="07e72a8a343c421129dc3a92902de565" category="cell">meta_14.yml</block>
  <block id="c44a959db7ffec72c54df85a2b00175b" category="cell">i2b:100.128.102.14 / 16 i1b:100.127.101.14 / 16</block>
  <block id="d4d36ef3d915a0d2eaac8c62f1d8eff6" category="cell">META_15.월</block>
  <block id="44b67b40baecc652e6f08e274b29865b" category="cell">i3b:100.127.101.15/16 i4b:100.128.102.15/16</block>
  <block id="b465a4b4c591a6f2e44fedac80e726d0" category="cell">meta_16.yml</block>
  <block id="23344e5747f1b08172f5d05aa88919e5" category="cell">i4b:100.128.102.16/16 i3b:100.127.101.16/16</block>
  <block id="91e38d134a7ca4a23006b0cf023d9011" category="list-text">group_vars/ 아래에서 다음 템플릿을 사용하여 'tor_16'을 통해 리소스 그룹 tor_09에 대한 파일을 만든 다음 예제를 참조하여 각 서비스의 자리 표시자 값을 입력합니다.</block>
  <block id="ca61951791cd6f4d50294a908b9eee76" category="admonition">올바른 크기는 을 참조하십시오 <block ref="152d8bea233357f34ffa00ccf219bae3" category="inline-link-macro-rx"></block>...</block>
  <block id="71c1385fcc844d118e8b2688b0cfd2d6" category="cell">STOR_09.대칭</block>
  <block id="b183ecb3a449e6250fd1771086e68253" category="cell">i1b: 100.127.103.9 / 16 i2b: 100.128.104.9 / 16</block>
  <block id="9282f3f43896f146dcbcc2d03d530b59" category="cell">Beegfs_S9_S10</block>
  <block id="8f72ae1bf7ca7b8218a4bf9e719f5e7d" category="cell">STOR_10.월</block>
  <block id="b8569c1d93725d20f1a50fb74f3947df" category="cell">i2b:100.128.104.10/16 i1b:100.127.103.10/16</block>
  <block id="e5a3d4f42adb756f3b3c2e3ed045e4a8" category="cell">STOR_11.월</block>
  <block id="53b0db6fe7b8e62a2dcc9bf455bcf174" category="cell">i3b:100.127.103.11 / 16 i4b:100.128.104.11 / 16</block>
  <block id="6e4cec4b32bddd9c9a3574aacee223b6" category="cell">Beegfs_s11_s12</block>
  <block id="05fd4833433a12b38d11d8045aebddff" category="cell">STOR_12.월</block>
  <block id="9df04e8249070b73fc9be81b8f249664" category="cell">i4b:100.128.104.12/16 i3b:100.127.103.12/16</block>
  <block id="437037bccd34f3db0b238843b50fe65a" category="cell">STOR_13.월</block>
  <block id="527c5e3cde165799cdd8148db81d6473" category="cell">i1b: 100.127.103.13 / 16 i2b: 100.128.104.13 / 16</block>
  <block id="7db433542754f496e2d707f51bf00c05" category="cell">Beegfs_S13_s14</block>
  <block id="b3c4ed6c5b5c833713923f9e9bdfb9b9" category="cell">STOR_14.월</block>
  <block id="80cd11504622edd89d4abbc32c1245aa" category="cell">i2b:100.128.104.14 / 16 i1b:100.127.103.14 / 16</block>
  <block id="4871ef58b7b91db78d33bb4d95e4bf27" category="cell">STOR_15.월</block>
  <block id="040551498fc870111512145ed93337fc" category="cell">i3b:100.127.103.15 / 16 i4b:100.128.104.15 / 16</block>
  <block id="b1a9c1cb2640dd5bc9fb4e80dda30200" category="cell">Beegfs_s15_S16</block>
  <block id="b02a9cdb541eba39e680a1da9c6299c7" category="cell">STOR_16.월</block>
  <block id="4799f858e623362408f753fa051a2699" category="cell">i4b:100.128.104.16/16 i3b:100.127.103.16/16</block>
  <block id="dea1f079dcd8c8280e07dcd96ea8c075" category="section-title">4단계: 스토리지 전용 구성 요소에 대한 인벤토리를 구성합니다</block>
  <block id="711be1acedea341e1f5455f007cdb22b" category="paragraph">다음 단계에서는 BeeGFS 스토리지 전용 구성 요소에 대한 Ansible 인벤토리를 설정하는 방법을 설명합니다. 메타데이터 + 스토리지에 대한 구성을 설정하는 것과 스토리지 전용 구성 블록에 대한 구성을 설정하는 것의 주된 차이점은 모든 메타데이터 리소스 그룹이 생략되고 각 스토리지 풀에 대해 "criteria_drive_count"를 10에서 12로 변경하는 것입니다.</block>
  <block id="5b6fe069463b7f5581a1864de036e765" category="list-text">group_vars/ 아래에서 다음 템플릿을 사용하여 'tor_24'를 통해 리소스 그룹 tor_17에 대한 파일을 만든 다음 예제를 참조하여 각 서비스의 자리 표시자 값을 입력합니다.</block>
  <block id="80f4c22d8a78e5d96cdf5bef28444426" category="admonition">올바른 크기는 을 참조하십시오 <block ref="152d8bea233357f34ffa00ccf219bae3" category="inline-link-macro-rx"></block>.</block>
  <block id="f9838993bed3d0e550ae346ed2e4355e" category="cell">STOR_17.월</block>
  <block id="de15a372e63adf3e9d172fcfe67bffbc" category="cell">i1b: 100.127.103.17 / 16 i2b: 100.128.104.17 / 16</block>
  <block id="5e71a5c8d7eefee3fe82fe28b69d3c1e" category="cell">ictad22a05</block>
  <block id="8cf4aacf94a115dfc0190ee6782190d3" category="cell">Beegfs_S17_s18</block>
  <block id="7876b49b042d07da9a565db780a9b186" category="cell">STOR_18.월</block>
  <block id="e14872a3791e3d785c59a5fb1892c4cf" category="cell">i2b:100.128.104.18 / 16 i1b:100.127.103.18 / 16</block>
  <block id="291847ab33dfc1d81beed13f4d7a0519" category="cell">STOR_19.대칭</block>
  <block id="29d24f7d913acaf024704d56a3b47f4d" category="cell">i3b:100.127.103.19 / 16 i4b:100.128.104.19 / 16</block>
  <block id="114a9ab19efb0876a3622e54afc5bdbb" category="cell">ictad22a06</block>
  <block id="6a972920f626e0b0b8d505315beaf38b" category="cell">Beegfs_S19_S20</block>
  <block id="943a4f354a2af18dac1fe2a6e14fe880" category="cell">STOR_20.월</block>
  <block id="e441e411ebace2ff01e6e612efceb07a" category="cell">i4b:100.128.104.20 / 16 i3b:100.127.103.20 / 16</block>
  <block id="a5aadbbde2e0b66fc661a126f5a1ce1e" category="cell">STOR_21.대칭</block>
  <block id="4a7361f8632968e437b2bae55a7d6a5e" category="cell">i1b: 100.127.103.21 / 16 i2b: 100.128.104.21 / 16</block>
  <block id="9c82263beb960ece0e5b6ac0604bb4d9" category="cell">Beegfs_s21_S22</block>
  <block id="4879e56fe4d161ba3e4df67f961c483a" category="cell">STOR_22.월</block>
  <block id="8768cf88da2b645b99d30056c6b1f6e7" category="cell">i2b:100.128.104.22/16 i1b:100.127.103.22/16</block>
  <block id="316b3c9a6656c51b87a725bf1f678a52" category="cell">STOR_23.월</block>
  <block id="5eda737d72e69dcbdd869d84cc7c0e48" category="cell">i3b:100.127.103.23 / 16 i4b:100.128.104.23 / 16</block>
  <block id="2404c81b13915ef9d59e0ac6328f4c10" category="cell">Beegfs_S23_S24</block>
  <block id="47662afeeaa16771e7d516dd96ade0b7" category="cell">STOR_24.월</block>
  <block id="a9088dda4778ef90eb3b6f87b070cd25" category="cell">i4b:100.128.104.24 / 16 i3b:100.127.103.24 / 16</block>
  <block id="66136a118d01240429805a157ae4b538" category="summary">2세대 구성 요소에 대해 스토리지 풀당 표준 볼륨 4개를 따르는 경우 다음 권장 비율을 참조하십시오.</block>
  <block id="13d38edc52fe6e049aae05e6fce1573a" category="paragraph">2세대 구성 요소에 대해 스토리지 풀당 표준 볼륨 4개를 따르는 경우 다음 표를 참조하십시오.</block>
  <block id="2d115a94acc324947afb0abf7c47d665" category="paragraph">이 표에는 각 BeeGFS 메타데이터 또는 스토리지 타겟에 대한 "eseries_storage_pool_configuration"의 볼륨 크기로 사용할 권장 비율이 나와 있습니다.</block>
  <block id="ec8691da9bf60fda22f12e08033d054b" category="cell">드라이브 크기</block>
  <block id="6f6cb72d544962fa333e2e34ce64f719" category="cell">크기</block>
  <block id="6f4922f45568161a8cdf4ad2299f6d23" category="cell">18</block>
  <block id="d81fdeb5a429e85d04118048e4b3485d" category="cell">21.5</block>
  <block id="6303058eb2f22355195922bb9eeac265" category="cell">22.5</block>
  <block id="1ff1de774005f8da13f42943881c655f" category="cell">24</block>
  <block id="b6f404dc4372a8369386a51240b69703" category="admonition">위의 지침은 관리 서비스가 포함된 스토리지 풀에 적용되지 않으며, 관리 데이터에 대해 스토리지 풀의 1%를 할당하기 위해 위의 크기를 .25%까지 줄여야 합니다.</block>
  <block id="cede28c203641f70169adaabc10df9b6" category="inline-link">TR-4800: 부록 A: SSD 내구성 및 오버 프로비저닝 이해</block>
  <block id="dab022c0b8356780eb602bc87effd71f" category="paragraph">이러한 값이 어떻게 결정되었는지 확인하려면 을 참조하십시오<block ref="fa826cd698d934925bfe1b514e70b591" category="inline-link-rx"></block>.</block>
  <block id="bea1a33800109358727c67f41cd01d07" category="summary">구성 배포 및 관리에는 Ansible이 실행해야 하는 작업이 포함된 하나 이상의 플레이북을 실행해야 전체 시스템을 원하는 상태로 되돌릴 수 있습니다.</block>
  <block id="40184afe39cc9f2361b3b73e0695976d" category="doc">BeeGFS 구축</block>
  <block id="a5cd3ed116608dac017f14c046ea56bf" category="inline-link">역할</block>
  <block id="d0dbcd7fcc2b33ea218a58e2364a462a" category="paragraph">모든 작업이 단일 Playbook에 포함될 수 있지만 복잡한 시스템의 경우 이를 관리하기가 매우 복잡해집니다. Ansible을 사용하면 재사용 가능한 플레이북 및 관련 콘텐츠(예: 기본 변수, 작업, 처리기)를 패키지하는 방법으로 역할을 만들고 배포할 수 있습니다. 자세한 내용은 용 Ansible 설명서를 참조하십시오<block ref="68a1974ca8634592518191ca9775617f" category="inline-link-rx"></block>.</block>
  <block id="63d74efd13802381ddc8b8a65a3a5000" category="paragraph">역할은 종종 관련 역할 및 모듈이 포함된 Ansible 컬렉션의 일부로 배포됩니다. 따라서, 이러한 플레이북은 다양한 NetApp E-Series Ansible 컬렉션에서 주로 다양한 역할을 하지만</block>
  <block id="3fb2d69a2432fdcecc09bb3418ad3ace" category="admonition">2노드 클러스터를 사용하여 쿼럼을 설정할 때 문제를 완화하기 위해 별도의 쿼럼 장치를 Tiebreaker로 구성하지 않는 한 현재 BeeGFS를 구축하려면 최소 2개의 구성 요소(4개의 파일 노드)가 필요합니다.</block>
  <block id="2ab028f46312dfd58cd64798fc7cbf9e" category="list-text">새로운 '플레이북.yml' 파일을 생성하고 다음을 포함합니다.</block>
  <block id="26a3e9e044d0e5b372c4803d6bdeefbd" category="admonition">이 플레이북에서는 파일 노드에 Python 3이 설치되어 있는지 확인하는 몇 가지 "pre_tasks"를 실행하고 제공되는 Ansible 태그가 지원되는지 확인합니다.</block>
  <block id="7cf59981bd844e32610404655f205256" category="list-text">BeeGFS를 배포할 준비가 되면 재고 및 플레이북 파일과 함께 'Ansible-Playbook' 명령을 사용하십시오.</block>
  <block id="f73890e8771abfa1abdc045ab1b722ef" category="paragraph">구축 과정에서 모든 "pre_tasks"를 실행한 다음 실제 BeeGFS 구축을 진행하기 전에 사용자 확인을 묻는 메시지가 표시됩니다.</block>
  <block id="efd5cfa405ebe66e35820b347b961b90" category="paragraph">다음 명령을 실행하여 필요에 따라 포크 수를 조정합니다(아래 참고 참조).</block>
  <block id="e1f7c8e8d5a879b01dcf2e832140f992" category="inline-link">Ansible 성능 조정</block>
  <block id="2485710fb8c15237f98f63beae48b455" category="inline-link">플레이북 실행 제어</block>
  <block id="44e3c962bed95de75adc370adf17965e" category="admonition">특히 대규모 배포의 경우 Ansible에서 병렬로 구성하는 호스트의 수를 늘리려면 '포크' 매개 변수를 사용하여 기본 포크 수(5)를 재정의하는 것이 좋습니다. (자세한 내용은 을 참조하십시오 <block ref="1ad83cdd7d1451f25e3de1b6b6ab91b1" category="inline-link-rx"></block> 및<block ref="2f92d47aead0a3ef15304d32faf6a032" category="inline-link-rx"></block>참조) 최대 값 설정은 Ansible 컨트롤 노드에서 사용할 수 있는 처리 능력에 따라 달라집니다. 위의 20개 예는 CPU 4개(인텔(R) 제온(R) 골드 6146 CPU @ 3.20GHz)가 장착된 가상 Ansible 컨트롤 노드에서 실행되었습니다.</block>
  <block id="e5e4c2e4c004bc7dbd4a04d4b0971e53" category="paragraph">Ansible 제어 노드와 BeeGFS 파일 및 블록 노드 간의 구축 및 네트워크 성능 크기에 따라 구축 시간이 달라질 수 있습니다.</block>
  <block id="c38012b2187d10d4a33d168693918570" category="summary">각 구성 요소는 HDR(200GB) InfiniBand를 사용하여 2개의 NetApp 블록 노드에 직접 연결된 검증된 x86 파일 노드 2개로 구성됩니다.</block>
  <block id="0893812920a9268362b89a618b2f05c4" category="paragraph">각 구성 요소는 HDR(200GB) InfiniBand 케이블을 사용하여 두 블록 노드에 직접 연결된 검증된 x86 파일 노드 2개로 구성됩니다.</block>
  <block id="cf173c7219b93e53cad26c1f5975c527" category="admonition">각 구성 요소에 BeeGFS 파일 노드가 2개 포함되어 있으므로 페일오버 클러스터에 쿼럼을 설정하려면 최소 2개의 구성 요소가 필요합니다. 2노드 클러스터를 구성할 수 있지만 일부 시나리오에서는 성공적인 페일오버가 발생하지 않도록 이 구성에 제한이 있습니다. 2노드 클러스터가 필요한 경우 이 구축 절차에 포함되지 않지만 3차 디바이스를 Tiebreaker로 통합할 수도 있습니다.</block>
  <block id="0cc464de9a37ad072fa7529593389b2a" category="paragraph">별도로 언급하지 않는 한, 다음 단계는 BeeGFS 메타데이터 및 스토리지 서비스 또는 스토리지 서비스만 실행하는 데 사용되는지 여부와 관계없이 클러스터의 각 구성 요소에 대해 동일합니다.</block>
  <block id="ee6202c3dca3dfe457b79b5ff39c7765" category="list-text">InfiniBand 모드에서 PCIe 4.0 ConnectX-6 이중 포트 호스트 채널 어댑터(HCA) 4개로 각 BeeGFS 파일 노드를 구성하고 PCIe 슬롯 2, 3, 5 및 6에 설치합니다.</block>
  <block id="9df6f3b087eea6552beb54d44653501a" category="list-text">이중 포트 200GB 호스트 인터페이스 카드(HIC)로 각 BeeGFS 블록 노드를 구성하고 두 스토리지 컨트롤러 각각에 HIC를 설치합니다.</block>
  <block id="31562d2b8d25ec86381df6ff0157e4b7" category="paragraph">두 개의 BeeGFS 파일 노드가 BeeGFS 블록 노드 위에 있도록 구성 요소를 랙에 설치하십시오. 다음 그림은 BeeGFS 빌딩 블록에 대한 올바른 하드웨어 구성을 보여 줍니다(후면).</block>
  <block id="7a549152f69a4c5a4d90a9ad467016da" category="paragraph"><block ref="7a549152f69a4c5a4d90a9ad467016da" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9e5081bbd0a64102ab8844f96776d6ea" category="admonition">운영 활용 사례에 대한 전원 공급 장치 구성은 일반적으로 중복 PSU를 사용해야 합니다.</block>
  <block id="cf31d049daa8cd238cb4238371f2e5d0" category="list-text">필요한 경우 각 BeeGFS 블록 노드에 드라이브를 설치합니다.</block>
  <block id="eb86aba8f900c8f076cdcddafcf7271f" category="list-text">빌딩 블록을 사용하여 BeeGFS 메타데이터 및 스토리지 서비스를 실행하고 작은 드라이브를 메타데이터 볼륨에 사용하는 경우 아래 그림과 같이 가장 바깥쪽 드라이브 슬롯에 채워졌는지 확인합니다.</block>
  <block id="c448ee45144a8930f2211d0a4edb7b91" category="list-text">모든 구성 요소 구성에서 드라이브 엔클로저가 완전히 채워지지 않은 경우 최적의 성능을 위해 슬롯 0–11 및 12–23에 동일한 수의 드라이브가 채워졌는지 확인하십시오.</block>
  <block id="4885044112b3b6c6858ae6802eb99831" category="paragraph"><block ref="4885044112b3b6c6858ae6802eb99831" category="inline-image-macro-rx" type="image"></block></block>
  <block id="472ae30ca7767b7347c25c071e0e4b13" category="list-text">파일 및 블록 노드에 케이블을 연결하려면 1m InfiniBand HDR 200GB 직접 연결 구리 케이블을 사용하여 아래 그림에 표시된 토폴로지와 일치시킵니다.</block>
  <block id="835b8f1e6b31f0d45576eed50cfe4027" category="paragraph"><block ref="835b8f1e6b31f0d45576eed50cfe4027" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7fd5b7ef2a561c49e1b59a838397af45" category="admonition">여러 빌딩 블록의 노드는 직접 연결되지 않습니다. 각 구성 요소는 독립형 장치로 취급해야 하며 구성 요소 간의 모든 통신은 네트워크 스위치를 통해 이루어집니다.</block>
  <block id="ca7450c6e9a714419bebd35c8d11414a" category="list-text">2m(또는 적절한 길이) InfiniBand HDR 200GB 직접 연결 구리 케이블을 사용하여 각 파일 노드의 나머지 InfiniBand 포트를 스토리지 네트워크에 사용할 InfiniBand 스위치에 케이블로 연결합니다.</block>
  <block id="678e3f5ded0c872017877baf55a34219" category="paragraph">사용 중인 중복 InfiniBand 스위치가 있는 경우 다음 그림에서 녹색으로 강조 표시된 포트를 서로 다른 스위치에 케이블로 연결합니다.</block>
  <block id="7a8dd1c52597fd7244751f757c26132e" category="paragraph"><block ref="7a8dd1c52597fd7244751f757c26132e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="57f799feabdc3b75aa704ff51e74f4c1" category="list-text">필요한 경우 동일한 케이블 연결 지침에 따라 추가 구성 요소를 조립합니다.</block>
  <block id="6a2ae129e5b77fd39f068e6cdee42d2a" category="admonition">단일 랙에 구축할 수 있는 총 구성 요소 수는 각 사이트의 사용 가능한 전력 및 냉각에 따라 다릅니다.</block>
  <block id="b11764419626b2eff6352f3d8e6022e3" category="summary">Ansible 제어 노드를 설정하려면 솔루션을 구성하는 데 사용할 수 있는 모든 파일 및 블록 노드의 관리 포트에 대한 네트워크 액세스를 갖춘 가상 머신 또는 물리적 머신을 식별합니다.</block>
  <block id="bfcf60c321d0d2cb85402c7a22d208b9" category="paragraph">Ansible 제어 노드를 설정하려면 솔루션을 구성하는 데 사용할 수 있는 모든 파일 및 블록 노드의 관리 포트에 대한 네트워크 액세스를 갖춘 가상 머신 또는 물리적 머신을 식별해야 합니다.</block>
  <block id="c98e4789c5801c863a516b10b7663838" category="paragraph">다음 단계는 CentOS 8.4에서 테스트되었습니다. 선호하는 Linux 배포판에 대한 단계는 를 참조하십시오<block ref="34c856f227a1cab1577af9d235784d24" category="inline-link-rx"></block>.</block>
  <block id="9987c24bf4e936399e49e8ef8615083d" category="list-text">Python 3.9를 설치하고 올바른 버전의 PIP가 설치되어 있는지 확인합니다.</block>
  <block id="bc55433e1f3f1b08c02a0254a0f864c1" category="list-text">심볼 링크를 생성하여 'python3' 또는 'python'이 호출될 때마다 Python 3.9 바이너리가 사용되도록 합니다.</block>
  <block id="e7a81038c18b15bf5d97b77fb110af03" category="list-text">NetApp BeeGFS 컬렉션에 필요한 Python 패키지를 설치합니다.</block>
  <block id="7f883f5609524995f000fc99b8f5691a" category="admonition">지원되는 Ansible 버전과 필요한 모든 Python 패키지를 설치하려면 BeeGFS 컬렉션의 Readme 파일을 참조하십시오. 지원되는 버전은 에도 나와 있습니다 <block ref="786d34f336ab7f462feb4fe8776c8670" category="inline-link-macro-rx"></block>.</block>
  <block id="a36d9a848f44be3e2b8d092a5861995a" category="list-text">올바른 버전의 Ansible 및 Python이 설치되어 있는지 확인하십시오.</block>
  <block id="4ac0a4015ebef3209a5f3acb61110dd9" category="list-text">Git 또는 BitBucket과 같은 소스 제어 시스템에 BeeGFS 구축을 설명하는 데 사용되는 Ansible 인벤토리를 저장한 다음 Git를 설치하여 이러한 시스템과 상호 작용합니다.</block>
  <block id="f2f38616eaf6d21846071c00e89109b4" category="list-text">암호 없는 SSH를 설정합니다. 이는 Ansible에서 Ansible 제어 노드의 원격 BeeGFS 파일 노드에 액세스할 수 있는 가장 쉬운 방법입니다.</block>
  <block id="3087af73e5990976755e4c56b6e7c754" category="list-text">필요한 경우 Ansible 컨트롤 노드에서 ssh-keygen을 사용하여 공개 키 쌍을 생성합니다</block>
  <block id="c5d36867af8fc130f7a6b6bd87d51d23" category="list-text">ssh-copy-id &lt;ip_or_hostname&gt;'을 사용하여 각 파일 노드에 대해 암호 없는 SSH를 설정합니다</block>
  <block id="c4e4fc85a76d5e87beac70d1fa166882" category="paragraph">블록 노드에 암호 없는 SSH를 * 설정하지 마십시오. 이 작업은 지원되거나 필요하지 않습니다.</block>
  <block id="03f38aac08b6c6c3e6e3afc965fedbcc" category="list-text">Ansible Galaxy를 사용하여 에 나열된 BeeGFS 컬렉션 버전을 설치합니다 <block ref="786d34f336ab7f462feb4fe8776c8670" category="inline-link-macro-rx"></block>.</block>
  <block id="b113449496b52721b53dc04e5120a57b" category="paragraph">이 설치에는 NetApp SANtricity 소프트웨어 및 호스트 컬렉션과 같은 추가 Ansible 종속성이 포함됩니다.</block>
  <block id="a8bb1258f035db2e1b989badd7504202" category="summary">파일 및 블록 노드의 구성을 정의하려면 구축할 BeeGFS 파일 시스템을 나타내는 Ansible 인벤토리를 생성합니다.</block>
  <block id="811a6b46c73b2ff846d806c69f166392" category="paragraph">파일 및 블록 노드의 구성을 정의하려면 구축할 BeeGFS 파일 시스템을 나타내는 Ansible 인벤토리를 생성합니다. 인벤토리는 원하는 BeeGFS 파일 시스템을 설명하는 호스트, 그룹 및 변수를 포함합니다.</block>
  <block id="f710d81b04cfd57ef65bc4cca28bc3d4" category="section-title">1단계: 모든 빌딩 블록에 대한 설정을 정의합니다</block>
  <block id="08ecdaa3e32e095bd8f7ecec87a6ffe1" category="paragraph">개별적으로 적용할 수 있는 구성 프로파일에 관계없이 모든 구성 요소에 적용되는 구성을 정의합니다.</block>
  <block id="135b308ed83c53f1516b7c754566d1c4" category="list-title">시작하기 전에</block>
  <block id="17de9612747c3e48aee3a32b1da30959" category="list-text">BitBucket 또는 Git와 같은 소스 제어 시스템을 사용하여 Ansible 인벤토리 및 플레이북 파일이 포함된 디렉토리의 콘텐츠를 저장합니다.</block>
  <block id="fc62f55b3e3e861f3b20a7ae40279cab" category="list-text">Git가 무시해야 하는 파일을 지정하는 '.gignore' 파일을 만듭니다. 이렇게 하면 Git에 큰 파일을 저장하지 않아도 됩니다.</block>
  <block id="1633329793556e695f8ae53c7f3c8756" category="list-text">Ansible 제어 노드에서 Ansible 인벤토리 및 플레이북 파일을 저장하는 데 사용할 디렉토리를 식별하십시오.</block>
  <block id="2af34d0fd4b17ecc42b7fb40d3a2019d" category="paragraph">별도로 언급하지 않는 한, 이 단계에서 만든 모든 파일과 디렉터리와 다음 단계는 이 디렉터리를 기준으로 생성됩니다.</block>
  <block id="31f13138a9fb78368dd1c5b8b9cb522e" category="list-text">다음 하위 디렉터리를 만듭니다.</block>
  <block id="f502c582ecc3459969f6ae37e60464d1" category="paragraph">HOST_VAR'입니다</block>
  <block id="f2151fe487fd8f761c16c5d92971a46f" category="paragraph">group_vars입니다</block>
  <block id="5fa06f80972ff05cf8eb18aa9af90bbd" category="paragraph">'패키지'</block>
  <block id="49266d47983011d7ceee48c764eaad20" category="section-title">2단계: 개별 파일 및 블록 노드에 대한 설정을 정의합니다</block>
  <block id="bcbd88b78dd9388280471b20c50ef836" category="paragraph">개별 파일 노드 및 개별 구성 요소 노드에 적용되는 구성을 정의합니다.</block>
  <block id="4ace9bc4fa627e77f6406dd2f64e2028" category="list-text">'host_vars/'에서 다음 내용으로 이름이 '&lt;HOSTNAME&gt;.yml'인 각 BeeGFS 파일 노드에 대한 파일을 만듭니다. BeeGFS 클러스터 IP 및 호스트 이름에 대해 채울 콘텐츠에 대한 메모는 홀수와 짝수로 끝나는 것이 좋습니다.</block>
  <block id="65742ecf20e6c51de487a8a5c4e5d085" category="paragraph">처음에는 파일 노드 인터페이스 이름이 여기에 나열된 것과 일치합니다(예: ib0 또는 ibs1f0). 이러한 사용자 정의 이름은 에 구성되어 있습니다 <block ref="9c327e4b0e0a41a0187df973a6c1c1f1" category="inline-xref-macro-rx"></block>.</block>
  <block id="c1df6ea154e4f3c22584570de9017604" category="admonition">BeeGFS 클러스터를 이미 구축한 경우, NVMe/IB에 사용되는 클러스터 IP 및 IP를 포함하여 정적으로 구성된 IP 주소를 추가하거나 변경하기 전에 클러스터를 중지해야 합니다. 이러한 변경 사항이 적절히 적용되고 클러스터 작업을 방해하지 않도록 이 작업이 필요합니다.</block>
  <block id="64f6e7ce4bce20648e5b5817cc7c9d5d" category="list-text">'host_vars/'에서 '&lt;HOSTNAME&gt;.yml'이라는 이름의 각 BeeGFS 블록 노드에 대한 파일을 생성하고 다음 내용으로 채웁니다.</block>
  <block id="350317d433df31d79bf0ded1b3748715" category="paragraph">홀수와 짝수로 끝나는 스토리지 배열 이름에 대한 내용을 입력할 때 특히 주의해야 합니다.</block>
  <block id="d9aa2babb29bda2ebcdcb05c255e1dd3" category="paragraph">각 블록 노드에 대해 하나의 파일을 생성하고 두 컨트롤러 중 하나의 "&lt;management_ip&gt;"를 지정합니다(일반적으로 A).</block>
  <block id="a79b02f70003beee254343e4cae10ad4" category="section-title">3단계: 모든 파일 및 블록 노드에 적용되어야 하는 설정을 정의합니다</block>
  <block id="7a7623c76e8a35ad9b47b72876017ffc" category="paragraph">그룹에 해당하는 파일 이름으로 group_vars 아래에 있는 호스트 그룹에 공통된 구성을 정의할 수 있습니다. 이렇게 하면 여러 위치에서 공유 구성이 반복되지 않습니다.</block>
  <block id="b8250a298e8217ebff19d4f7c62cf654" category="inline-link">변수 사용</block>
  <block id="45c67f165a1990ff04bfa4ffd3ad1908" category="paragraph">호스트는 둘 이상의 그룹에 있을 수 있으며 런타임 시 Ansible은 변수 우선 순위 규칙에 따라 특정 호스트에 적용되는 변수를 선택합니다. (이 규칙에 대한 자세한 내용은 용 Ansible 설명서를 참조하십시오<block ref="e846c866a706aed07204d4b81c43f562" category="inline-link-rx"></block>참조)</block>
  <block id="30670ef79ffcebf619cb84794bb9f467" category="paragraph">호스트 대 그룹 지정은 이 절차의 마지막을 위해 생성되는 실제 Ansible 인벤토리 파일에 정의됩니다.</block>
  <block id="13fe78da26730165534ca728d16729df" category="paragraph">Ansible에서는 모든 호스트에 적용할 구성을 '모두'라는 그룹으로 정의할 수 있습니다. 다음 내용으로 group_vars/all.yml 파일을 만듭니다.</block>
  <block id="970c2de774d4cba551050f0b96346cc6" category="section-title">4단계: 모든 파일 노드에 적용할 구성을 정의합니다</block>
  <block id="68decee7f537598fe42c449c7effd748" category="paragraph">파일 노드의 공유 구성은 ha_cluster라는 그룹에 정의됩니다. 이 섹션의 단계에서는 group_vars/ha_cluster.yml 파일에 포함되어야 하는 구성을 작성합니다.</block>
  <block id="01eabbaba4e3200ffffeaf687ced4089" category="list-text">파일 맨 위에서 파일 노드의 'SUDO' 사용자로 사용할 암호를 포함하여 기본값을 정의합니다.</block>
  <block id="c61c5c1226a5daff294e618d1b90ec26" category="admonition">특히 프로덕션 환경에서는 암호를 일반 텍스트로 저장하지 마십시오. 대신 Ansible Vault를 사용하십시오(참조<block ref="69d38d4b5deda302461f6461c5317006" category="inline-link-rx"></block>) 또는 '--Ask-when-pass' 옵션을 선택합니다. 'Ansible_ssh_user'가 이미 'root'인 경우 Anabilities_BAREY_PASSWORD를 선택적으로 생략할 수 있습니다.</block>
  <block id="3eeae040dcd4e8e08ba89cd729351414" category="list-text">필요에 따라 고가용성(HA) 클러스터의 이름을 구성하고 클러스터 내 통신을 위한 사용자를 지정합니다.</block>
  <block id="22bf408c8339ca14dab3745bbe56780d" category="paragraph">전용 IP 주소 지정 체계를 수정하는 경우 기본 "begfs_ha_mgmtd_floating_ip"도 업데이트해야 합니다. 나중에 BeeGFS 관리 리소스 그룹에 대해 구성한 것과 일치해야 합니다.</block>
  <block id="ba4d50db9221cc812d5f7981d4600c2d" category="paragraph">"begfs_ha_alert_email_list"를 사용하여 클러스터 이벤트에 대한 경고를 수신할 e-메일을 하나 이상 지정합니다.</block>
  <block id="e69d5d030b5267144694edd30e58fa4b" category="admonition">중복된 것처럼 보이지만 BeeGFS 파일 시스템을 단일 HA 클러스터 이상으로 확장하는 경우 "begfs_ha_mgmtd_floating_ip"가 중요합니다. 이후 HA 클러스터는 추가 BeeGFS 관리 서비스 없이 구축되고 첫 번째 클러스터에서 제공하는 관리 서비스를 가리키도록 구축됩니다.</block>
  <block id="7509dcf152f48abcba19fa72adedb808" category="inline-link">Red Hat High Availability 클러스터에서 펜싱을 구성합니다</block>
  <block id="da185ecc8c2bce6af5f506542a665aab" category="list-text">펜싱 에이전트를 구성합니다. (자세한 내용은 을 참조하십시오<block ref="dc7760afd7fe301addd396cbb1b31319" category="inline-link-rx"></block>참조) 다음 출력에서는 일반적인 펜싱 에이전트를 구성하는 예를 보여 줍니다. 다음 옵션 중 하나를 선택합니다.</block>
  <block id="b2f365e9dc240069eb174f596f8086dd" category="paragraph">이 단계에서는 다음 사항에 유의하십시오.</block>
  <block id="83a5cc26327b36012de2442c022e0357" category="list-text">기본적으로 펜싱은 활성화되어 있지만 fencing_agent_를 구성해야 합니다.</block>
  <block id="502142ce464e9e0c49b233594ce3af26" category="list-text">pcmk_host_map 또는 pcmk_host_list에 지정된 '&lt;HOSTNAME&gt;'은(는) Ansible 인벤토리의 호스트 이름과 일치해야 합니다.</block>
  <block id="08c76f94c7c5d2fb0509d39d58f7d298" category="list-text">특히 운영 환경에서는 펜싱 없이 BeeGFS 클러스터를 실행할 수 없습니다. 이는 주로 블록 디바이스와 같은 리소스 종속성이 포함된 BeeGFS 서비스가 문제로 인해 페일오버될 때 파일 시스템 손상 또는 기타 바람직하지 않거나 예기치 않은 동작으로 이어질 수 있는 여러 노드에 의한 동시 액세스 위험이 발생하지 않도록 하기 위한 것입니다. 펜싱을 비활성화해야 하는 경우 BeeGFS HA 역할의 시작 가이드의 일반 참고를 참조하여 ha_cluster_crm_config_options ["STONITH -enabled"]"를 false 로 설정합니다.</block>
  <block id="8134b950ce435c1478c36f8d9e28640a" category="list-text">사용 가능한 노드 레벨 펜싱 장치가 여러 개 있으며 BeeGFS HA 역할은 Red Hat HA 패키지 리포지토리에서 사용 가능한 펜싱 에이전트를 구성할 수 있습니다. 가능한 경우 무정전 전원 공급 장치(UPS) 또는 랙 배전 장치(rPDU)를 통해 작동하는 펜싱 에이전트를 사용합니다. BMC(베이스보드 관리 컨트롤러) 또는 서버에 내장된 기타 표시등 출력 장치와 같은 일부 펜싱 에이전트가 특정 장애 시나리오에서 Fence 요청에 응답하지 않을 수 있기 때문입니다.</block>
  <block id="6793d5cb3a8bc008d05678615f821ca7" category="list-text">Linux OS에서 권장되는 성능 조정을 활성화합니다.</block>
  <block id="951cd0f9ef758f90609564a78a7f36a2" category="paragraph">일반적으로 성능 매개 변수에 대한 기본 설정은 대부분의 사용자가 찾지만 선택적으로 특정 작업 부하에 대한 기본 설정을 변경할 수 있습니다. 따라서 이러한 권장 사항은 BeeGFS 역할에 포함되지만 기본적으로 설정되어 있지 않으므로 사용자가 파일 시스템에 적용된 튜닝에 대해 알 수 있습니다.</block>
  <block id="2e468d52e0778656623f6a98e831b3c0" category="paragraph">성능 조정을 활성화하려면 다음을 지정하십시오.</block>
  <block id="5886796779dc029ac41ffca429f9f5d1" category="list-text">(선택 사항) 필요에 따라 Linux OS에서 성능 조정 매개 변수를 조정할 수 있습니다.</block>
  <block id="fe7cbbcd6bbbe894cb7364e04d36c7ae" category="inline-link">E-Series BeeGFS GitHub 사이트</block>
  <block id="a2a731b1d02a58e1e3cbcdae15a63023" category="paragraph">조정할 수 있는 사용 가능한 튜닝 매개 변수의 전체 목록은 에서 BeeGFS HA 역할의 성능 조정 기본값 섹션을 참조하십시오<block ref="32c82538a26b94ce448b7cce29eb6898" category="inline-link-rx"></block>. 이 파일의 클러스터에 있는 모든 노드 또는 개별 노드에 대한 'host_vars' 파일에 대해 기본값을 재정의할 수 있습니다.</block>
  <block id="3abafbb6a7adaface99f5d9cd23b12d0" category="list-text">블록과 파일 노드 간에 전체 200GB/HDR 연결을 허용하려면 Mellanox Open Fabrics Enterprise Distribution(MLNX_OFED)의 OpenSM(Open Subnet Manager) 패키지를 사용하십시오. (받은 편지함인 OpenSM 패키지는 필요한 가상화 기능을 지원하지 않습니다.) Ansible을 사용하여 구축할 수도 있지만, 먼저 BeeGFS 역할을 실행하는 데 사용되는 Ansible 제어 노드에 원하는 패키지를 다운로드해야 합니다.</block>
  <block id="b98ee7eab01ffcc8be1325c0937f01e8" category="list-text">컬링이나 원하는 도구를 사용하여 Mellanox 웹 사이트의 기술 요구 사항 섹션에 나열된 OpenSM 버전의 패키지를 "packages/" 디렉토리로 다운로드합니다. 예를 들면 다음과 같습니다.</block>
  <block id="372ec1e9d1761b6aa16b9f0b54a4433b" category="list-text">group_vars/ha_cluster.yml에 다음 파라미터를 입력합니다(필요에 따라 패키지 조정).</block>
  <block id="382cd5df5d20e8ee60bea9f8be1884e3" category="list-text">논리적 InfiniBand 포트 식별자를 기본 PCIe 디바이스에 일관되게 매핑하도록 'udev' 규칙을 구성합니다.</block>
  <block id="acb63a2b1a344472ec1b72c168bf5a95" category="paragraph">udev 규칙은 BeeGFS 파일 노드로 사용되는 각 서버 플랫폼의 PCIe 토폴로지에 고유해야 합니다.</block>
  <block id="8cec215dcbcd9866be7ad7f12652d9bd" category="paragraph">검증된 파일 노드에 대해 다음 값을 사용합니다.</block>
  <block id="b535d5891e9112526732586cf8225d93" category="list-text">(선택 사항) 메타데이터 대상 선택 알고리즘을 업데이트합니다.</block>
  <block id="e3c1663ae83b766d79e4b2be55767666" category="inline-link">BeeGFS 시스템을 벤치마킹합니다</block>
  <block id="8dff66e73ac10da6c457b7092c6f9005" category="admonition">검증 테스트에서는 일반적으로 성능 벤치마킹 중에 테스트 파일이 모든 BeeGFS 스토리지 대상에 고르게 분산되도록 하기 위해 "랜덤 로빈"이 사용되었습니다(벤치마킹을 위한 자세한 내용은 BeeGFS 사이트 참조)<block ref="831dbcfeece1d9e52170bb11173ba315" category="inline-link-rx"></block>)를 클릭합니다. 실제 환경에서 사용하면 낮은 번호의 대상이 높은 번호의 목표보다 빠르게 채워질 수 있습니다. 기본 '무작위 배정' 값을 사용하기만 하면 사용 가능한 모든 대상을 활용하는 동시에 우수한 성능을 제공하는 것으로 나타났습니다.</block>
  <block id="aad0b8e6a3552eebcdcf125f218d1954" category="section-title">5단계: 공통 블록 노드에 대한 구성을 정의합니다</block>
  <block id="f9ed56c11a1443e285b3d786249fe6aa" category="paragraph">블록 노드의 공유 구성은 eseries_storage_systems라는 그룹에 정의되어 있습니다. 이 섹션의 단계에서는 group_vars/eseries_storage_systems.yml 파일에 포함되어야 하는 구성을 작성합니다.</block>
  <block id="7d304d17d15c3332b9d8584fa30f070b" category="list-text">Ansible 연결을 로컬로 설정하고 시스템 암호를 제공하며 SSL 인증서를 확인해야 하는지 여부를 지정합니다. (일반적으로 Ansible은 SSH를 사용하여 관리 호스트에 연결하지만, 블록 노드로 사용되는 NetApp E-Series 스토리지 시스템의 경우 모듈은 통신에 REST API를 사용합니다.) 파일 맨 위에 다음을 추가합니다.</block>
  <block id="41c70fb9d233363d68fe27194430adc1" category="admonition">암호를 일반 텍스트로 나열하는 것은 권장되지 않습니다. Ansible 볼트를 사용하거나 '- Extra-VAR'을 사용하여 Ansible을 실행할 때 'eseries_system_password'를 제공하십시오.</block>
  <block id="a18d6a60f542af2e3b0784928e17f417" category="list-text">최적의 성능을 보장하기 위해 에 블록 노드에 대해 나열된 버전을 설치합니다 <block ref="786d34f336ab7f462feb4fe8776c8670" category="inline-link-macro-rx"></block>.</block>
  <block id="8c41baf1ca98e1184f48c4721d44d431" category="inline-link">NetApp Support 사이트</block>
  <block id="38119f4253b4080e689702afd647df1f" category="paragraph">에서 해당 파일을 다운로드합니다<block ref="3f80e15ba326a9eb1fc39b6d8ba81472" category="inline-link-rx"></block>. 수동으로 업그레이드하거나 Ansible 제어 노드의 'packages/' 디렉토리에 추가한 다음, Ansible을 사용하여 업그레이드하려면 "eseries_storage_systems.yml"에 다음 매개 변수를 입력합니다.</block>
  <block id="a5a82f3b02ae57420ae1197446e1efc0" category="list-text">에서 Block 노드에 설치된 드라이브에 사용할 수 있는 최신 드라이브 펌웨어를 다운로드하여 설치합니다<block ref="7bf536b69fb1e52c85b84904e073cbdb" category="inline-link-rx"></block>. 수동으로 업그레이드하거나 Ansible 제어 노드의 'packages/' 디렉토리에 추가한 다음, Ansible을 사용하여 업그레이드하려면 "eseries_storage_systems.yml"에 다음 매개 변수를 입력합니다.</block>
  <block id="72423a5fa99fafb4c2dc7b7e7f7d7962" category="admonition">eseries_drive_firmware_upgrade_drives_online을 "false"로 설정하면 업그레이드 속도가 빨라지지만 BeeGFS가 구축되기 전에는 수행할 수 없습니다. 이 설정은 응용 프로그램 오류를 방지하기 위해 업그레이드 전에 드라이브에 대한 모든 I/O를 중지하도록 하기 때문입니다. 볼륨을 구성하기 전에 온라인 드라이브 펌웨어 업그레이드를 수행하는 것이 여전히 빠르지만 나중에 문제가 발생하지 않도록 항상 이 값을 "참"으로 설정하는 것이 좋습니다.</block>
  <block id="2b0551e04ffc3a713c07e9a9611b9897" category="list-text">성능을 최적화하려면 글로벌 구성을 다음과 같이 변경합니다.</block>
  <block id="6b7cf272a4e3aeaf52c2d0ca991829e5" category="list-text">최적의 볼륨 프로비저닝 및 동작을 위해 다음 매개 변수를 지정합니다.</block>
  <block id="b969df7be52ed192c298428e4fb0e696" category="admonition">'eseries_storage_pool_usable_drives'에 지정된 값은 NetApp EF600 블록 노드에만 해당되며 드라이브가 새 볼륨 그룹에 할당되는 순서를 제어합니다. 이 주문을 통해 각 그룹에 대한 입출력이 백엔드 드라이브 채널에 균등하게 분산됩니다.</block>
  <block id="7042a03d018b94aee36197baf79897b2" category="summary">성능을 최대화하려면 파일 노드로 사용하는 서버 모델에서 시스템 설정을 구성하는 것이 좋습니다.</block>
  <block id="e95c3b26aabb0242b0a38d72568b125a" category="paragraph">성능을 최대화하려면 파일 노드로 사용하는 서버 모델에서 시스템 설정을 구성하는 것이 좋습니다.</block>
  <block id="291e90fb83bca326d06b5479d0ae7197" category="paragraph">시스템 설정은 파일 노드로 사용하는 서버 모델에 따라 달라집니다. 이 항목에서는 검증된 Lenovo ThinkSystem SR665 서버 파일 노드에 대한 시스템 설정을 구성하는 방법에 대해 설명합니다.</block>
  <block id="cfa9d7ef51eae23751a0ea54765b99fd" category="section-title">UEFI 인터페이스를 사용하여 시스템 설정을 조정합니다</block>
  <block id="7afe745e5e5ded0e0cf311f6ab05ce41" category="paragraph">Lenovo SR665 서버의 시스템 펌웨어에는 UEFI 인터페이스를 통해 설정할 수 있는 다양한 조정 매개변수가 포함되어 있습니다. 이러한 튜닝 매개 변수는 서버의 작동 방식 및 서버 성능에 미치는 모든 측면에 영향을 줄 수 있습니다.</block>
  <block id="01d5e77f89697d310442aa744d5c4068" category="paragraph">UEFI 설정 &gt; 시스템 설정 * 에서 다음 시스템 설정을 조정합니다.</block>
  <block id="6e2e169ab41f56781f3cd65629914fc6" category="section-title">작동 모드 메뉴</block>
  <block id="f7adfd4c98207b1161c7b693c16fa9ea" category="cell">* 시스템 설정 *</block>
  <block id="a3fb412bb8de9718b8510aa99340221a" category="cell">* 로 변경합니다</block>
  <block id="1c2631aa94b6d5e1cc826b0cb76a87ba" category="paragraph">작동 모드</block>
  <block id="90589c47f06eb971d548591f23c285af" category="paragraph">맞춤형</block>
  <block id="43e16592d1b7c57c68cdf68bcd7f2fbd" category="paragraph">cTDP</block>
  <block id="e1ba155a9f2e8c3be94020eef32a0301" category="paragraph">수동</block>
  <block id="db0877bc3fbb4ce0ffd2f36fa5470581" category="paragraph">cTDP 설명서</block>
  <block id="9de6d14fff9806d4bcd1ef555be766cd" category="paragraph">350</block>
  <block id="43287f46609a4dc60f40223b99452814" category="paragraph">패키지 전력 제한</block>
  <block id="8bec16a6c589939ad9d0a3c20f7dd8dc" category="paragraph">효율성 모드</block>
  <block id="bcfaccebf745acfd5e75351095a5394a" category="paragraph">사용 안 함</block>
  <block id="50a4d260500229aae705dffbef792499" category="paragraph">Global-Cstate-Control</block>
  <block id="bbb8600e28b07b4e7765ccb37c8ba72d" category="paragraph">SOC P 상태</block>
  <block id="16a2e561c536a77cbfd10490ea398be6" category="paragraph">P0</block>
  <block id="f7d2d14860cfdee82e8cf9418c1ec624" category="paragraph">DF C 상태</block>
  <block id="450e20de3fc0482fa7bdadc4622005ed" category="paragraph">P - 상태 1</block>
  <block id="9c1a39470ba5d6a8856c5e813e20ef6b" category="paragraph">메모리 전원 끄기 활성화</block>
  <block id="3011761cbf6a8eb38a41f6b38210c119" category="paragraph">소켓당 NUMA 노드</block>
  <block id="4142a6b2c0ac3aaf643751457e9aad6a" category="paragraph">NPS1</block>
  <block id="cdceaf6498461c15ce1ae0800bf60c66" category="section-title">Device and I/O ports(장치 및 I/O 포트) 메뉴</block>
  <block id="fb31ba7c369028665e7e1a20bd645da6" category="paragraph">IOMMU</block>
  <block id="ada62bbe41ae187c3f0f777ffbd44d28" category="section-title">전원 메뉴</block>
  <block id="e7dc1149b98b9a234419b52cb65c86eb" category="paragraph">PCIe 전원 브레이크</block>
  <block id="a4fb96bd64d4ecceb3f0f416f7032bb9" category="section-title">프로세서 메뉴</block>
  <block id="78ee21f7e9d290c773c1aa6ae0d03303" category="paragraph">글로벌 C 상태 제어</block>
  <block id="dc8a824c345b5e3bbaa79fce219830c2" category="paragraph">SMT 모드</block>
  <block id="28fb70bc7fdb441f9e6550205a24c92c" category="paragraph">CPPC</block>
  <block id="83ed73e76e0c1cfe38ef9627b7ae0fe0" category="section-title">Redfish API를 사용하여 시스템 설정을 조정합니다</block>
  <block id="2bfb51b6fb78d5540135d28668652ab6" category="paragraph">UEFI 설정 외에도 Redfish API를 사용하여 시스템 설정을 변경할 수 있습니다.</block>
  <block id="33e221e2cea2342a6bae3c4c24f33827" category="inline-link">DMTF 웹 사이트</block>
  <block id="d96afe3ab332c2cc42ac69c811923ba7" category="paragraph">Redfish 스키마에 대한 자세한 내용은 를 참조하십시오<block ref="108ef396f9aef1d6bcaea08379b877eb" category="inline-link-rx"></block>.</block>
  <block id="71f5771dab663d80ba4dad1627e3386a" category="summary">업그레이드 개요</block>
  <block id="e9c44bbfd795a5d63d74c6a77afee70d" category="summary">법적 고지 사항은 저작권 선언, 상표, 특허 등에 대한 액세스를 제공합니다.</block>
  <block id="30d965eef5ba25c6b9998ae38270b43e" category="doc">법적 고지</block>
  <block id="6016a2b341113bf496b719905398ecd2" category="section-title">저작권</block>
  <block id="126a02652da6de02962cf1b654fd6376" category="section-title">상표</block>
  <block id="c4ce4761e466527d26b3e3d5ed1006fd" category="paragraph">NetApp, NetApp 로고, NetApp 상표 페이지에 나열된 마크는 NetApp Inc.의 상표입니다. 기타 회사 및 제품 이름은 해당 소유자의 상표일 수 있습니다.</block>
  <block id="be89498d2f8a22ce47c02ba9795fe2af" category="section-title">특허</block>
  <block id="d0b19d36be2c5f16e9aef46c8a452d3d" category="paragraph">NetApp 소유 특허 목록은 다음 사이트에서 확인할 수 있습니다.</block>
  <block id="56c34c6410dd45c5cec44149ad0ce037" category="section-title">개인 정보 보호 정책</block>
  <block id="c0227cef6f07a8cd2ac72f2945b031aa" category="section-title">오픈 소스</block>
  <block id="9b73989307c1975dfa4d5e1581e4afe8" category="paragraph">통지 파일은 NetApp 소프트웨어에 사용된 타사의 저작권 및 라이센스에 대한 정보를 제공합니다.</block>
  <block id="cc1ba14f8dc9bd7ba20e2aa654cde10b" category="inline-link">E-Series/EF-Series SANtricity OS에 대한 알림</block>
  <block id="2dae7f81af3097152530b0bc519d7eb1" category="paragraph"><block ref="2dae7f81af3097152530b0bc519d7eb1" category="inline-link-rx"></block></block>
  <block id="e3b88cba18358b065044f4788449026b" category="summary">지연 시간이 짧은 고성능 NetApp E-Series 스토리지에서 실행되는 BeeGFS 병렬 클러스터 파일 시스템에 대한 솔루션 지원 NetApp의 지원을 받아 비용 효율적이고 관리가 쉬우며 가용성이 높은 HPC 솔루션을 제공합니다.</block>
  <block id="28e8b3e83af233fe7085ba954fc6fd36" category="doc">E-Series 스토리지를 지원하는 NetApp 기반 BeeGFS</block>
  <block id="4929a64464b43e326e35b25ce7e3ceeb" category="sidebar">NetApp 솔루션의 BeeGFS는 NVA(NetApp Verified Architecture)로, BeeGFS 병렬 파일 시스템을 NetApp EF600 스토리지 시스템과 결합합니다. 이 솔루션은 가장 까다로운 워크로드에 대응할 수 있는 안정적이고 확장 가능하며 비용 효율적인 인프라입니다.</block>
  <block id="be11c74c1dd7f307bb80183a90dc2067" category="sidebar">시작하십시오</block>
  <block id="12623d7cc9dff74b7325aa809ffc84df" category="sidebar">블로그 - BeeGFS 및 E-Series에 대해 알아보십시오</block>
  <block id="0af9e7bf64a8e8c1b37ec554248f3d14" category="sidebar">블로그 - 초보자를 위한 BeeGFS</block>
  <block id="6316c96cdd51a54d33d0011cf5f10c81" category="sidebar">블로그 - BeeGFS의 HA</block>
  <block id="d5bc9778dcd2b28ce384782d014e53fc" category="sidebar">비디오 - NetApp 기반의 BeeGFS로 AI 워크로드 가속화</block>
  <block id="b89fcecfac1f6b8376165aabe5b6c5ee" category="sidebar">추가 문서</block>
  <block id="bc4fe2352063642d68529f2aa0ca7ca3" category="sidebar">NetApp 제품 설명서</block>
  <block id="dbd68e15f4c30d2a47d780a9bf4f3da1" category="sidebar">BeeGFS 문서</block>
  <block id="974ad78dc53c253ebfe5b2b8b376f353" category="sidebar">도구 지원</block>
  <block id="d564be87f67790fe4b92faa0eea29c48" category="sidebar">Ansible Galaxy의 NetApp E-Series 컬렉션</block>
  <block id="bc8be72fdc9d6054f356bb2b7f80fd12" category="sidebar">NetApp 상호 운용성 매트릭스</block>
  <block id="668e2078ef1b1722c77cdb5c523a4463" category="sidebar">NetApp 기술 자료</block>
  <block id="2bae42f280067110dfd52cc69a468364" category="sidebar">Active IQ(로그인 필요)</block>
  <block id="c35665ae18bf4eff9afa413fcb281b07" category="sidebar">NetApp 문서에서 BeeGFS 사용</block>
  <block id="f40341c80e215542b4fdfe4e2f2e2a21" category="sidebar">이 사이트에 포함된 내용</block>
  <block id="539652fdf317cc6e27c7373dc6fe13d3" category="sidebar">솔루션 설계를 검토합니다</block>
  <block id="6c24b1b24585abc1454b91e5eb163103" category="sidebar">솔루션 구축</block>
  <block id="c5d1e465274381bca5df236c2a5a7d57" category="sidebar">소프트웨어 배포</block>
  <block id="97ecf64b4f2550ec2c53f49bb9fde847" category="sidebar">Ansible 제어 노드를 설정합니다</block>
  <block id="f99ff2e7716d2f6aa55979e838f0a328" category="sidebar">Ansible 인벤토리를 생성합니다</block>
  <block id="da7f5c02044100badae24523f01941a2" category="sidebar">BeeGFS 구성 요소를 정의합니다</block>
  <block id="8025f3ce3e3e1dd003430788c4be8b5e" category="sidebar">BeeGFS 클러스터 확장</block>
  <block id="e304a70d2f42f62cefb9b474f73a1e91" category="sidebar">권장 볼륨 백분율</block>
  <block id="ba13e086fe19056a379b6240e05651a8" category="sidebar">TR-4915 - AI용 E-Series 및 BeeGFS를 통한 데이터 이동</block>
  <block id="bc893b2686532fc683cb056beffd08aa" category="cell">드라이브 크기(10 + 2 RAID 6) 스토리지 볼륨 그룹</block>
  <block id="132789d9474eae064aef2cd5266138d8" category="section-title">NVIDIA DGX A100 SuperPOD 및 BasePOD 검증</block>
  <block id="d88f3188efb434f39b922170592443b5" category="paragraph">NetApp은 메타데이터와 스토리지 구성 프로필이 적용된 3개의 구성 블록으로 구성된 유사한 BeeGFS 파일 시스템을 사용하여 NVIDIAs DGX A100 SuperPOD에 대한 스토리지 솔루션을 검증했습니다. 검증 노력에는 다양한 스토리지, 머신 러닝 및 딥 러닝 벤치마크를 실행하는 20개의 DGX A100 GPU 서버를 통해 이 NVA에 의해 설명된 솔루션을 테스트하는 작업이 포함되었습니다. NVIDIA DGX A100 SuperPOD에서 사용하도록 인증된 모든 스토리지는 NVIDIA BasePOD 아키텍처에도 자동으로 사용하도록 인증되었습니다.</block>
  <block id="64dc43320ec1a44c390fafb5e2408f4b" category="inline-link">NVIDIA DGX 베이스POD</block>
  <block id="33d753992c8525a016e60650889ef7a9" category="paragraph">자세한 내용은 을 참조하십시오<block ref="917e0b817a1bc5579c3d00c8de7a0790" category="inline-link-rx"></block> 및<block ref="d4d49ddfca3de3daecdc231399362db8" category="inline-link-rx"></block>.</block>
  <block id="e79ef600cb60c3e821f1cef23dcb17c1" category="list-text">NVIDIA DGX A100 SuperPOD 및 NVIDIA BasePOD 아키텍처에 대한 외부 검증</block>
  <block id="1e5b7e91f7684d1e82eca499bd3e9f00" category="paragraph">NetApp 기반의 2세대 BeeGFS는 HPC(고성능 컴퓨팅) 및 HPC 스타일 머신 러닝(ML), 딥 러닝(DL), 유사한 인공 지능(AI) 기술 등 까다로운 워크로드의 성능 요구사항을 충족하도록 최적화되어 있습니다. BeeGFS on NetApp 솔루션은 공유 디스크 HA(고가용성) 아키텍처를 통합하여 워크로드 및 사용 사례에 맞게 확장 가능한 스토리지를 찾듯이 다운타임 또는 데이터 손실을 허용할 수 없는 기업 및 기타 조직의 데이터 내구성 및 가용성 요구사항을 충족합니다. 이 솔루션은 NetApp에서 검증되었을 뿐만 아니라 NVIDIA DGX SuperPOD 및 DGX BasePOD의 스토리지 옵션으로 외부 인증도 받았습니다.</block>
  <block id="aa00436c66c8456a1c9ef0a12178a4ab" category="paragraph-title">서브넷 A: 100.127.0.0/16</block>
  <block id="079e5887eeb92f6f17c9fa25fd464e2a" category="paragraph-title">서브넷 B: 100.128.0.0/16</block>
  <block id="015dd422187100bd2a53cae756db5bcd" category="paragraph-title">하나의 BeeGFS 기본(관리, 메타데이터 및 스토리지) 구성 요소입니다</block>
  <block id="2eb32f267ab2864aa50a3171522c1574" category="paragraph-title">BeeGFS 메타데이터 + 스토리지 구성 요소입니다</block>
  <block id="2cf619569e1d3422599fa7ba3fff04f2" category="paragraph-title">BeeGFS 스토리지 전용 구성 요소입니다</block>
  <block id="9443a11095bad63a50d95ece24842fb2" category="paragraph-title">BeeGFS 빌딩 블록 3개</block>
  <block id="3c793d71f0d81892f28ab10f661381c8" category="paragraph-title">하나의 BeeGFS 메타데이터 + 스토리지 구성 요소입니다</block>
  <block id="94c5de0e8c5b79f8b061a00a2d638234" category="paragraph-title">BeeGFS 메타데이터 + 스토리지 구성 요소 2개</block>
  <block id="53c31a8ba69af9d096629948d271d34d" category="paragraph-title">대역폭을 활용하기 위한 케이블 연결</block>
  <block id="bbe48fb854ea022537208eeeff822f91" category="paragraph-title">이 작업에 대해</block>
  <block id="48c7c41b72e1d678923ce3571aa65b2d" category="paragraph-title">단계</block>
  <block id="02cf3373667b246c17c8d054c073a372" category="paragraph">배포 권장 사항의 차이가 있는 파생 아키텍처:</block>
  <block id="2e93d3c37349d17095fd0dca7d6fe097" category="inline-link-macro">고용량 빌딩 블록</block>
  <block id="8a43f7c3e77834cf43b5398c116033e3" category="list-text"><block ref="8a43f7c3e77834cf43b5398c116033e3" category="inline-link-macro-rx"></block></block>
  <block id="119c6b2e3908d75335ad13f9fead045a" category="cell">1,938,577,200</block>
  <block id="753b107ce954fb125f0557af947a86c5" category="cell">51.77TB</block>
  <block id="bb586a502f621b433b3966d68c887364" category="cell">3,880,388,400</block>
  <block id="8b2e1597e74fb68a87ef415a1ce004fc" category="cell">103.55TB</block>
  <block id="9c0aa8a6ddcfe00cef8951f0edd99c58" category="cell">8,125,278,000입니다</block>
  <block id="b0baa6e5c027744d7e7f2a93d8686bf5" category="cell">216.74TB</block>
  <block id="edd8590257b34c7c6f57e06f28bb9460" category="cell">17,269,854,000</block>
  <block id="0d9c02ec5b1f4c4a835073aa142d0b7f" category="cell">460.60TB</block>
  <block id="f8ed0cba5469cc89e05fa4d3025eca1b" category="summary">고용량 빌딩 블록을 위한 설계 변형.</block>
  <block id="8b074fc693c7d8fd35c61de8fe2dee9a" category="doc">고용량 구성 요소입니다</block>
  <block id="fb5708557d5e7c6d44ac55ef4c09a054" category="paragraph">표준 BeeGFS 솔루션 설계는 고성능 워크로드를 염두에 두고 설계되었습니다. 고용량 사용 사례를 찾는 고객은 여기에 설명된 설계 및 성능 특성의 변화를 준수해야 합니다.</block>
  <block id="800f7da804cf784ad962d085fbc70486" category="section-title">하드웨어 및 소프트웨어 구성</block>
  <block id="90f177623f1131fc7f45e82db6189a1b" category="paragraph">고용량 구성 요소에 대한 하드웨어 및 소프트웨어 구성은 EF300 컨트롤러를 각 스토리지 어레이당 60개의 드라이브로 1~7개의 IOM 확장 트레이를 연결하는 옵션과 함께 EF300 컨트롤러로 교체해야 한다는 점을 제외하고 표준입니다. 빌딩 블록당 총 2-14개의 확장 트레이.</block>
  <block id="467fccc62f2ea7630303f15d47a54aa7" category="paragraph">대용량 구성 요소 설계를 구축하는 고객은 각 노드에 대해 BeeGFS 관리, 메타데이터 및 스토리지 서비스로 구성된 기본 구성 요소 스타일 구성만 사용할 수 있습니다. 비용 효율성을 위해 대용량 스토리지 노드는 EF300 컨트롤러 엔클로저의 NVMe 드라이브에 메타데이터 볼륨을 프로비저닝하고 확장 트레이의 NL-SAS 드라이브에 스토리지 볼륨을 프로비저닝해야 합니다.</block>
  <block id="774f4231e5651061791e65cf90314897" category="paragraph"><block ref="774f4231e5651061791e65cf90314897" category="inline-image-macro-rx" type="image"></block></block>
  <block id="267aa4fef181a2097a06345c854cc106" category="paragraph">이 사이징 지침은 대용량 구성 요소가 기본 EF300 엔클로저의 메타데이터용 2+2 NVMe SSD 볼륨 그룹 1개와 스토리지용 IOM 확장 트레이당 8개+2 NL-SAS 볼륨 그룹 6개로 구성되어 있다고 가정합니다.</block>
  <block id="963320465e8fcfa25188a669a43858c4" category="cell">드라이브 크기(용량 HDD)</block>
  <block id="55fd8e839de07671a6869fad80279ab9" category="cell">BB당 용량(1트레이)</block>
  <block id="001115a96afe0add22e654316239365a" category="cell">BB당 용량(2개의 트레이)</block>
  <block id="b9781606af717d9b153714ca7a3a2d33" category="cell">BB당 용량(3개의 트레이)</block>
  <block id="345ffe7c9ac213823037fbcdca8f4ef2" category="cell">BB당 용량(4개의 트레이)</block>
  <block id="6b7e0bcfc566b639bc0d10bad9f871dd" category="cell">4TB</block>
  <block id="676efbc64df1b4909842616f91027d96" category="cell">439TB</block>
  <block id="25c359cf674976f1bd282922ff6ed0e3" category="cell">878TB</block>
  <block id="1416acbb13ce37c62934fde6e37b3c6b" category="cell">1,317TB</block>
  <block id="3aa071e61efaac2113f5fc251c03b688" category="cell">1756TB</block>
  <block id="0706c165b0123479cffaac9b374484f0" category="cell">8TB</block>
  <block id="76a91245e71b558dbe0040ea8b7b3c21" category="cell">2,634TB</block>
  <block id="dd9fa1084ca34ce21c6b127bd37446b9" category="cell">3512TB</block>
  <block id="1191f788083da9194f8eef9400d10898" category="cell">10TB</block>
  <block id="6587b6d3747beeadda1eccb500e9771b" category="cell">1097TB</block>
  <block id="3a89d830e84dc7715fe902bb9adac448" category="cell">2195TB</block>
  <block id="1024776bf84a4c2469e49539ac248790" category="cell">3292TB</block>
  <block id="0af601e969fa263e021792cfd1dfd4af" category="cell">4390TB</block>
  <block id="aad11c7dd0feb18c08cb728eea0a8c46" category="cell">12TB</block>
  <block id="0fc4914bd341e29e4eef438ff8c44bdb" category="cell">3,951TB</block>
  <block id="4d63a00ef9361479d55d2914d7f75e28" category="cell">5268TB</block>
  <block id="324f218b8144e744b54eb58e0bf14eea" category="cell">16TB</block>
  <block id="af4d6969d11876b269a31ebb39d7c34e" category="cell">7024TB</block>
  <block id="7ba1b40b5eed0a67df50aa00c907f9ac" category="cell">18TB</block>
  <block id="23f86ea0b6ba63be94542d36e1d0ac20" category="cell">1975TB</block>
  <block id="01dbb09e4b3f7243c1cae305daf2972a" category="cell">5,927TB</block>
  <block id="547259566f92db3383cbd2575b9d68c1" category="cell">7902TB</block>
  <block id="585389cefc924819e7ab6d5b7eba5f03" category="paragraph">설계 및 성능 면에서 다양한 파생 아키텍처:</block>
  <block id="f45c646cffcf39011c125e7523fa9149" category="summary">대용량 구성 요소를 위한 구축 변형</block>
  <block id="fc6e06f3e4cfc328095f04c8f44c28f1" category="paragraph">표준 BeeGFS 솔루션 구축 가이드에서는 고성능 워크로드 요구 사항에 대한 절차 및 권장 사항을 간략하게 설명합니다. 고용량 요구 사항을 충족하려는 고객은 여기에 설명된 구축 및 권장 사항의 변화를 관찰해야 합니다.</block>
  <block id="cbfb14f470701bf93424d757c624369a" category="section-title">컨트롤러</block>
  <block id="174e6193fff9ed7c9b1839367e007f13" category="paragraph">고용량 구성 요소의 경우 EF600 컨트롤러를 EF300 컨트롤러로 교체해야 하며, 각 컨트롤러는 SAS 확장을 위해 Cascade HIC를 설치합니다. 각 블록 노드는 스토리지 엔클로저에 BeeGFS 메타데이터 스토리지를 위한 최소한의 NVMe SSD를 포함하고 BeeGFS 스토리지 볼륨용 NL-SAS HDD로 채워진 확장 셸프에 연결됩니다.</block>
  <block id="1ec9226d3745f2995d2686d2450831c7" category="paragraph">File Node to Block 노드 구성은 동일하게 유지됩니다.</block>
  <block id="af932b84cc0c8562c0e572647564048f" category="section-title">드라이브 배치</block>
  <block id="f96a95c482225ca6a9b4c17bfa47d918" category="paragraph">BeeGFS 메타데이터 스토리지를 위해 각 블록 노드에 최소 4개의 NVMe SSD가 필요합니다. 이러한 드라이브는 인클로저의 가장 바깥쪽 슬롯에 위치해야 합니다.</block>
  <block id="778e10a0753cc201500f1209098b9b5f" category="paragraph"><block ref="778e10a0753cc201500f1209098b9b5f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fdd528ca6f274d102819b008b189961c" category="section-title">확장 트레이</block>
  <block id="6627fde89324d2cbb6afd245e3d32d35" category="paragraph">스토리지 어레이당 1-7, 60 드라이브 확장 트레이를 사용하여 대용량 구성 요소를 사이징할 수 있습니다.</block>
  <block id="80b4ce0c4b11e4d8c7c4a14614b871f7" category="inline-link-macro">드라이브 쉘프의 EF300 케이블 연결을 참조하십시오</block>
  <block id="25ada85328148d5356ce4edd989b1f40" category="paragraph">각 확장 트레이 케이블 연결 지침은 <block ref="8c170f7da852d665db7cd9113b2ed6bb" category="inline-link-macro-rx"></block>.</block>
  <block id="0607ff4a53c90b270dd9fd9fce5c3d92" category="sidebar">고용량 옵션</block>
  <block id="23bc11ca7e09a55b459ef424efb98c36" category="summary">PC를 사용하여 클러스터의 상태를 봅니다.</block>
  <block id="d4c39d91a1df6c7a7094c35722ec3ed5" category="doc">클러스터의 상태를 검사합니다</block>
  <block id="3b878279a04dc47d60932cb294d96259" category="section-title">개요</block>
  <block id="b6330a3d35150021353dc39d5bf1899a" category="paragraph">실행 중입니다<block ref="fcad1c87c23363c990849a7aaf9d6cd9" prefix=" " category="inline-code"></block> 모든 클러스터 노드에서 클러스터의 전체 상태와 각 리소스의 상태(예: BeeGFS 서비스 및 해당 종속성)를 확인하는 가장 쉬운 방법입니다. 이 섹션에서는 의 출력에서 확인할 수 있는 내용을 설명합니다<block ref="fcad1c87c23363c990849a7aaf9d6cd9" prefix=" " category="inline-code"></block> 명령.</block>
  <block id="a58022af0d3ce83b3b4031643fcdb7be" category="section-title">의 출력 이해<block ref="fcad1c87c23363c990849a7aaf9d6cd9" prefix=" " category="inline-code"></block></block>
  <block id="24b70b7dc179eb742a98eca1b4c954b3" category="paragraph">실행<block ref="fcad1c87c23363c990849a7aaf9d6cd9" prefix=" " category="inline-code"></block> 클러스터 서비스(박동조율기 및 Corosync)가 시작되는 모든 클러스터 노드에서. 출력 맨 위에는 클러스터의 요약이 표시됩니다.</block>
  <block id="9e1d70fa0d8e4964c3bd135b73fa8375" category="paragraph">아래 섹션에는 클러스터의 노드가 나열됩니다.</block>
  <block id="ce0c86ab66a5ecdcc820da60194c7abc" category="paragraph">이는 대기 또는 오프라인 상태인 노드를 나타냅니다. 대기 상태의 노드는 여전히 클러스터에 참여하고 있지만 리소스 실행 부적격으로 표시되어 있습니다. 오프라인 상태인 노드는 노드가 수동으로 중지되었거나 노드가 재부팅/종료되었기 때문에 해당 노드에서 클러스터 서비스가 실행되고 있지 않음을 나타냅니다.</block>
  <block id="39dd7b2f17eda84e2e8059bb568493c9" category="admonition">노드가 처음 시작될 때 클러스터 서비스가 중지되며, 비정상적인 노드로 리소스가 실수로 페일백되지 않도록 수동으로 시작해야 합니다.</block>
  <block id="cbc566d6b815d43dd99c76ca8f2fd4f8" category="paragraph">노드가 비관리적 이유(예: 실패)로 인해 대기 또는 오프라인 상태인 경우 노드의 상태 옆에 괄호 안에 추가 텍스트가 표시됩니다. 예를 들어 펜싱을 사용하지 않도록 설정하고 리소스에 장애가 발생하면 표시됩니다<block ref="1db3c4bcbb494ae3b1b2e86c57842a69" prefix=" " category="inline-code"></block>. 다른 가능한 상태는 입니다<block ref="3fd6d1573d7af30709095c1a01f1fdd9" prefix=" " category="inline-code"></block>펜싱이 실패하여 클러스터가 노드 상태를 확인할 수 없음을 나타내는 경우(다른 노드에서 리소스가 시작되는 것을 차단할 수 있음) 잠시 노드가 펜싱되는 것으로 나타나지만 지속합니다.</block>
  <block id="56cfcb8bfa2e43de0547ffbf4a2edd0e" category="paragraph">다음 섹션에는 클러스터의 모든 리소스 목록과 해당 상태가 표시됩니다.</block>
  <block id="45caf63eb71a242bf4ef160a8aeeb2a4" category="paragraph">노드와 마찬가지로 리소스에 문제가 있는 경우 괄호 안의 리소스 상태 옆에 추가 텍스트가 표시됩니다. 예를 들어 페이스 메이커의 리소스 중지를 요청했으나 할당된 시간 내에 완료되지 못한 경우 심장박동기는 노드를 울타리로 만들려고 시도합니다. 펜싱이 비활성화되거나 펜싱 작업이 실패하는 경우 리소스 상태는 입니다<block ref="bb38152bf8b813a142650a06ad87363e" prefix=" " category="inline-code"></block> 다른 노드에서 심장박동조율기를 시작할 수 없습니다.</block>
  <block id="028c86c0d3bdc4a78f8123e9fad41847" category="paragraph">BeeGFS HA 클러스터가 여러 BeeGFS에 최적화된 맞춤형 OCF 리소스 에이전트를 사용하는 것을 주목할 필요가 있습니다. 특히 BeeGFS 모니터는 특정 노드의 BeeGFS 리소스를 사용할 수 없을 때 페일오버를 트리거합니다.</block>
  <block id="0532f63b7151a82cb4b5e3351e2371d0" category="summary">정상적으로 HA 클러스터를 중지 및 시작합니다.</block>
  <block id="7479b021f04933331bfad4de007ca0c2" category="doc">클러스터를 중지하고 시작합니다</block>
  <block id="2b884da4a956e42f63bc07b5d20c50b1" category="paragraph">이 섹션에서는 BeeGFS 클러스터를 정상적으로 종료하고 다시 시작하는 방법에 대해 설명합니다. 이러한 작업이 필요할 수 있는 시나리오에는 전기 유지보수 또는 데이터 센터 또는 랙 간 마이그레이션이 포함됩니다.</block>
  <block id="c61d5048d10a534a03e7687782b475e2" category="paragraph">어떤 이유로든 전체 BeeGFS 클러스터를 중지하고 모든 서비스를 종료해야 하는 경우 다음을 실행합니다.</block>
  <block id="3ad6e9988864aeae2ef386345946dc6d" category="inline-link-macro">페일오버</block>
  <block id="d449e36705eea41c6a590f7b2c80954c" category="paragraph">또한 노드를 먼저 대기 상태로 전환하는 것이 좋지만 개별 노드에서 클러스터를 중지하고(다른 노드로 자동으로 서비스 페일오버) 다른 노드를 추가하는 것이 좋습니다(참조) <block ref="4843c7d7cb9083e16e9eaa5961895258" category="inline-link-macro-rx"></block> 섹션):</block>
  <block id="9e94ba8f70ed52b0ae6c2a8725f97a9f" category="paragraph">모든 노드에서 클러스터 서비스 및 리소스를 시작하려면 다음을 실행합니다.</block>
  <block id="80bd5673b361d19dc46e6b882f98b061" category="paragraph">또는 다음 특정 노드에서 서비스를 시작합니다.</block>
  <block id="56ad9ec5396c5f035697d1e62c4b0926" category="paragraph">이 시점에서 를 실행합니다<block ref="fcad1c87c23363c990849a7aaf9d6cd9" prefix=" " category="inline-code"></block> 모든 노드에서 클러스터와 BeeGFS 서비스가 시작되는지, 그리고 원하는 노드에서 서비스가 실행되고 있는지 확인합니다.</block>
  <block id="f2cc0b0e79d5eccda5009e593729ce23" category="admonition">클러스터의 크기에 따라 전체 클러스터가 중지되거나 에서 시작될 때까지 몇 초~몇 분 정도 걸릴 수 있습니다<block ref="fcad1c87c23363c990849a7aaf9d6cd9" prefix=" " category="inline-code"></block>. If(경우<block ref="88f9ea6da6d01a3e529f8aa41e0e4643" prefix=" " category="inline-code"></block> "Ctrl+C"를 실행하여 명령을 취소하기 전에 5분 이상 작동이 멈추고 클러스터의 각 노드에 로그인하여 를 사용합니다<block ref="fcad1c87c23363c990849a7aaf9d6cd9" prefix=" " category="inline-code"></block> 해당 노드에서 클러스터 서비스(Corosync/Pacemaker)가 여전히 실행되고 있는지 확인합니다. 클러스터가 여전히 활성 상태인 모든 노드에서 클러스터를 차단하는 리소스를 확인할 수 있습니다. 문제를 수동으로 해결하고 명령을 완료하거나 다시 실행하여 나머지 서비스를 중지할 수 있습니다.</block>
  <block id="9cdd9805effd30bec624c806fd980309" category="summary">클러스터 노드 간에 BeeGFS 서비스 이동</block>
  <block id="f6054493b235622c6d85c56597db1eb1" category="doc">장애 조치 및 장애 복구 서비스</block>
  <block id="2c053c4f4aa73d509803b712a335712b" category="paragraph">BeeGFS 서비스는 클러스터에서 노드 간에 페일오버를 수행하여 노드에 장애가 발생하거나 계획된 유지 관리를 수행해야 하는 경우 클라이언트가 파일 시스템에 계속 액세스할 수 있도록 합니다. 이 섹션에서는 장애를 복구한 후 관리자가 클러스터를 복구하거나 노드 간에 서비스를 수동으로 이동할 수 있는 다양한 방법에 대해 설명합니다.</block>
  <block id="07216bb55061288a2fa29cda954742e3" category="section-title">페일오버 및 페일백</block>
  <block id="23709dbf750335ca35bb098cb16932f2" category="section-title">페일오버(계획됨)</block>
  <block id="805e61a2ff2aebdab58587660993241c" category="paragraph">일반적으로 유지 관리를 위해 단일 파일 노드를 오프라인으로 전환해야 하는 경우 해당 노드에서 모든 BeeGFS 서비스를 이동(또는 드레이닝)해야 합니다. 먼저 노드를 대기 상태로 전환하여 이 작업을 수행할 수 있습니다.</block>
  <block id="ecbf8d7e7d9f1eb0a529231cebd2199c" category="paragraph"><block ref="45235c2d84b11e465f5ed5176cc9fc73" prefix="" category="inline-code"></block></block>
  <block id="badd2ea7f58914039bb51471883e3461" category="paragraph">를 사용하여 확인한 후<block ref="fcad1c87c23363c990849a7aaf9d6cd9" prefix=" " category="inline-code"></block> 모든 리소스가 대체 파일 노드에서 다시 시작되었습니다. 노드를 종료하거나 필요에 따라 변경할 수 있습니다.</block>
  <block id="1343bdd328b646934d900b04ee8ba9bd" category="section-title">페일백(계획된 페일오버 후)</block>
  <block id="746bffd8542d5a995ff4e29343881c45" category="paragraph">BeeGFS 서비스를 기본 노드 첫 번째 실행으로 복구할 준비가 되면<block ref="fcad1c87c23363c990849a7aaf9d6cd9" prefix=" " category="inline-code"></block> "노드 목록"에서 상태가 대기 상태인지 확인합니다. 노드가 재부팅된 경우 클러스터 서비스를 온라인 상태로 전환할 때까지 오프라인 상태로 표시됩니다.</block>
  <block id="91e6580245db1e731f9ba78076973736" category="paragraph">노드가 온라인 상태가 되면 다음을 사용하여 대기 모드에서 나오게 합니다.</block>
  <block id="040901cb649ee5383b238c42c7746fca" category="paragraph">마지막으로 다음을 통해 모든 BeeGFS 서비스를 기본 노드에 다시 재배치하십시오.</block>
  <block id="6ebfd7088ae3d5d766caee83ef99e7bc" category="section-title">페일백(계획되지 않은 페일오버 후)</block>
  <block id="e09245effc62059e51f926fad603e413" category="inline-link-macro">문제 해결</block>
  <block id="0dd80abc12adacf83c3c27a835b9c7a3" category="paragraph">노드에 하드웨어 또는 기타 장애가 발생할 경우 HA 클러스터가 자동으로 대응하고 서비스를 정상 노드로 이동하여 관리자에게 수정 조치를 취할 수 있는 시간을 제공해야 합니다. 계속하기 전에 을 참조하십시오 <block ref="5e4db6f9f5ecbaadfbb532aac5ccee6e" category="inline-link-macro-rx"></block> 섹션을 참조하여 페일오버 원인을 확인하고 해결되지 않은 문제를 해결합니다. 노드 전원이 다시 켜지고 정상 상태가 되면 페일백을 진행할 수 있습니다.</block>
  <block id="364ed45bbda2e3fd57309efe24fc0d55" category="paragraph">예정되지 않은(또는 계획된) 재부팅 후 노드가 부팅될 때 클러스터 서비스가 자동으로 시작되도록 설정되지 않으므로 먼저 를 사용하여 노드를 온라인 상태로 가져와야 합니다.</block>
  <block id="f00b2994ca5cfc6ab0328a63736caa02" category="paragraph">그런 다음 리소스 장애를 정리하고 노드의 펜싱 기록을 재설정합니다.</block>
  <block id="ac161f403f36186463574a43968aa121" category="paragraph">에서 확인하십시오<block ref="fcad1c87c23363c990849a7aaf9d6cd9" prefix=" " category="inline-code"></block> 노드가 온라인 상태이고 정상 상태입니다. 기본적으로 BeeGFS 서비스는 실수로 리소스가 정상 상태가 아닌 노드로 다시 이동하는 것을 방지하기 위해 자동으로 페일백하지 않습니다. 준비되면 클러스터의 모든 리소스를 원하는 노드로 다시 돌려볼 수 있는 방법은 다음과 같습니다.</block>
  <block id="a65e0cef92147365de773d870438a30d" category="section-title">개별 BeeGFS 서비스를 대체 파일 노드로 이동</block>
  <block id="606a28acf3a90904d7e27f3497573da7" category="section-title">BeeGFS 서비스를 새 파일 노드로 영구적으로 이동합니다</block>
  <block id="8f56c19ef179745c1437a4f477337649" category="paragraph">개별 BeeGFS 서비스에 대해 선호하는 파일 노드를 영구적으로 변경하려면 선호하는 노드가 먼저 나열되도록 Ansible 인벤토리를 조정하고 Ansible 플레이북을 다시 실행하십시오.</block>
  <block id="7f86f0b1f1f7dc413a7da5a9a5acb79a" category="paragraph">예를 들어, 이 샘플에서 사용할 수 있습니다<block ref="d28e452e49fc926f32af1d87afcff3ce" prefix=" " category="inline-code"></block> 파일, ictad22h01은 BeeGFS 관리 서비스를 실행하는 기본 파일 노드입니다.</block>
  <block id="b2d792db6eba9ea2a4bd7ebaf525e9a4" category="paragraph">순서를 반대로 하면 ictad22h02에서 관리 서비스가 선호됩니다.</block>
  <block id="346788f496d57b1e768d1dfaccdb3660" category="section-title">BeeGFS 서비스를 대체 파일 노드로 임시 이동합니다</block>
  <block id="bad9cbcf702b276e1564c24e67ad301c" category="paragraph">일반적으로 노드가 유지 관리 중인 경우 [failover and failback steps](#failover-and-failback)를 사용하여 해당 노드에서 모든 서비스를 이동하려고 합니다.</block>
  <block id="0a51cf78eac085426260a02c70378519" category="paragraph">어떤 이유로 개별 서비스를 다른 파일 노드로 이동해야 하는 경우 다음을 실행합니다.</block>
  <block id="9adf512d668d8b56c695d172f4de3f90" category="admonition">개별 리소스 또는 리소스 그룹을 지정하지 마십시오. 재배치할 BeeGFS 서비스에 대한 모니터 이름을 항상 지정합니다. 예를 들어 BeeGFS 관리 서비스를 ictad22h02로 이동하려면 다음을 실행합니다.<block ref="2349d8eb257904ae75bc6d292598087c" prefix=" " category="inline-code"></block>. 이 프로세스를 반복하여 하나 이상의 서비스를 원하는 노드에서 이동할 수 있습니다. 를 사용하여 확인합니다<block ref="fcad1c87c23363c990849a7aaf9d6cd9" prefix=" " category="inline-code"></block> 서비스가 새 노드에서 재배치/시작되었습니다.</block>
  <block id="15bda9336e0e061125e3b40fe7bfbb0f" category="paragraph">BeeGFS 서비스를 기본 노드로 다시 이동하려면 먼저 임시 리소스 제약 조건을 해제합니다(여러 서비스에 필요한 경우 이 단계를 반복).</block>
  <block id="d5c46792adbb43a012cbc1e858dc8bf4" category="paragraph">그런 다음 실제로 서비스를 원하는 노드로 다시 이동할 준비가 되면 다음을 실행합니다.</block>
  <block id="05ccfd1bb05ec0cb0ad0dbc5cfa2b32d" category="paragraph">참고 이 명령은 더 이상 임시 리소스 제약 조건이 없는 서비스를 기본 노드에 배치하지 않습니다.</block>
  <block id="b64fbf2b70c0da78d7c165d234dbde59" category="summary">원래 서버에 오류가 있는 경우 파일 노드를 교체합니다.</block>
  <block id="813789e46622daf96cc8a246b7123900" category="doc">파일 노드를 바꿉니다</block>
  <block id="7d8e819a8720821d1bda4944e3b284f8" category="paragraph">다음은 클러스터의 파일 노드를 교체하는 데 필요한 단계에 대한 개요입니다. 다음 단계에서는 하드웨어 문제로 인해 파일 노드가 실패했으며 동일한 새 파일 노드로 교체된다고 가정합니다.</block>
  <block id="0ca6560aa88bd22fa1b3bb69d8594555" category="section-title">단계:</block>
  <block id="237c1293f678bb3fb45da7ff985bc6ff" category="list-text">파일 노드를 물리적으로 교체하고 블록 노드 및 스토리지 네트워크에 대한 모든 케이블 연결을 복원합니다.</block>
  <block id="2fcfb8cbd69fbc9fbfe292049243f520" category="list-text">Red Hat 서브스크립션 추가를 포함하여 파일 노드에 운영 체제를 다시 설치합니다.</block>
  <block id="54bf3b134460f90ada283da98dfe7f55" category="list-text">파일 노드에서 관리 및 BMC 네트워킹을 구성합니다.</block>
  <block id="e07337279837c08243349fd1812b45ad" category="list-text">호스트 이름, IP, PCIe-논리 인터페이스 매핑 또는 새 파일 노드에 대해 변경된 사항이 있는 경우 Ansible 인벤토리를 업데이트합니다. 일반적으로 노드가 동일한 서버 하드웨어로 교체되었고 원래 네트워크 구성을 사용하는 경우에는 필요하지 않습니다.</block>
  <block id="1092a09068da1d54ef98835a92b7ae93" category="list-text">예를 들어 호스트 이름이 변경된 경우 노드의 인벤토리 파일을 생성하거나 이름을 변경합니다 <block ref="68c99491876298ad1740f875d0009eb1" prefix="(" category="inline-code"></block>)를 선택한 다음 Ansible 인벤토리 파일에 저장합니다 <block ref="d28e452e49fc926f32af1d87afcff3ce" prefix="(" category="inline-code"></block>)에서 이전 노드의 이름을 새 노드 이름으로 바꿉니다.</block>
  <block id="4e77e3629d6cf2dd24d01cd0816444dc" category="list-text">클러스터의 다른 노드 중 하나에서 이전 노드를 제거합니다.<block ref="0b3c8b6f1b9e3417f6658a2d7bf57e50" prefix=" " category="inline-code"></block>.</block>
  <block id="80b3f35b9a09098f23ac89ae2b86b045" category="admonition">이 단계를 실행하기 전에 진행하지 마십시오.</block>
  <block id="b13bbcb9af62574d6f02dd11fb1e8467" category="list-text">Ansible 제어 노드에서:</block>
  <block id="bdd8d1913bd5c9a453285898025b96c3" category="list-text">다음을 사용하여 이전 SSH 키를 제거합니다.</block>
  <block id="357f3d871a04ba99dca4088160a070c7" category="list-text">바꾸기 노드에 대해 암호 없는 SSH를 다음으로 구성:</block>
  <block id="7142a43bd39c703832e1dedd5cc1781d" category="list-text">Ansible 플레이북을 다시 실행하여 노드를 구성하고 클러스터에 추가합니다.</block>
  <block id="cb6fdf37da197d680c43c0f6f18ad11d" category="list-text">이때 를 실행합니다<block ref="fcad1c87c23363c990849a7aaf9d6cd9" prefix=" " category="inline-code"></block> 교체된 노드가 나열되고 서비스가 실행 중인지 확인합니다.</block>
  <block id="7728706b8b42de0081920e7246a76547" category="summary">HA 클러스터가 운영 환경의 의도된 변경 사항에 실수로 반응하는 것을 방지합니다.</block>
  <block id="e1fee8e589d1f622a7c4194531dd6d51" category="doc">클러스터를 유지보수 모드로 전환합니다</block>
  <block id="de51662eceb9c88ae773c201eb0345d1" category="paragraph">클러스터를 유지보수 모드로 전환하면 모든 리소스 모니터링이 비활성화되고 박동기가 클러스터 리소스를 이동하거나 관리하는 것을 방지할 수 있습니다. 액세스를 방해하는 일시적인 장애 조건이 있더라도 모든 리소스는 원래 노드에서 계속 실행됩니다. 권장/유용한 시나리오는 다음과 같습니다.</block>
  <block id="ea4d028cbc39da373f2405d19e55ab0f" category="list-text">파일 노드와 BeeGFS 서비스 간의 연결이 일시적으로 중단될 수 있는 네트워크 유지 보수</block>
  <block id="fb9f2ee248fa11ccfb854f09fcda2a80" category="list-text">블록 노드 업그레이드</block>
  <block id="92a6e3227dfe7be15777e64043fb613f" category="list-text">파일 노드 운영 체제, 커널 또는 기타 패키지 업데이트.</block>
  <block id="6c1cf36b91fdf2375e857652291bab2e" category="paragraph">일반적으로 클러스터를 유지 관리 모드로 수동으로 설정하는 유일한 이유는 해당 클러스터가 환경의 외부 변경에 반응하지 않도록 하기 위해서입니다. 클러스터의 개별 노드에 물리적 복구가 필요한 경우 유지보수 모드를 사용하지 말고 위의 절차에 따라 해당 노드를 대기 모드에 두십시오. Ansible을 다시 실행하면 업그레이드 및 구성 변경을 포함하여 대부분의 소프트웨어 유지보수를 수행할 수 있도록 클러스터가 유지보수 모드로 자동으로 전환됩니다.</block>
  <block id="bbf6745fae83e12806200feeb795f0ef" category="paragraph">클러스터가 유지보수 모드인지 확인하려면 다음을 실행합니다.</block>
  <block id="4a6b1ae7d59c5bf02b1b5759e9f9b8e7" category="paragraph">클러스터가 정상적으로 작동 중일 경우 이 오류가 false로 반환됩니다. 유지보수 모드를 활성화하려면 다음을 실행하십시오.</block>
  <block id="4ecbc8384cde54344112e6ab08db42be" category="paragraph">PC 상태를 실행하고 모든 리소스에 "(관리되지 않음)"이 표시되는지 확인하여 확인할 수 있습니다. 클러스터를 유지보수 모드에서 제외하려면 다음을 실행하십시오.</block>
  <block id="9afe1c93907babebeb4d7a466e216a3e" category="summary">클러스터에서 구성 요소를 추가하거나 제거합니다.</block>
  <block id="da82c1c93eafcb34930ae3da89361e1e" category="doc">클러스터를 확장 또는 축소합니다</block>
  <block id="c8fb5d104008cab3ab8a229181f5dfac" category="paragraph">이 섹션에서는 BeeGFS HA 클러스터의 크기를 조정하는 다양한 고려 사항 및 옵션에 대해 설명합니다. 일반적으로 클러스터 크기는 구성 요소를 추가 또는 제거하여 조정합니다. 구성 요소는 일반적으로 2개의 파일 노드를 HA 쌍으로 설정합니다. 필요한 경우 개별 파일 노드(또는 다른 유형의 클러스터 노드)를 추가하거나 제거할 수도 있습니다.</block>
  <block id="711c6d6edaed786b4dc0203b75460778" category="section-title">클러스터에 빌딩 블록 추가</block>
  <block id="ea61e2c2ff507048203824add1eb7c21" category="section-title">고려 사항</block>
  <block id="f29b9abf87c880782cf8c378e24a1668" category="paragraph">추가 구성 요소를 추가하여 클러스터를 늘리는 것은 간단한 프로세스입니다. 시작하기 전에 각 개별 HA 클러스터의 최소 및 최대 클러스터 노드 수에 대한 제한을 염두에 두고, 기존 HA 클러스터에 노드를 추가하거나 새로운 HA 클러스터를 생성해야 하는지 확인합니다. 일반적으로 각 구성 요소는 2개의 파일 노드로 구성되지만, 3개의 노드는 쿼럼(quorum)을 설정하기 위해 클러스터당 최소 노드 수이고 10개는 권장(테스트)입니다. 고급 시나리오의 경우 2노드 클러스터를 구축할 때 BeeGFS 서비스를 실행하지 않는 단일 "Tiebreaker" 노드를 추가할 수 있습니다. 이러한 배포를 고려 중인 경우 NetApp 지원에 문의하십시오.</block>
  <block id="662a466b951b1af4fe3b4c3fd2e0370c" category="paragraph">클러스터를 확장하는 방법을 결정할 때는 이러한 제한 사항과 향후 클러스터 확장에 대한 예상에 유의하십시오. 예를 들어, 6노드 클러스터가 있고 4노드를 더 추가해야 하는 경우 새 HA 클러스터를 시작하는 것이 좋습니다.</block>
  <block id="2b988a3f29ebee8dccd80147a22c1bc6" category="admonition">단일 BeeGFS 파일 시스템은 여러 독립 HA 클러스터로 구성될 수 있습니다. 따라서 파일 시스템은 기본 HA 클러스터 구성 요소의 권장/하드 제한보다 훨씬 높은 확장성을 유지할 수 있습니다.</block>
  <block id="c9e209235fa71f94c6ca46692bb327a3" category="inline-link-macro">맞춤형 아키텍처를 사용합니다</block>
  <block id="2b8a37e03c93039e78a6e190ca3eab78" category="paragraph">클러스터에 구성 요소를 추가할 때 를 생성해야 합니다<block ref="3342582e194d63e4c91b56623752c9c6" prefix=" " category="inline-code"></block> 각 새 파일 노드 및 블록 노드(E-Series 어레이)에 대한 파일 이러한 호스트의 이름은 생성할 새 리소스와 함께 인벤토리에 추가해야 합니다. 해당<block ref="96fa973cda8809ad84f646e3d8fbbc1c" prefix=" " category="inline-code"></block> 각 새 리소스에 대해 파일을 만들어야 합니다. 를 참조하십시오 <block ref="6a2ae3835c9e26f17fff6aca74581491" category="inline-link-macro-rx"></block> 섹션을 참조하십시오.</block>
  <block id="0a9e15a6a510b24d4e6ac91c02152457" category="paragraph">올바른 파일을 생성한 후 다음 명령을 사용하여 자동화를 다시 실행해야 합니다.</block>
  <block id="8d695d37ced4690199d537aed9d4bd55" category="section-title">클러스터에서 빌딩 블록 제거</block>
  <block id="b68ea55d7263db6f96db88774fb7b864" category="paragraph">구성 요소를 폐기해야 할 경우에는 다음과 같은 여러 가지 사항을 고려해야 합니다.</block>
  <block id="c26cc9593863fbf09a98a7c1809d4501" category="list-text">이 빌딩 블록에서 실행 중인 BeeGFS 서비스는 무엇입니까?</block>
  <block id="64e344a53d6a50c0b641de71dcc0d0e6" category="list-text">파일 노드만 사용 중지되며 블록 노드를 새 파일 노드에 연결해야 합니까?</block>
  <block id="de3bc01ba61503e7b8699b9318d0fd0b" category="list-text">전체 빌딩 블록이 사용 중단된 경우 데이터를 새 빌딩 블록으로 이동하거나, 클러스터의 기존 노드로 분산하거나, 새로운 BeeGFS 파일 시스템 또는 다른 스토리지 시스템으로 이동해야 합니까?</block>
  <block id="b6bb45be6629ebff573a5364d6abba3e" category="list-text">이 문제는 중단 중에 발생할 수 있습니까? 아니면 중단 없이 수행해야 합니까?</block>
  <block id="9b0ed7965704c34f1d45d89e7afe7bfc" category="list-text">구성 요소를 적극적으로 사용하고 있습니까, 아니면 주로 더 이상 활성 상태가 아니지 않은 데이터가 포함되어 있습니까?</block>
  <block id="2f1f874ab85cc95aedb0e31639ddd1be" category="paragraph">가능한 다양한 시작 지점과 원하는 종료 상태 때문에 NetApp 지원에 문의하여 고객 환경과 요구 사항에 따라 최상의 전략을 파악하고 구현할 수 있습니다.</block>
  <block id="1819205ce38618cd2752bb84e2b73e58" category="summary">BeeGFS HA 클러스터 문제 해결</block>
  <block id="d60c463bb4096f3ed4bd1618626dfe10" category="doc">문제 해결</block>
  <block id="b162a91192a0936d7593cb252c65dfd8" category="paragraph">이 섹션에서는 BeeGFS HA 클러스터를 운영할 때 발생할 수 있는 다양한 장애 및 기타 시나리오를 조사하고 해결하는 방법을 설명합니다.</block>
  <block id="40327cd11d60bd1f114b3e4566f94e50" category="section-title">문제 해결 설명서</block>
  <block id="e1c58302972da23d09a5ab5fe221a170" category="section-title">예상치 못한 장애 조치 조사</block>
  <block id="4fbaa99fc13cc42ed40e8b05969de8fb" category="paragraph">노드가 예기치 않게 펜싱되고 해당 서비스가 다른 노드로 이동된 경우 첫 번째 단계는 클러스터가 하단에 리소스 장애를 나타내는지 확인하는 것입니다<block ref="fcad1c87c23363c990849a7aaf9d6cd9" prefix=" " category="inline-code"></block>. 펜싱이 성공적으로 완료되고 리소스가 다른 노드에서 다시 시작된 경우에는 일반적으로 아무 것도 표시되지 않습니다.</block>
  <block id="31288ba37f67baa9a96377c197fd16b4" category="paragraph">일반적으로 다음 단계는 를 사용하여 시스템 로그를 검색하는 것입니다<block ref="eed23a3d2310f43954a09887cb36b398" prefix=" " category="inline-code"></block> 나머지 파일 노드 중 하나에서(심장박동기 로그는 모든 노드에서 동기화됨) 오류가 발생한 시간을 알고 있는 경우 장애가 발생하기 바로 직전에 검색을 시작할 수 있습니다(일반적으로 10분 이상 전에 검색을 시작하는 것이 좋습니다).</block>
  <block id="adc8528fced336e7a819071c746b5738" category="paragraph">다음 섹션에서는 조사 범위를 더욱 좁히기 위해 로그에 표시할 수 있는 일반적인 텍스트를 보여 줍니다.</block>
  <block id="a6dea15cd908ef20a94b7b92df902f0b" category="section-title">조사/해결 단계</block>
  <block id="d418f50c5ddea28b4ca856017b36cb20" category="section-title">1단계: BeeGFS 모니터에서 장애를 감지했는지 확인합니다.</block>
  <block id="a0d295ceecafcdade2e77c52fee836e0" category="paragraph">BeeGFS 모니터에 의해 페일오버가 트리거된 경우 오류가 표시됩니다(다음 단계로 진행되지 않는 경우).</block>
  <block id="1792a4cca8d37bb062059acbb40ebf88" category="paragraph">이 경우 BeeGFS 서비스 META_08이 어떤 이유로 중지되었습니다. 문제 해결을 계속하려면 ictad22h02를 부팅하고 의 서비스 로그를 검토해야 합니다<block ref="45434eee994714888e9eafad4993b0d3" prefix=" " category="inline-code"></block>. 예를 들어, BeeGFS 서비스에서 노드의 내부 문제 또는 문제로 인해 애플리케이션 오류가 발생했을 수 있습니다.</block>
  <block id="ba35f78b5ee9757310a818131880e7ba" category="admonition">페이스 메이커의 로그와 달리 BeeGFS 서비스의 로그는 클러스터의 모든 노드에 배포되지 않습니다. 이러한 유형의 장애를 조사하려면 장애가 발생한 원래 노드의 로그가 필요합니다.</block>
  <block id="e7ed0a662a65a2b9a77688262294bdeb" category="paragraph">모니터에서 보고할 수 있는 문제는 다음과 같습니다.</block>
  <block id="7cdeb72a25ab193e904385b516b1b346" category="list-text">대상에 액세스할 수 없습니다!</block>
  <block id="b5937b98653f70b6902650183cf4ec74" category="list-text">설명: 블록 볼륨을 액세스할 수 없음을 나타냅니다.</block>
  <block id="2fe85519f178203eb9e17cd7d958eff5" category="list-text">문제 해결:</block>
  <block id="a337b1ea21fcd18ca666a6d53d5d43cd" category="list-text">대체 파일 노드에서 서비스도 시작하지 못한 경우 블록 노드가 정상 상태인지 확인합니다.</block>
  <block id="1a92a4c3328c821522ae4b4f7b7939f4" category="list-text">이 파일 노드에서 블록 노드에 액세스하지 못하게 하는 물리적 문제(예: InfiniBand 어댑터 또는 케이블 장애)가 있는지 확인합니다.</block>
  <block id="07d73b1c441d1587365e83eab249cc0e" category="list-text">네트워크에 연결할 수 없습니다!</block>
  <block id="640de5e4317b2b6b4cdfc75056c11dc1" category="list-text">설명: 클라이언트가 이 BeeGFS 서비스에 연결하는 데 사용하는 어댑터 중 온라인 어댑터가 없습니다.</block>
  <block id="a6fe0c48e93a5942e6a707553dc58b72" category="list-text">여러 파일 노드/모든 파일 노드에 영향을 받은 경우 BeeGFS 클라이언트 및 파일 시스템을 연결하는 데 사용된 네트워크에 장애가 있는지 확인합니다.</block>
  <block id="89af81e10eaa132cd26657feb6c0255d" category="list-text">이 파일 노드에서 클라이언트에 액세스하지 못하게 하는 물리적 문제(예: InfiniBand 어댑터 또는 케이블 장애)가 있는지 확인합니다.</block>
  <block id="74a668540699bf39afc1015b6ce839e7" category="list-text">BeeGFS 서비스가 활성 상태가 아닙니다.</block>
  <block id="d297ccf512793d172de0cfd4051e2e96" category="list-text">설명: BeeGFS 서비스가 예기치 않게 중지되었습니다.</block>
  <block id="4937184e80e5bebefae7244965d351b9" category="list-text">오류를 보고한 파일 노드에서 영향을 받는 BeeGFS 서비스의 로그를 확인하여 충돌이 보고되었는지 확인합니다. 이 경우 NetApp Support에서 케이스를 접수하여 충돌을 조사하십시오.</block>
  <block id="feec20659fe99c02d4979b8ad026cc97" category="list-text">BeeGFS 로그에 보고된 오류가 없는 경우 저널 로그를 확인하여 시스템이 서비스가 중지된 이유를 기록했는지 확인합니다. 일부 시나리오에서 BeeGFS 서비스는 프로세스가 종료되기 전에(예: 누군가 를 실행한 경우) 메시지를 기록할 수 있는 기회를 제공하지 않았을 수 있습니다<block ref="c287e2fa9b978b64df6b25bc14f4ebad" prefix=" " category="inline-code"></block>)를 클릭합니다.</block>
  <block id="6c187654c83a0705225e629e5ef0e690" category="section-title">2단계: 노드가 예기치 않게 클러스터를 종료했는지 확인합니다</block>
  <block id="48de5b8ba61031259301e7dcfed5f30f" category="paragraph">노드에 심각한 하드웨어 장애가 발생하거나(예: 시스템 보드가 작동하지 않음) 커널 패닉 또는 유사한 소프트웨어 문제가 발생한 경우 BeeGFS 모니터에서 오류를 보고하지 않습니다. 대신 호스트 이름을 찾으십시오. 심장박동기에서 노드가 예기치 않게 손실되었음을 나타내는 메시지가 표시됩니다.</block>
  <block id="e2c890774d7c7d0dbdd940e9e70a6e38" category="section-title">3단계: 심장박동기가 노드를 울타리로 만들 수 있는지 확인합니다</block>
  <block id="233ac49c948b907a2f3ece7ba249837e" category="paragraph">모든 시나리오에서 노드가 실제로 오프라인 상태인지 확인하기 위해 심장박동기 펜스(pencing)를 시도하는 것을 볼 수 있습니다(정확한 메시지는 펜싱 원인에 따라 다를 수 있음).</block>
  <block id="43878a52c3fd9ee95d536dd53db82be8" category="paragraph">펜싱 작업이 성공적으로 완료되면 다음과 같은 메시지가 표시됩니다.</block>
  <block id="c9fc2871ff88666659a1639b7bc7a907" category="paragraph">어떤 이유로 펜싱 작업이 실패한 경우 데이터 손상을 방지하기 위해 다른 노드에서 BeeGFS 서비스를 다시 시작할 수 없습니다. 예를 들어 펜싱 장치(PDU 또는 BMC)에 액세스할 수 없거나 잘못 구성된 경우 별도로 조사하는 것이 문제입니다.</block>
  <block id="824b5f569e1c282ba489e1d3fe24611f" category="section-title">실패한 리소스 작업 해결(PCS 상태 하단에 있음)</block>
  <block id="ac9c4f2d9dc79954795119e7ac4da835" category="inline-link-macro">계획되지 않은 페일오버 후 페일백</block>
  <block id="899430038aa8ddcfa7ab42a1d1943ea5" category="paragraph">BeeGFS 서비스를 실행하는 데 필요한 리소스에 장애가 발생하면 BeeGFS 모니터에서 페일오버가 트리거됩니다. 이 경우 하단에 "실패한 리소스 작업"이 표시되지 않을 수 있습니다<block ref="fcad1c87c23363c990849a7aaf9d6cd9" prefix=" " category="inline-code"></block> 및 에 대한 단계를 참조해야 합니다 <block ref="119b29e10d1a1bb55d1b986e2dceaeea" category="inline-link-macro-rx"></block>.</block>
  <block id="afdd1f65895e11b4a9ab295926e39116" category="paragraph">그렇지 않으면 일반적으로 "실패한 리소스 작업"이 표시되는 두 가지 시나리오만 있어야 합니다.</block>
  <block id="43c78de0154f6f48f749527f62bfd41c" category="section-title">시나리오 1: 펜싱 에이전트에서 일시적 또는 영구적인 문제가 감지되어 이를 다시 시작하거나 다른 노드로 이동했습니다.</block>
  <block id="b06e37c96b80ada3e042c0997f9d54a6" category="paragraph">일부 펜싱 에이전트는 다른 펜싱 장치보다 신뢰성이 높으며 각 펜싱 장치가 준비되도록 자체 모니터링 방법을 구현합니다. 특히 Redfish 펜싱 에이전트가 여전히 started로 표시되더라도 다음과 같은 실패한 리소스 작업을 보고하는 것으로 나타났습니다.</block>
  <block id="13ff1974a31501c1a357c51cda2ff685" category="paragraph">특정 노드에서 장애가 발생한 리소스 작업을 보고하는 펜싱 에이전트가 해당 노드에서 실행되는 BeeGFS 서비스의 페일오버를 트리거하지 않습니다. 동일한 노드 또는 다른 노드에서 자동으로 다시 시작하기만 하면 됩니다.</block>
  <block id="549252a4b6f49c6993519d622a3e9c5d" category="paragraph">해결 단계:</block>
  <block id="51f376a71f801714c5dbbdfa83541a86" category="list-text">펜싱 에이전트가 노드 전체 또는 하위 집합에서 지속적으로 실행을 거부하는 경우 해당 노드가 펜싱 에이전트에 연결할 수 있는지 확인하고 펜싱 에이전트가 Ansible 인벤토리에서 올바르게 구성되었는지 확인합니다.</block>
  <block id="1ae58017c838c0e0ed1e3299e7c683d5" category="list-text">예를 들어, BMC(Redfish) 펜싱 에이전트가 펜싱을 담당하는 동일한 노드에서 실행되고 있고 OS 관리 및 BMC IP가 동일한 물리적 인터페이스에 있는 경우 일부 네트워크 스위치 구성에서는 두 인터페이스 간의 통신을 허용하지 않습니다(네트워크 루프 방지). 기본적으로 HA 클러스터는 펜싱을 담당하는 노드에 펜싱 에이전트를 배치하는 것을 피하려고 하지만 일부 시나리오/구성에서는 이러한 문제가 발생할 수 있습니다.</block>
  <block id="217b4320fb1b29ae95bb478645ec6ba8" category="list-text">모든 문제가 해결되거나 문제가 일시적인 것으로 나타나는 경우 를 실행합니다<block ref="b292ce60014c1c0e30e4db1f177243d3" prefix=" " category="inline-code"></block> 실패한 리소스 작업을 재설정합니다.</block>
  <block id="5e2b597167eb07cb64833681dcd53f6f" category="section-title">시나리오 2: BeeGFS 모니터가 문제를 감지하여 페일오버를 트리거했지만, 어떤 이유로 보조 노드에서 리소스를 시작할 수 없습니다.</block>
  <block id="cf41377d64715247d22bef68c671d9dc" category="paragraph">펜싱이 활성화되고 리소스가 원래 노드에서 정지하는 것을 차단하지 않은 경우("대기(장애 발생 시)"의 문제 해결 섹션 참조), 보조 노드에서 리소스를 시작하는 데 다음과 같은 문제가 원인일 수 있습니다.</block>
  <block id="ecbc2fa36aa8e4ccfd535f315ff5a1bc" category="list-text">보조 노드가 이미 오프라인 상태입니다.</block>
  <block id="9fc9f95992286a812b388e7c2def3cde" category="list-text">물리적 또는 논리적 구성 문제로 인해 보조 시스템에서 BeeGFS 타겟으로 사용되는 블록 볼륨에 액세스하지 못했습니다.</block>
  <block id="1ffc42a5bdee5039a96dffea4901017d" category="list-text">실패한 리소스 작업의 각 항목에 대해 다음을 수행합니다.</block>
  <block id="fb6dc7c10276db82fd903122c9aa6780" category="list-text">실패한 리소스 작업이 시작 작업인지 확인합니다.</block>
  <block id="6ec17a9b3e2983ef695c793467180ed8" category="list-text">표시된 리소스와 실패한 리소스 작업에 지정된 노드를 기반으로 합니다.</block>
  <block id="15cdec9d63ec68e3300810746f7c66c5" category="list-text">노드가 지정된 리소스를 시작하지 못하는 외부 문제를 찾아 해결합니다. 예를 들어 BeeGFS IP 주소(부동 IP)를 시작하지 못한 경우 필요한 인터페이스 중 하나 이상이 온라인으로 연결되어 있고 올바른 네트워크 스위치에 케이블로 연결되어 있는지 확인합니다. BeeGFS 타겟(블록 디바이스/E-Series 볼륨)에 장애가 발생한 경우 백엔드 블록 노드에 대한 물리적 접속이 예상대로 접속되어 있는지 확인하고 블록 노드가 정상 상태인지 확인합니다.</block>
  <block id="66f0528ed6c9cd01b92486aef88bca25" category="list-text">명확한 외부 문제가 없고 이 인시던트에 대한 근본 원인이 필요한 경우, 다음 단계로 인해 근본 원인 분석(RCA)이 어렵거나 불가능할 수 있으므로 계속하기 전에 NetApp Support에서 케이스를 열어 조사하는 것이 좋습니다.</block>
  <block id="3f79d63c01f8e573f1485641a01784f5" category="list-text">외부 문제 해결 후:</block>
  <block id="0fc5581e5e588d921d0659c6725c8bb7" category="list-text">Anabilities inventory.yml 파일에서 작동하지 않는 노드를 모두 제거하고 전체 Ansible 플레이북을 다시 실행하여 모든 논리적 구성이 보조 노드에 올바르게 설정되었는지 확인합니다.</block>
  <block id="837bc4d502bb7c6e4bb1557e18c0d778" category="list-text">참고: 노드 상태가 양호하고 페일백할 준비가 되면 이러한 노드의 주석을 해제하고 플레이북을 다시 실행하십시오.</block>
  <block id="7198cccc6bdd4a3f49c6f73aecb797e3" category="list-text">또는 클러스터를 수동으로 복구할 수도 있습니다.</block>
  <block id="6db4e0b9e5f080b1d47896ae71390476" category="list-text">다음을 사용하여 오프라인 노드를 다시 온라인 상태로 전환:<block ref="2e6a9bc781ade1dd9ff94654afbc34bd" prefix=" " category="inline-code"></block></block>
  <block id="0292b418af30a3106696db822913b4fd" category="list-text">다음을 사용하여 실패한 모든 리소스 작업을 지웁니다.<block ref="b292ce60014c1c0e30e4db1f177243d3" prefix=" " category="inline-code"></block></block>
  <block id="8177fac49f20d8c76b3afe0ead42fe89" category="list-text">PCS 상태를 실행하고 모든 서비스가 예상대로 시작되는지 확인합니다.</block>
  <block id="0a584da0f19f70578ae419f6c3de1804" category="list-text">필요한 경우 실행합니다<block ref="31b8a2d98f4312a9e7b7ac373d9cca6a" prefix=" " category="inline-code"></block> 리소스를 원하는 노드로 다시 이동하려면(사용 가능한 경우)</block>
  <block id="b34551a00d39152d67273fc8e1fc4a52" category="section-title">일반적인 문제</block>
  <block id="e728c5fcf9b4ab50066868a6b637a709" category="section-title">BeeGFS 서비스는 요청 시 페일오버 또는 페일백을 수행하지 않습니다</block>
  <block id="07f7fa9ba2b669bb79d185d75b136e12" category="paragraph">* 가능성 높은 문제: *<block ref="960b2f261f11ad1988eea18a4ecc34c9" prefix=" " category="inline-code"></block> 실행 명령이 실행되었지만 성공적으로 완료되지 않았습니다.</block>
  <block id="844f68b15c1713a6baa4b0ec6aa225df" category="paragraph">* 확인 방법: * 실행<block ref="5a4892b5d40be89d668321c86afd400b" prefix=" " category="inline-code"></block> ID가 인 위치 제약 조건이 있는지 확인합니다<block ref="2fcf6d99d76b884a404fa4e359bf2b59" prefix=" " category="inline-code"></block>.</block>
  <block id="9e43dd5b3ec5864eaeb73e8dc9a4a445" category="paragraph">* 해결 방법: * 실행<block ref="3132f7183339b30b65d4c94ec98e59c6" prefix=" " category="inline-code"></block> 그런 다음 다시 실행합니다<block ref="5a4892b5d40be89d668321c86afd400b" prefix=" " category="inline-code"></block> 추가 구속조건이 제거되었는지 확인합니다.</block>
  <block id="1950007e622fca4ac1ecb2dca5c5b0ca" category="section-title">펜싱이 비활성화된 경우 PCS 상태의 노드 중 하나에 "STANDBY(ON-FAIL)"가 표시됩니다</block>
  <block id="7f73632b6cb42dac5be42f899b8f3075" category="paragraph">* 가능성 높은 문제: * 심장박동기가 실패한 노드에서 모든 리소스가 중지되었는지 확인할 수 없습니다.</block>
  <block id="62e46498125737c7dea16f67e65f663b" category="paragraph">* 해결 방법: *</block>
  <block id="2443318955c1e9ac3d484a3a95366847" category="list-text">실행<block ref="fcad1c87c23363c990849a7aaf9d6cd9" prefix=" " category="inline-code"></block> 그리고 출력 하단에 "시작"되지 않은 리소스 또는 오류가 표시되는지 확인하고 모든 문제를 해결합니다.</block>
  <block id="fde999fddc7a609f9b1112a0d74b811e" category="list-text">노드를 다시 온라인 상태로 전환하려면 다음을 수행합니다<block ref="22c6d25b4cef458448bf6ec7b072cfdc" prefix=" " category="inline-code"></block>.</block>
  <block id="0b566700630488a9f296399143b71b21" category="section-title">예기치 않은 장애 조치 후 펜싱이 활성화된 경우 PCS 상태에 "started (on-fail)"가 표시됩니다</block>
  <block id="d82216004991d1ee26d8a39d995fd037" category="paragraph">* 가능성 높은 문제: * 장애 조치를 트리거한 문제가 발생했지만 심장박동기가 노드 펜싱되었는지 확인할 수 없었습니다. 펜싱이 잘못 구성되었거나 펜싱 에이전트(예: 네트워크에서 PDU 연결이 끊어짐)에 문제가 있기 때문에 이 문제가 발생할 수 있습니다.</block>
  <block id="d9377bb89128ecc3849d522366a1bc0e" category="list-text">노드의 전원이 실제로 꺼져 있는지 확인합니다.</block>
  <block id="26cf4911b5df9522d0b71ba51aa2797f" category="admonition">지정하는 노드가 실제로 꺼져 있지 않지만 클러스터 서비스 또는 리소스를 실행하는 경우 데이터 손상/클러스터 장애가 발생합니다.</block>
  <block id="eb7adca6805c8d7130032cd721d69726" category="list-text">다음을 사용하여 펜싱을 수동으로 확인합니다.<block ref="5448b9bc8364c2b3f706918cda259325" prefix=" " category="inline-code"></block></block>
  <block id="1c0ee784ecf6c6dae18bd342462b0460" category="paragraph">이 시점에서 서비스는 장애 조치를 완료하고 다른 정상 노드에서 다시 시작해야 합니다.</block>
  <block id="144c35532a298805242b9831523175df" category="section-title">일반적인 문제 해결 작업</block>
  <block id="e78d742ead1e3187a4781d20c9f53692" category="section-title">개별 BeeGFS 서비스를 다시 시작합니다</block>
  <block id="5bd968465c3ccdeb171ce7ade4907d6f" category="paragraph">일반적으로 BeeGFS 서비스를 다시 시작해야 하는 경우(예: 구성 변경을 용이하게 함) Ansible 인벤토리를 업데이트하고 플레이북을 다시 실행하여 이 작업을 수행해야 합니다. 경우에 따라 전체 Playbook을 실행할 때까지 기다릴 필요 없이 로깅 수준을 변경하는 등 더 빠른 문제 해결을 위해 개별 서비스를 다시 시작하는 것이 좋습니다.</block>
  <block id="57f3d071d972e615cf2b21fc580b3981" category="admonition">수동 변경 사항도 Ansible 인벤토리에 추가되지 않으면 다음 번에 Ansible 플레이북을 실행할 때 되돌릴 수 있습니다.</block>
  <block id="e6ec687230170238fbff13af150aac11" category="section-title">옵션 1: 시스템 d가 재시작을 제어했습니다</block>
  <block id="8bd682031ba8c79bdc3518a66ecb5f1d" category="paragraph">BeeGFS 서비스가 새 구성으로 제대로 재시작되지 않을 위험이 있는 경우 먼저 클러스터를 유지 관리 모드로 전환하여 BeeGFS 모니터가 서비스를 감지하지 못하게 하고 원치 않는 페일오버를 트리거하는 것을 방지하십시오.</block>
  <block id="e445f63138e0cf42d48b191e7212fba5" category="paragraph">필요한 경우 에서 서비스 구성을 변경합니다<block ref="7b2e56941196b9587e16891bfbec2093" prefix=" " category="inline-code"></block> (예:<block ref="e3cb2c4f0757837b4a51b638bed0ec4d" prefix=" " category="inline-code"></block>) 그런 다음 systemd를 사용하여 다시 시작합니다.</block>
  <block id="fc618f42db9108f58f9c7fc76181a551" category="paragraph">예:<block ref="d1adfe915ae154bb103f4a2e2d28183d" prefix=" " category="inline-code"></block></block>
  <block id="b8a88c45f80fb4ad388f6cfe0958b272" category="section-title">옵션 2: 심장박동기 제어 재시작</block>
  <block id="b28d67df7faeb6762f0262ed21fd5c44" category="paragraph">새로운 구성으로 인해 서비스가 예기치 않게 중지되거나(예: 로깅 수준 변경) 유지 보수 기간에 있고 다운타임이 염려되지 않는 경우 다시 시작할 서비스에 대해 BeeGFS 모니터를 다시 시작하면 됩니다.</block>
  <block id="1ea90ec9ad2232dc8536efa244b502cd" category="paragraph">예를 들어 BeeGFS 관리 서비스를 다시 시작하려면<block ref="19191ce739dde363bc25ef750853010b" prefix=" " category="inline-code"></block></block>
  <block id="647328604bd666deba44b0caaea998a2" category="summary">구축된 BeeGFS HA 클러스터를 관리하는 방법에 대해 알아보십시오.</block>
  <block id="0aa1ffb15625f418cfc560deda2535bb" category="doc">개요, 주요 개념 및 용어</block>
  <block id="d051e95d54ee33ed5c79e05f582bab59" category="paragraph">이 섹션은 구축된 BeeGFS HA 클러스터를 관리해야 하는 클러스터 관리자를 대상으로 합니다. Linux HA 클러스터에 익숙한 사람조차도 이 가이드를 완전히 읽어야 합니다. Ansible을 사용하여 재구성을 수행할 때는 특히 클러스터 관리 방법에 여러 가지 차이점이 있기 때문입니다.</block>
  <block id="612b7c650263f39248b97e7e57b35a77" category="section-title">주요 개념</block>
  <block id="db7e5dec439a7c83d48d86330a62e954" category="inline-link-macro">용어 및 개념</block>
  <block id="f0ca7f454ca467a752ad7b5f66747b70" category="paragraph">이러한 개념 중 일부는 주요 제품에 소개되어 있습니다 <block ref="9a256c21d0775c8b23b592e82da8914c" category="inline-link-macro-rx"></block> BeeGFS HA 클러스터의 컨텍스트에서 이러한 기능을 다시 소개하는 것이 좋습니다.</block>
  <block id="8961c26dabe98c278717f1cb0fc25fdc" category="paragraph">** 클러스터 노드:** 심장박동기 및 Corosync 서비스를 실행하고 HA 클러스터에 참여하는 서버.</block>
  <block id="e0a3a06b3c015009967896eb40327e82" category="paragraph">** 파일 노드:** 하나 이상의 BeeGFS 관리, 메타데이터 또는 스토리지 서비스를 실행하는 데 사용되는 클러스터 노드입니다.</block>
  <block id="1985ebdeb71d83b6b551914e77b2b178" category="paragraph">** 블록 노드:** 파일 노드에 블록 스토리지를 제공하는 NetApp E-Series 스토리지 시스템 이러한 노드는 자체 독립형 HA 기능을 제공하므로 BeeGFS HA 클러스터에 참여하지 않습니다. 각 노드는 블록 계층에서 고가용성을 제공하는 2개의 스토리지 컨트롤러로 구성됩니다.</block>
  <block id="31a3205f29074295100fad4351661826" category="paragraph">** BeeGFS 서비스:** BeeGFS 관리, 메타데이터 또는 스토리지 서비스 각 파일 노드는 블록 노드의 볼륨을 사용하여 데이터를 저장하는 하나 이상의 서비스를 실행합니다.</block>
  <block id="495f4cf25a1d9d4e5a1258aafbbf0c8d" category="paragraph">** 빌딩 블록:** BeeGFS 파일 노드, E-Series 블록 노드 및 BeeGFS 서비스를 표준화된 방식으로 구축하여 NetApp 검증 아키텍처에 따라 BeeGFS HA 클러스터/파일 시스템을 간편하게 확장할 수 있습니다. 맞춤형 HA 클러스터도 지원되지만, 확장을 단순화하기 위해 유사한 구성 요소 접근 방식을 따르는 경우가 많습니다.</block>
  <block id="f1816719094f9c5af3f9f2666c1c5666" category="paragraph">** BeeGFS HA Cluster:** 블록 노드에서 지원하는 BeeGFS 서비스를 실행하는 데 사용되는 확장 가능한 수의 파일 노드를 통해 BeeGFS 데이터를 고가용성 방식으로 저장합니다. 패키징 및 배포를 위해 Ansible을 사용하여 업계에서 검증된 오픈 소스 구성 요소 페이스 메이커 및 Corosync를 기반으로 합니다.</block>
  <block id="830f6f39f3eb0533714fc986605bb0fc" category="paragraph">** 클러스터 서비스: ** 클러스터에 참여하는 각 노드에서 실행 중인 심장박동기 및 Corosync 서비스를 나타냅니다. 참고: 노드가 BeeGFS 서비스를 실행하지 않고 단지 두 개의 파일 노드만 필요한 경우 "Tiebreaker" 노드로 클러스터에 참여할 수 있습니다.</block>
  <block id="ac47f8eb4b50e1f3fefe94fafff761c2" category="paragraph">** 클러스터 리소스:** 클러스터에서 실행 중인 각 BeeGFS 서비스에 대해 BeeGFS 모니터링 리소스와 BeeGFS 타겟, IP 주소(부동 IP) 및 BeeGFS 서비스 자체에 대한 리소스가 포함된 리소스 그룹이 표시됩니다.</block>
  <block id="25d0c377de7b7699ce796352723a7a41" category="paragraph">Ansible:** 소프트웨어 프로비저닝, 구성 관리 및 애플리케이션 배포를 위한 도구로 인프라를 코드로 구현할 수 있습니다. BeeGFS HA 클러스터를 패키지화하여 NetApp에서 BeeGFS 구축, 재구성 및 업데이트 프로세스를 간소화합니다.</block>
  <block id="53ece6444fc3a7adacd61f55a3d5e410" category="paragraph">** PCS:** 클러스터의 파일 노드에서 사용할 수 있는 명령줄 인터페이스입니다. 이 인터페이스는 클러스터의 노드 및 리소스 상태를 쿼리하고 제어하는 데 사용됩니다.</block>
  <block id="1ed63b060fea1b0497535f402b308312" category="section-title">일반 용어</block>
  <block id="d3d43886ce330c5bc1abf87c9da84517" category="paragraph">** 장애 조치:** 각 BeeGFS 서비스에는 해당 노드에 장애가 발생하지 않는 한 실행되는 기본 파일 노드가 있습니다. 비기본/보조 파일 노드에서 BeeGFS 서비스를 실행하는 경우 페일오버 중인 것으로 표시됩니다.</block>
  <block id="360fc740d5a934107e93d720053a8a24" category="paragraph">** 페일백:** 비기본 파일 노드에서 기본 설정 노드로 BeeGFS 서비스를 이동하는 동작</block>
  <block id="1687b43e3f76609bd3a5dda1cdbd29b3" category="paragraph">** HA 쌍:** 동일한 블록 노드 세트에 액세스할 수 있는 두 개의 파일 노드를 HA 쌍이라고도 합니다. 이는 NetApp 전체에서 사용되는 일반적인 용어로 서로 "이어갈" 수 있는 2개의 스토리지 컨트롤러 또는 노드를 참조하는 데 사용됩니다.</block>
  <block id="3663bc32267b225ac55e52a4e99f2b3c" category="inline-link-macro">유지보수 모드</block>
  <block id="39560dcdbcd94c46104949cdc818ff92" category="paragraph">** 유지 관리 모드:** 모든 리소스 모니터링을 비활성화하고 심장박동기 가 클러스터 리소스를 이동하거나 관리하는 것을 방지합니다(의 섹션 참조) <block ref="f0a78cef389e4c877fc593c4dc0dd05c" category="inline-link-macro-rx"></block>)를 클릭합니다.</block>
  <block id="e7f8a11794ad2275f244bec012ef84de" category="paragraph">** HA 클러스터:** 클러스터의 여러 노드 간에 페일오버하여 가용성이 높은 BeeGFS 파일 시스템을 생성할 수 있는 BeeGFS 서비스를 실행하는 하나 이상의 파일 노드. 파일 노드는 클러스터에서 BeeGFS 서비스의 하위 집합을 실행할 수 있는 HA 쌍으로 구성되는 경우가 많습니다.</block>
  <block id="c8c3d1dbab26a87a3652e84d9f35d37f" category="summary">HA 클러스터를 관리하기 위해 Ansible과 PCS 명령줄 도구를 사용해야 하는 경우는 언제입니까?</block>
  <block id="932c5a738d1d867e858cd1dbc1391b1a" category="doc">Ansible과 PCS 도구를 사용해야 하는 경우</block>
  <block id="272d3f535988cc62fbddd197f2ce0477" category="paragraph">모든 클러스터 배포 및 재구성 작업은 외부 Ansible 제어 노드의 Ansible을 사용하여 완료해야 합니다. 클러스터 상태의 일시적인 변경(예: 대기 모드 내외부로 노드 배치)은 일반적으로 클러스터의 한 노드(성능이 저하되지 않거나 유지 보수를 수행하려고 하지 않는 노드)에 로그인하고 PCS 명령줄 도구를 사용하여 수행됩니다.</block>
  <block id="5b94af0d2c18b35c22f5cfa622f91a3c" category="paragraph">리소스, 제약, 속성 및 BeeGFS 서비스 자체를 비롯한 클러스터 구성을 수정하려면 항상 Ansible을 사용해야 합니다. Ansible 인벤토리 및 플레이북의 최신 복사본(소스 제어 기능을 통해 변경 사항을 추적하는 것이 이상적)을 유지하는 것은 클러스터를 유지하는 데 필요한 부분입니다. 구성을 변경해야 하는 경우 인벤토리를 업데이트하고 BeeGFS HA 역할을 가져오는 Ansible 플레이북을 다시 실행합니다.</block>
  <block id="636c6afe41e34a0f4dc30a8fee8de25c" category="paragraph">HA 역할은 클러스터를 유지 관리 모드로 설정한 다음 필요한 변경을 수행한 후 BeeGFS 또는 클러스터 서비스를 다시 시작하여 새 구성을 적용하는 작업을 처리합니다. 전체 노드 재부팅은 일반적으로 초기 구현 이후에 필요하지 않기 때문에 Ansible을 다시 실행하는 것은 일반적으로 "안전한" 절차로 간주되지만, BeeGFS 서비스를 다시 시작해야 할 경우 유지보수 시간이나 근무 시간 외에 실행하는 것이 좋습니다. 이러한 재시작으로 인해 일반적으로 응용 프로그램 오류가 발생하지는 않지만 성능이 저하될 수 있습니다(일부 응용 프로그램이 다른 응용 프로그램보다 더 잘 처리할 수 있음).</block>
  <block id="cfe79eee27daf73a913f7b76cbb46461" category="paragraph">또한 Ansible을 다시 실행하는 것은 전체 클러스터를 최적의 상태로 되돌리는 옵션이며, 경우에 따라 PC를 사용할 때보다 클러스터의 상태를 더 쉽게 복구할 수 있습니다. 특히 어떤 이유로 클러스터가 중단된 비상 상황에서는 모든 노드가 다시 실행 중인 Ansible을 사용하면 PC를 사용하는 것보다 신속하고 안정적으로 클러스터를 복구할 수 있습니다.</block>
  <block id="c94162d41104b03145716ac6946bd39a" category="summary">Ansible을 사용하여 클러스터를 재구성합니다.</block>
  <block id="388a6dd09725cda0da5d81c2d32f9c19" category="doc">HA 클러스터와 BeeGFS를 재구성합니다</block>
  <block id="cb584c33a4eae31ed6d0c6ae575a915c" category="inline-link-macro">일반 파일 노드 구성을 지정합니다</block>
  <block id="2141a88f2dbe4203823c0a65261cec92" category="paragraph">일반적으로 BeeGFS HA 클러스터의 모든 측면을 재구성할 때는 Ansible 인벤토리를 업데이트하고 을 다시 실행해야 합니다<block ref="6afa1ad605a4192ba2e50e8be9966e68" prefix=" " category="inline-code"></block> 명령. 여기에는 알림 업데이트, 영구 펜싱 구성 변경 또는 BeeGFS 서비스 구성 조정 등이 포함됩니다. 이러한 설정은 를 사용하여 조정합니다<block ref="4003590e6e5408f8e5272e50f909dfac" prefix=" " category="inline-code"></block> 파일 및 전체 옵션 목록은 에서 찾을 수 있습니다 <block ref="bd1503180303c25487957027c3618d2a" category="inline-link-macro-rx"></block> 섹션을 참조하십시오.</block>
  <block id="f7f37d848a0be4caeb97d6886778dc2a" category="paragraph">유지 관리를 수행하거나 클러스터를 서비스할 때 관리자가 알아야 하는 구성 옵션에 대한 자세한 내용은 아래를 참조하십시오.</block>
  <block id="d876616b83b1231cc28d82f157ed29c5" category="section-title">펜싱 비활성화 및 활성화 방법</block>
  <block id="22228968b8b77db0d4e57d7cb284feb3" category="paragraph">클러스터를 설정할 때 펜싱은 기본적으로 활성화/필요합니다. 경우에 따라 펜싱을 일시적으로 비활성화하여 운영 체제 업그레이드와 같은 특정 유지보수 작업을 수행할 때 노드가 실수로 종료되지 않도록 하는 것이 좋습니다. 이 기능은 수동으로 비활성화할 수 있지만 관리자가 주의해야 할 단점이 있습니다.</block>
  <block id="bdb2b6bd7635150b7e92a51e70612e12" category="section-title">옵션 1: Ansible을 사용하여 펜싱 비활성화(권장)</block>
  <block id="619a84cba5006df3e436e2a726ca2871" category="paragraph">Ansible을 사용하여 펜싱을 비활성화하면 BeeGFS 모니터의 장애 발생 시 동작이 "fence"에서 "standby"로 변경됩니다. 즉, BeeGFS 모니터가 장애를 감지하면 노드를 대기 상태로 두고 모든 BeeGFS 서비스를 페일오버하려고 합니다. 활성 상태의 문제 해결/테스트 이외의 경우 일반적으로 옵션 2보다 더 권장됩니다. 단점은 리소스가 원래 노드에서 중지되지 않을 경우 다른 위치에서 시작하는 것이 차단된다는 것입니다(즉, 펜싱은 일반적으로 운영 클러스터에 필요합니다).</block>
  <block id="0809fe829e193f81980e79631c9c15cc" category="list-text">에 있는 Ansible 인벤토리에 들어 있습니다<block ref="24eab3114da61057c831607cf391b3b9" prefix=" " category="inline-code"></block> 다음 구성을 추가합니다.</block>
  <block id="d73646db1bf30029f2486d5b7462cde5" category="list-text">Ansible 플레이북을 다시 실행하여 클러스터의 변경 사항을 적용합니다.</block>
  <block id="50a460b97c563d3429b629b6911db7d5" category="section-title">옵션 2: 수동으로 펜싱을 비활성화합니다.</block>
  <block id="28850c63d2fb8db15eeb1664c121e11b" category="paragraph">경우에 따라 Ansible을 다시 실행하지 않고 펜싱을 일시적으로 비활성화할 수 있으며, 클러스터에 대한 문제 해결 또는 테스트를 용이하게 할 수 있습니다.</block>
  <block id="e0740d4e01fcc73df3a73294627cd292" category="admonition">이 구성에서 BeeGFS 모니터가 장애를 감지하면 클러스터가 해당 리소스 그룹을 중지하려고 시도합니다. 전체 페일오버를 트리거하거나 영향을 받는 리소스 그룹을 다시 시작하거나 다른 호스트로 이동하려고 시도하지 않습니다. 복구하려면 문제를 해결한 다음 를 실행하십시오<block ref="b292ce60014c1c0e30e4db1f177243d3" prefix=" " category="inline-code"></block> 또는 노드를 수동으로 대기 상태로 전환합니다.</block>
  <block id="99f83169540f1c3e08a1e696707dcbee" category="list-text">펜싱(STONITH)이 전역적으로 활성화 또는 비활성화되었는지 확인하려면 다음을 실행하십시오.<block ref="f9bc36eebaadfbe3971849dbb1a7a291" prefix=" " category="inline-code"></block></block>
  <block id="88653da28715cbac123466935349c7b2" category="list-text">펜싱 실행을 비활성화하려면:<block ref="d3749d5705f2a9af97f05b0c5c91b235" prefix=" " category="inline-code"></block></block>
  <block id="79c811c32be072ba96828f7eaf67e191" category="list-text">펜싱 실행을 활성화하려면:<block ref="65795833f6c4653caabc1cbacafe84d8" prefix=" " category="inline-code"></block></block>
  <block id="54dfcc160f4c7fc21df07ee9c7df6f86" category="paragraph">참고: 이 설정은 다음 번에 Ansible 플레이북을 실행할 때 재정의됩니다.</block>
  <block id="d60c67e58f8b774cb2aa20f043f8db60" category="summary">Ansible을 사용하여 BeeGFS 및 HA 클러스터를 업데이트합니다.</block>
  <block id="c53f6cfbd1ec7e63b00c0287a063e28c" category="doc">HA 클러스터와 BeeGFS를 업데이트합니다</block>
  <block id="1d1a2914dac869f373457b417771e6a6" category="paragraph">BeeGFS 버전은 에 따라 버전이 적용됩니다<block ref="95d209426d2bead51bc37b6066b6ee21" prefix=" " category="inline-code"></block> 지원되는 각 BeeGFS에 대해 버전 관리 체계 및 BeeGFS HA Ansible 역할이 제공됩니다<block ref="708997fbc70843c52165e3f6faed4fa8" prefix=" " category="inline-code"></block> 버전(예<block ref="4111d90a1d8089aa9621c399414fd198" prefix=" " category="inline-code"></block> 및<block ref="7bfdf60ffcc8e818739972660aeebf71" prefix=" " category="inline-code"></block>)를 클릭합니다. 각 HA 역할은 Ansible 컬렉션이 릴리즈될 때 최신 BeeGFS 패치 버전에 고정됩니다.</block>
  <block id="51e0180a7b3c2158984fbbe6e8f869a0" category="paragraph">Ansible을 사용하여 BeeGFS의 주요 버전, 부 버전, 패치 버전 간 이동을 비롯한 모든 BeeGFS 업그레이드를 수행할 수 있습니다. BeeGFS를 업데이트하려면 먼저 BeeGFS Ansible 컬렉션을 업데이트해야 합니다. 그러면 구축/관리 자동화 및 기본 HA 클러스터에 대한 최신 수정 사항 및 개선 사항도 포함됩니다. 최신 버전의 컬렉션으로 업데이트한 후에도 BeeGFS는 까지 업그레이드되지 않습니다<block ref="6afa1ad605a4192ba2e50e8be9966e68" prefix=" " category="inline-code"></block> 가 와 함께 실행되었습니다<block ref="1c5a0082b7b70fba66dc89c5dcadda70" prefix=" " category="inline-code"></block> 설정.</block>
  <block id="c647c561b083b3d7395174f66f8631ea" category="inline-link-macro">BeeGFS 업그레이드 설명서</block>
  <block id="c24ac53eed3b244d067e62d9a64dfd49" category="admonition">BeeGFS 버전에 대한 자세한 내용은 를 참조하십시오 <block ref="8574fc3a2a061b998ddd0369208f121a" category="inline-link-macro-rx"></block>.</block>
  <block id="249c0f5c176707459e70ddb6695a2d0b" category="section-title">테스트된 업그레이드 경로</block>
  <block id="47d550a414d88378d8af3a8ee7202f43" category="paragraph">각 버전의 BeeGFS 컬렉션은 특정 버전의 BeeGFS에서 테스트하여 모든 구성 요소 간의 상호 운용성을 보장합니다. 또한 컬렉션의 마지막 버전에서 지원되는 BeeGFS 버전에서 최신 릴리즈에서 지원되는 버전으로 업그레이드할 수 있도록 테스트가 수행됩니다.</block>
  <block id="898fd772d03120abb80bc290103408c1" category="cell">원본 버전</block>
  <block id="6b109fe64fc40b0f8653da2a76f4622d" category="cell">버전 업그레이드</block>
  <block id="4805ea9349955c3f72d0d2a6e29e9599" category="cell">멀티 레일</block>
  <block id="3ec365dd533ddb7ef3d1c111186ce872" category="cell">세부 정보</block>
  <block id="0cbcbda5109bcde6b94054595b5c2163" category="cell">7.3.2</block>
  <block id="93cba07454f06a4a960172bbd6e2a435" category="cell">예</block>
  <block id="80af1bca395a5729dba29bf239d414de" category="cell">v3.0.1에서 v3.1.0으로 Beegfs 컬렉션을 업그레이드하는 중, 멀티레일이 추가되었습니다</block>
  <block id="cd0d3c01d5de47172fb0980b9e484085" category="cell">7.2.8</block>
  <block id="bafd7322c6e97d25b6299b5d6fe8920b" category="cell">아니요</block>
  <block id="f8c6df0b95129e4f957da4faa69e9a95" category="cell">v3.0.1에서 v3.1.0으로 Beegfs 컬렉션 업그레이드</block>
  <block id="90e738eca301c4d89366b1a4d15fe37f" category="cell">7.3.1에서 포함</block>
  <block id="37ee8dee8daa5fa1f91e93f31f1e4548" category="cell">begfs 컬렉션 v3.1.0을 사용하여 업그레이드하십시오. 멀티레일이 추가되었습니다</block>
  <block id="35aee211b7a94a90469b8820e9b58379" category="cell">Beegfs 컬렉션 v3.1.0을 사용하여 업그레이드합니다</block>
  <block id="390e3e776572a27d6c80365516e8c16b" category="section-title">BeeGFS 업그레이드 단계</block>
  <block id="273ff57e75c54934edf55dce6acbd4fb" category="paragraph">다음 섹션에서는 BeeGFS Ansible 컬렉션 및 BeeGFS 자체를 업데이트하는 단계를 제공합니다. BeeGFS 주 버전 또는 부 버전 업데이트에 대한 추가 단계에 특히 주의하십시오.</block>
  <block id="b57e5fe19f7ba63474311a27d676448b" category="section-title">1단계: BeeGFS 컬렉션 업그레이드</block>
  <block id="2f4c1ac28e39c823ee4c1a07b7cd93aa" category="paragraph">에 액세스하여 컬렉션 업그레이드용 <block ref="d8617fd1dfbd628e2360b843d6070e54" category="inline-link-macro-rx"></block>에서 다음 명령을 실행합니다.</block>
  <block id="c199206a11a9882502e88de065338656" category="paragraph">오프라인 컬렉션 업그레이드의 경우 에서 컬렉션을 다운로드하십시오 <block ref="d8617fd1dfbd628e2360b843d6070e54" category="inline-link-macro-rx"></block> 원하는 을 클릭합니다<block ref="5ab34c986ae1945ee0c548bc8d6ac4a8" prefix=" " category="inline-code"></block> 그리고 나서<block ref="80af28150f2ffd9a902b18cd4e9b6656" prefix=" " category="inline-code"></block>. 타볼을 Ansible 제어 노드로 전송하고 다음 명령을 실행합니다.</block>
  <block id="dd26fb41f43f69172e0099b87c9d0732" category="inline-link-macro">컬렉션 설치 중</block>
  <block id="6aa260cc14fabe54e7e9f6efd513b871" category="paragraph">을 참조하십시오 <block ref="78e19afa50f5104f13264e857fffab2b" category="inline-link-macro-rx"></block> 를 참조하십시오.</block>
  <block id="e3e48a2ea685760842b2722b48a2e797" category="section-title">2단계: Ansible 인벤토리 업데이트</block>
  <block id="e6811430a0324887ba2ad63393a262e1" category="inline-link-macro">버전 업그레이드 참고 사항</block>
  <block id="91eaeb6e5e7e4e970687d3f792cb1fc2" category="inline-link-macro">사용자 정의 아키텍처를 사용합니다</block>
  <block id="1fd9deaaaf47488f551e416eed092dc4" category="paragraph">클러스터의 Ansible 인벤토리 파일에 대해 필요하거나 원하는 업데이트를 수행합니다. 를 참조하십시오 <block ref="45bb05730b6b8d8285ea6a3b0b08136e" category="inline-link-macro-rx"></block> 특정 업그레이드 요구 사항에 대한 자세한 내용은 아래 섹션을 참조하십시오. 를 참조하십시오 <block ref="cd8d64b4736b3d402448d2252c8caef5" category="inline-link-macro-rx"></block> BeeGFS HA 인벤토리 구성에 대한 일반 정보를 보려면 섹션을 참조하십시오.</block>
  <block id="e9bec369ce9e01aa4b52853b96332456" category="section-title">3단계: Ansible 플레이북 업데이트(주 버전 또는 부 버전만 업데이트할 경우)</block>
  <block id="741fd5c03969a4e2dd468f897af24b03" category="paragraph">주 버전 또는 부 버전 간에 이동하는 경우 에서 를 참조하십시오<block ref="2f78c4e27feaf25ffb33d97e8ff7e7a6" prefix=" " category="inline-code"></block> 클러스터를 구축하고 유지하는 데 사용되는 파일, 의 이름을 업데이트합니다<block ref="66b5cc4f55c22b7b05dfd4be1be47aab" prefix=" " category="inline-code"></block> 원하는 버전을 반영하는 역할입니다. 예를 들어 BeeGFS 7.3을 구축하려는 경우 이는 입니다<block ref="7bfdf60ffcc8e818739972660aeebf71" prefix=" " category="inline-code"></block>:</block>
  <block id="800371603b58ee549a4a9674cd231cfd" category="inline-link-macro">BeeGFS HA 클러스터를 구축합니다</block>
  <block id="8bb6abf93d767c3eea0b12c8c4b6bbb9" category="paragraph">이 플레이북 파일의 내용에 대한 자세한 내용은 을 참조하십시오 <block ref="fb53cae6b899ceb0b1bf986adcdc0e3a" category="inline-link-macro-rx"></block> 섹션을 참조하십시오.</block>
  <block id="66422423510da7fd29c77f6559cd7ef6" category="section-title">4단계: BeeGFS 업그레이드를 실행합니다</block>
  <block id="5c349c42761230bd8e50fff98f6e7508" category="paragraph">BeeGFS 업데이트 적용하기:</block>
  <block id="a2dd7653f3025e7feb8e282bcc0bde84" category="paragraph">BeeGFS HA 역할에서 다루는 비하인드 스토리:</block>
  <block id="2d304ec0e0fbeec292dc41145e2eecb0" category="list-text">각 BeeGFS 서비스가 기본 노드에 위치하도록 클러스터가 최적의 상태인지 확인합니다.</block>
  <block id="5f143f3872f8df75b9266e40b2272406" category="list-text">클러스터를 유지보수 모드로 전환합니다.</block>
  <block id="400df38ef11abbe30ea67fa8e7200a0d" category="list-text">HA 클러스터 구성 요소를 업데이트합니다(필요한 경우).</block>
  <block id="33421319eb71c7eeb0ce5b0e4a6e4b8f" category="list-text">다음과 같이 각 파일 노드를 한 번에 하나씩 업그레이드합니다.</block>
  <block id="e8e28076de7654eb24e044afdf734b1a" category="list-text">대기 노드에 배치하고 서비스를 보조 노드로 페일오버합니다.</block>
  <block id="428a1ecc41f6178248f2f8dadec2f62b" category="list-text">BeeGFS 패키지를 업그레이드합니다.</block>
  <block id="8a1d7e8d1dce93a3d4fb9150570283c2" category="list-text">서비스 대체.</block>
  <block id="f4a4c394b32e613eb518abe373f40c37" category="list-text">클러스터를 유지보수 모드 외부로 이동합니다.</block>
  <block id="2e5a7ec61feb5cc6bfdf6e50d5cc9a86" category="section-title">BeeGFS 버전 7.2.6 또는 7.3.0에서 업그레이드</block>
  <block id="3398f8eccca63b60d155b3c42101428c" category="section-title">연결 기반 인증에 대한 변경 사항</block>
  <block id="7202d449c02688973a53bb72a0090f19" category="inline-link-macro">BeeGFS 연결 기반 인증</block>
  <block id="334d537e5273e4291972dbb772133d23" category="paragraph">7.3.1 이후에 출시된 BeeGFS 버전에서는 을 지정하지 않고 서비스를 시작할 수 없습니다<block ref="6097b6e95af2579f2147a330c21f7b59" prefix=" " category="inline-code"></block> 설정을 선택합니다<block ref="194193db6aa10dc83a871ef82dae32ce" prefix=" " category="inline-code"></block> 서비스 구성 파일 연결 기반 인증 보안을 사용하는 것이 좋습니다. 을 참조하십시오 <block ref="f745eac1796bcd7c76bb4ab7bb03be5b" category="inline-link-macro-rx"></block> 를 참조하십시오.</block>
  <block id="37075250adff19201f1f54be05b5a07a" category="paragraph">기본적으로 는 를 사용합니다<block ref="59544be57ace17b034c14f8d12510eee" prefix=" " category="inline-code"></block> 역할은 이 파일을 생성하고 배포하여 의 Ansible 제어 노드에 추가합니다<block ref="d60ea3ba7610ba191573b69dca307efb" prefix=" " category="inline-code"></block>. 를 클릭합니다<block ref="84f7933b4ff9fefcfc60fd5fff4b3b54" prefix=" " category="inline-code"></block> 또한 역할은 이 파일이 있는지 확인하고 가능한 경우 클라이언트에 제공합니다.</block>
  <block id="1ea32c7c84666a27c0f0add65b2c620e" category="admonition">를 누릅니다<block ref="84f7933b4ff9fefcfc60fd5fff4b3b54" prefix=" " category="inline-code"></block> 역할을 사용하여 클라이언트를 구성하지 않았습니다. 이 파일은 각 클라이언트와 에 수동으로 배포해야 합니다<block ref="6097b6e95af2579f2147a330c21f7b59" prefix=" " category="inline-code"></block> 의 구성<block ref="1b33ed41c854e3144951352c24ab4653" prefix=" " category="inline-code"></block> 파일을 사용하도록 설정합니다. 연결 기반 인증이 활성화되지 않은 이전 버전의 BeeGFS에서 업그레이드할 때 설정을 통해 업그레이드 과정에서 연결 기반 인증이 비활성화되지 않는 한 클라이언트는 액세스 권한을 잃게 됩니다<block ref="2ff6bdfeb6b3a41d28029b9ff7bdb93c" prefix=" " category="inline-code"></block> 인치<block ref="4003590e6e5408f8e5272e50f909dfac" prefix=" " category="inline-code"></block> (권장하지 않음).</block>
  <block id="0541656d70a4c4cf414ae5049179dd3e" category="paragraph">자세한 내용과 대체 구성 옵션은 에서 연결 인증을 구성하는 단계를 참조하십시오 <block ref="bd1503180303c25487957027c3618d2a" category="inline-link-macro-rx"></block> 섹션을 참조하십시오.</block>
  <block id="cc211dfb7bfb2c913740671716097933" category="summary">BeeGFS on NetApp 솔루션은 BeeGFS 병렬 파일 시스템을 NetApp E-Series 스토리지 시스템과 결합하여 까다로운 워크로드에 대응할 수 있는 안정적이고 확장 가능하며 비용 효율적인 인프라를 제공합니다.</block>
  <block id="49274a22f777d8ee156d9a597e66731d" category="doc">개요 및 요구 사항</block>
  <block id="4fde5e2673b7e14764688237d98539a4" category="paragraph">Ansible을 사용하여 BeeGFS 고가용성 클러스터를 구축할 때 모든 NetApp E/EF-Series 스토리지 시스템을 BeeGFS 블록 노드 및 x86 서버로 BeeGFS 파일 노드로 사용할 수 있습니다.</block>
  <block id="a526fbfd670633e8a75f4085dc1aa978" category="admonition">이 섹션 전체에서 사용되는 용어에 대한 정의는 에서 확인할 수 있습니다 <block ref="9a256c21d0775c8b23b592e82da8914c" category="inline-link-macro-rx"></block> 페이지.</block>
  <block id="0b79795d3efc95b9976c7c5b933afce2" category="section-title">소개</block>
  <block id="58d7101385af8eaef1dc397806989cbb" category="inline-link-macro">NetApp 검증 아키텍처</block>
  <block id="976f0d8cf9d3940cf8e3b455ac2a745a" category="paragraph">있습니다 <block ref="debdb16c2fe7cca1eb7f522c443894ec" category="inline-link-macro-rx"></block> 사전 정의된 참조 구성 및 사이징 지침을 제공하는 일부 고객 및 파트너는 특정 요구 사항 또는 하드웨어 기본 설정에 더 적합한 맞춤형 아키텍처를 설계할 수 있습니다. NetApp에서 BeeGFS를 선택할 때의 주요 이점 중 하나는 Ansible을 사용하여 BeeGFS 공유 디스크 HA 클러스터를 구축하여 NetApp에서 작성한 HA 구성요소를 통해 클러스터 관리를 단순화하고 안정성을 높일 수 있다는 것입니다. NetApp에 맞춤형 BeeGFS 아키텍처를 구축할 때는 Ansible을 사용하여 유연한 하드웨어 제품군에서 어플라이언스 같은 접근 방식을 유지 관리합니다.</block>
  <block id="ddda17ba962e180630c243fddd448b5f" category="paragraph">이 섹션에서는 NetApp 하드웨어에서 BeeGFS 파일 시스템을 구축하고 Ansible을 사용하여 BeeGFS 파일 시스템을 구성하는 데 필요한 일반적인 단계를 간략하게 설명합니다. BeeGFS 파일 시스템 설계 및 최적화된 예시와 관련된 Best Practice에 대한 자세한 내용은 를 참조하십시오 <block ref="debdb16c2fe7cca1eb7f522c443894ec" category="inline-link-macro-rx"></block> 섹션을 참조하십시오.</block>
  <block id="6d2bf94f38d1fdf840fe9b231866899c" category="section-title">구축 개요</block>
  <block id="00298d02a62e3ad710061bdb858bc72b" category="paragraph">일반적으로 BeeGFS 파일 시스템을 구축하려면 다음 단계를 수행해야 합니다.</block>
  <block id="a3f59792a4244ec442fe3d6689ce5a5d" category="list-text">초기 설정:</block>
  <block id="bed2a4653b2c422bf2632c104da5c873" category="list-text">하드웨어 설치/케이블 연결</block>
  <block id="a2d48c839c25c269a71b232a366cdfbc" category="list-text">파일 및 블록 노드 설정</block>
  <block id="e8ec50ce42367b5c2125ba84ee0b2b07" category="list-text">Ansible 제어 노드를 설정합니다.</block>
  <block id="1166a5354ac02035abc5f968f7ed4570" category="list-text">BeeGFS 파일 시스템을 Ansible 인벤토리로 정의합니다.</block>
  <block id="45a41d17b919852e176b0bef9ba18dde" category="list-text">파일 및 블록 노드 기준으로 Ansible을 실행하여 BeeGFS 구축</block>
  <block id="b29828241f384dfaa560eb24d45c7035" category="list-text">선택적으로 클라이언트를 설정하고 BeeGFS를 마운트합니다.</block>
  <block id="3b5256e7140e65040f9635a6b8b884ee" category="paragraph">다음 섹션에서는 이러한 단계에 대해 자세히 설명합니다.</block>
  <block id="216c2fbf006b3f1ca9acdd60d04a9b4b" category="paragraph">Ansible은 다음을 비롯한 모든 소프트웨어 프로비저닝 및 구성 작업을 처리합니다.</block>
  <block id="fd699aca3f31bc5416fca3a153cc4779" category="list-text">블록 노드에서 볼륨 생성/매핑</block>
  <block id="7565e19b34a4d2460620720a599da376" category="list-text">파일 노드에서 볼륨 포맷/튜닝</block>
  <block id="8744d71fb56c3e75f875de0a416ea912" category="list-text">파일 노드에 소프트웨어 설치/구성</block>
  <block id="dcc4901f1f1938989ed2264f42fd1104" category="list-text">HA 클러스터 설정 및 BeeGFS 리소스 및 파일 시스템 서비스 구성</block>
  <block id="077a8397a5f4ba0711faf87b91f8906c" category="paragraph">Ansible에서 BeeGFS에 대한 지원은 에서 제공됩니다 <block ref="e5bec9f043c86b9afcbef28a688a4cdd" category="inline-link-macro-rx"></block> BeeGFS HA 클러스터의 포괄적인 구축 및 관리를 자동화하는 역할 및 모듈 모음입니다.</block>
  <block id="5207de659c47ed66a8f04540f2cf7d28" category="paragraph">BeeGFS 자체는 &lt;major&gt;.&lt;minor&gt;.&lt;patch&gt; 버전 관리 체계에 따라 버전이 지정되며, 이 컬렉션은 지원되는 각 &lt;major&gt;.&lt;minor&gt; 버전의 BeeGFS에 대한 역할을 유지합니다. 예를 들어 BeeGFS 7.2 또는 BeeGFS 7.3과 같은 BeeGFS 버전이 있습니다. 컬렉션에 대한 업데이트가 릴리스되면 각 역할의 패치 버전이 해당 릴리즈 지점에 대해 사용 가능한 최신 BeeGFS 버전을 가리키도록 업데이트됩니다(예: 7.2.8). 각 컬렉션 버전은 특정 Linux 배포 및 버전, 현재 파일 노드용 Red Hat, 클라이언트용 RedHat 및 Ubuntu에서도 테스트 및 지원됩니다. 다른 배포판 실행이 지원되지 않으며 다른 버전(특히 다른 주요 버전)을 실행하는 것은 권장되지 않습니다.</block>
  <block id="ff58765d6c48f433685b2f9354c057ed" category="section-title">Ansible 컨트롤 노드</block>
  <block id="267dc210028d3a563bde0eb07ca563a0" category="paragraph">이 노드에는 BeeGFS 관리에 사용되는 인벤토리 및 Playbook이 포함됩니다. 다음과 같은 요구 사항이 있습니다.</block>
  <block id="fa364b2fe46e5e06529d637ca126add1" category="list-text">Ansible 6.x(Ansible-코어 2.13)</block>
  <block id="3ac4555ed79bcb16976991998d5a957c" category="list-text">Python 3.6 (이상)</block>
  <block id="44ebd117631269d8cc52eda82b890ecc" category="list-text">Python(PIP) 패키지: ipaddr 및 netaddr</block>
  <block id="8486bce50d4152772da3c4531a015ab8" category="paragraph">또한 제어 노드에서 모든 BeeGFS 파일 노드 및 클라이언트로 암호 없는 SSH를 설정하는 것이 좋습니다.</block>
  <block id="5bca534f5a45c18ffc0306e63b306c62" category="section-title">BeeGFS 파일 노드</block>
  <block id="db9f63f8d00e9b524f09cf9c3bdce9c6" category="paragraph">파일 노드는 RedHat 8.4를 실행하고 필수 패키지(페이스 메이커, Corosync, Fence-agent-all, resource-agent)가 포함된 HA 리포지토리에 액세스할 수 있어야 합니다. 예를 들어 다음 명령을 실행하여 RedHat 8에서 적절한 리포지토리를 활성화할 수 있습니다.</block>
  <block id="676b08aacbe937f16d558f23d90b29da" category="section-title">BeeGFS 클라이언트 노드</block>
  <block id="dc203cff346fc33ab19584264833d533" category="paragraph">BeeGFS 클라이언트 Ansible 역할을 사용하여 BeeGFS 클라이언트 패키지를 설치하고 BeeGFS 마운트를 관리할 수 있습니다. 이 역할은 RedHat 8.4 및 Ubuntu 22.04에서 테스트되었습니다.</block>
  <block id="2e0da5c1c3cbd1cda1312f57209c96e4" category="inline-link-macro">BeeGFS는 Linux 배포 및 커널을 지원했습니다</block>
  <block id="b44b294130612c32e5f179fb81f347ec" category="paragraph">Anabilities를 사용하여 BeeGFS 클라이언트를 설정하고 BeeGFS를 마운트하지 않는 경우 <block ref="ed8f85054917a214583881f0e58e2825" category="inline-link-macro-rx"></block> 사용할 수 있습니다.</block>
  <block id="03a96e493f11c9bdee76520257a1462d" category="summary">호스트 변수(host_vars)를 사용하여 개별 파일 노드의 구성을 지정합니다.</block>
  <block id="021fa309ed559d86433974a82c934acb" category="doc">개별 파일 노드를 구성합니다</block>
  <block id="882d9f125986842da2dd0a55dab49692" category="paragraph">이 섹션에서는 를 채우는 방법을 설명합니다<block ref="6ec1b7d2e07359817e585e3cab8e078f" prefix=" " category="inline-code"></block> 클러스터에 있는 각 파일 노드에 대한 파일입니다. 이러한 파일에는 특정 파일 노드에 고유한 구성만 포함되어야 합니다. 여기에는 일반적으로 다음이 포함됩니다.</block>
  <block id="3a67b6422642abadfa758fc6684f8438" category="list-text">Ansible에서 노드에 연결하는 데 사용해야 하는 IP 또는 호스트 이름 정의</block>
  <block id="fc0fd95b8cee27585e1c24e4d4a97663" category="list-text">다른 파일 노드와 통신하기 위해 HA 클러스터 서비스(박동조율기 및 Corosync)에 사용되는 추가 인터페이스 및 클러스터 IP를 구성합니다. 기본적으로 이러한 서비스는 관리 인터페이스와 동일한 네트워크를 사용하지만 이중화를 위해 추가 인터페이스를 사용할 수 있어야 합니다. 일반적으로 추가 클러스터 또는 관리 네트워크가 필요하지 않도록 스토리지 네트워크에 추가 IP를 정의하는 것이 좋습니다.</block>
  <block id="d3bb2cb10c3de19eafb23408d3a400a6" category="list-text">클러스터 통신에 사용되는 모든 네트워크의 성능은 파일 시스템 성능에 중요하지 않습니다. 기본 클러스터 구성에서는 일반적으로 1Gbps 이상의 네트워크가 노드 상태 동기화 및 클러스터 리소스 상태 변경 조정과 같은 클러스터 작업에 충분한 성능을 제공합니다. 느리거나 사용량이 많은 네트워크는 리소스 상태 변경이 평소보다 오래 걸릴 수 있으며, 극단적인 경우 적절한 시간 내에 하트비트를 전송할 수 없는 경우 클러스터에서 노드가 제거될 수 있습니다.</block>
  <block id="a557d06b3a2f8ed98f967366125754a4" category="list-text">원하는 프로토콜을 통해 블록 노드에 연결하는 데 사용되는 인터페이스 구성(예: iSCSI/iSER, NVMe/IB, NVMe/RoCE, FCP 등)</block>
  <block id="3990d1c8eb99844fa4339dea97a4f692" category="inline-link-macro">파일 시스템 계획</block>
  <block id="346674dbd97098838f5327dc1e5c9c18" category="paragraph">에 정의된 IP 주소 지정 체계를 참조합니다 <block ref="9b15c2b73cdd7b8794597878cdbf2b1c" category="inline-link-macro-rx"></block> 섹션에서 클러스터의 각 파일 노드에 대해 파일을 생성합니다<block ref="29c5616b1b8c32726b3152860a451439" prefix=" " category="inline-code"></block> 다음과 같이 채웁니다.</block>
  <block id="625cd1f9698fddb4256f18db4fbe2c9f" category="list-text">맨 위에서 Ansible이 노드에 SSH를 통해 사용하고 관리해야 하는 IP 또는 호스트 이름을 지정합니다.</block>
  <block id="2c411df90af25473ca34f96c5d61fdbd" category="list-text">클러스터 트래픽에 사용할 수 있는 추가 IP 구성:</block>
  <block id="13252baac98263adb995638740670156" category="inline-link-macro">InfiniBand(IPoIB 사용)</block>
  <block id="4ec9f0d4c55bed99ab83189074c79fda" category="list-text">네트워크 유형이 인 경우 <block ref="ce64f086b1422863947177e8ac3c3f3f" category="inline-link-macro-rx"></block>:</block>
  <block id="703a1e1ae0933c0197e1615ce5751d82" category="inline-link-macro">RoCE(RDMA over Converged Ethernet)</block>
  <block id="e8f5d6c59a43e4d1004ee930d690ba27" category="list-text">네트워크 유형이 인 경우 <block ref="513b838786f4a360fbbf4a58f2a48329" category="inline-link-macro-rx"></block>:</block>
  <block id="1e6c082cb30ec9603b75d0e43e10ed58" category="inline-link-macro">이더넷(TCP 전용, RDMA 없음)</block>
  <block id="022fdafc43fcb01f91b57ea09f74ecea" category="list-text">네트워크 유형이 인 경우 <block ref="0d1150d6d50cb438873f5f691ec395a3" category="inline-link-macro-rx"></block>:</block>
  <block id="caec0146669daf8b955fbc692dce520b" category="list-text">클러스터 트래픽에 사용해야 하는 IP를 표시하고 기본 IP가 더 높게 나열됨:</block>
  <block id="8ab316490a957aa5fb5fe572defa9604" category="admonition">2단계에서 구성된 IPS는 에 포함되지 않는 한 클러스터 IP로 사용되지 않습니다<block ref="736da50e459ba4f3c37629db79164765" prefix=" " category="inline-code"></block> 목록. 따라서 필요한 경우 다른 목적으로 사용할 수 있는 Ansible을 사용하여 추가 IP/인터페이스를 구성할 수 있습니다.</block>
  <block id="fe608507c9e692b58aed73b8f11125e4" category="list-text">파일 노드가 IP 기반 프로토콜을 통해 블록 노드와 통신해야 하는 경우 IP를 적절한 인터페이스와 해당 프로토콜에 필요한 모든 패키지를 설치/구성해야 합니다.</block>
  <block id="e4e1c13bb0b14f6cb7608cbecea948ef" category="inline-link-macro">iSCSI</block>
  <block id="e38ebb7478bbd7c30fcefbdd68c36a12" category="list-text">를 사용하는 경우 <block ref="c46eb98747333d3b3d4803c99165252d" category="inline-link-macro-rx"></block>:</block>
  <block id="04363472361fdfa664dfcfdfa289d7f8" category="inline-link-macro">iSER</block>
  <block id="25d076d8b955ae9a10c335a6a41c5dac" category="list-text">를 사용하는 경우 <block ref="fa0a3baed35abd76cdb7d05d37537402" category="inline-link-macro-rx"></block>:</block>
  <block id="10c103240eb7689c62b54e419902d174" category="inline-link-macro">NVMe/IB</block>
  <block id="17e6fab71004356520b6a05746233689" category="list-text">를 사용하는 경우 <block ref="cb33aa2303f4543f0ddc6cc084dc11e2" category="inline-link-macro-rx"></block>:</block>
  <block id="bb0b9e255a3bf215a4f994ef912a5fd7" category="inline-link-macro">NVMe/RoCE</block>
  <block id="7b049824318ebce7d5761f9928468034" category="list-text">를 사용하는 경우 <block ref="dcd6a35349a26dd7f2ff0413151122c4" category="inline-link-macro-rx"></block>:</block>
  <block id="7de7f0266a638e2b92287e19c3daa0c0" category="list-text">기타 프로토콜:</block>
  <block id="26bcb9f1cb6f391f4b2c18e676bb458d" category="inline-link-macro">NVMe/FC</block>
  <block id="22c518d1512a40bae5f92e178ec69be7" category="list-text">를 사용하는 경우 <block ref="20d003b59b6b0f29fbb82550734ddf9c" category="inline-link-macro-rx"></block>, 개별 인터페이스를 구성할 필요가 없습니다. BeeGFS 클러스터 배포는 자동으로 프로토콜을 감지하고 필요에 따라 요구 사항을 설치/구성합니다. 패브릭을 사용하여 파일 및 블록 노드를 연결하는 경우, 스위치가 NetApp과 스위치 공급업체의 모범 사례에 따라 적절히 조닝되었는지 확인하십시오.</block>
  <block id="cfaa375bf6c7f9fcc1bc04d4f30c9154" category="inline-link-macro">넷엡</block>
  <block id="59153461462a6c82d6207480cde38687" category="list-text">FCP 또는 SAS를 사용하는 경우 추가 소프트웨어를 설치하거나 구성할 필요가 없습니다. FCP를 사용하는 경우 스위치가 다음에 적절하게 조닝(zoning)되어 있는지 확인합니다 <block ref="6839ca80f3cddcad48af8ac7c3fe1eba" category="inline-link-macro-rx"></block> 스위치 공급업체의 모범 사례를 소개합니다.</block>
  <block id="31887cc493f03e51b901bf0def837d66" category="list-text">현재 IB SRP 사용은 권장되지 않습니다. E-Series 블록 노드에서 지원하는 것에 따라 NVMe/IB 또는 iSER을 사용합니다.</block>
  <block id="6c92285fa6d3e827b198d120ea3ac674" category="inline-link-macro">여기</block>
  <block id="02613a7c8b7a72805b5196cbf7ed0def" category="paragraph">을 클릭합니다 <block ref="6ff86e054594e10fe2118d48eb3fbd14" category="inline-link-macro-rx"></block> 단일 파일 노드를 나타내는 전체 인벤토리 파일의 예</block>
  <block id="310ccb00662c7e9dcc32789c0d9b1b7a" category="section-title">고급: 이더넷과 InfiniBand 모드 간에 NVIDIA ConnectX VPI 어댑터를 전환합니다</block>
  <block id="dcc92cf452bd744849cd00433f6a6065" category="inline-link-macro">Mellanox firmare 도구(MFT)</block>
  <block id="ed6cbc43ac185fea723a14d38091893c" category="paragraph">NVIDIA ConnectX-Virtual Protocol Interconnect &amp; reg;(VPI) 어댑터는 전송 계층으로 InfiniBand와 이더넷을 모두 지원합니다. 모드 간 전환은 자동으로 조정되지 않으며 을 사용하여 구성해야 합니다<block ref="366fe119442ebda85ac564541700d0b5" prefix=" " category="inline-code"></block> 에 포함된 도구<block ref="a55706c70f646ff289a7f6fb8ddc1353" prefix=" " category="inline-code"></block>의 일부인 오픈 소스 패키지입니다 <block ref="c5b5fd4585af953450ea07aa852104bf" category="inline-link-macro-rx"></block>. 어댑터 모드 변경은 한 번만 수행하면 됩니다. 이 작업은 수동으로 수행하거나 를 사용하여 구성된 인터페이스의 일부로 Ansible 인벤토리에 포함할 수 있습니다<block ref="d6ca1855b29b160948694322764a86cb" prefix=" " category="inline-code"></block> 재고 섹션에서 자동으로 확인/적용되도록 합니다.</block>
  <block id="2b4c9bc157bda4a68fe7b673b411f9cd" category="paragraph">예를 들어, InfiniBand 모드에서 인터페이스 전류를 이더넷으로 변경하여 RoCE에 사용할 수 있습니다.</block>
  <block id="f352db79870cb8a06a0551761aba6955" category="list-text">구성할 각 인터페이스에 대해 지정합니다<block ref="366fe119442ebda85ac564541700d0b5" prefix=" " category="inline-code"></block> 를 지정하는 매핑(또는 사전)으로 지정합니다<block ref="ced82128b540acaf7a5a55ad007dc9fc" prefix=" " category="inline-code"></block> 위치<block ref="ecb5fc74e9cd1f249d43a2bdbf2f239d" prefix=" " category="inline-code"></block> 인터페이스에 대한 HCA의 포트 번호로 결정됩니다. 를 클릭합니다<block ref="ecb5fc74e9cd1f249d43a2bdbf2f239d" prefix=" " category="inline-code"></block> 값은 를 실행하여 확인할 수 있습니다<block ref="2ea620f2a9b9bed90c46047fef7e151b" prefix=" " category="inline-code"></block> PCI 슬롯 이름의 성에 1을 추가하고 10진수로 변환합니다.</block>
  <block id="070b28e93cab063481c989d1404f9835" category="list-text">예를 들어, 를 입력합니다<block ref="92c00058a177a7a840386578304e1345" prefix=" " category="inline-code"></block> (2+1 -&gt; HCA 포트 3) -&gt;<block ref="f5e96e67a1ff914902859c7140e258c6" prefix=" " category="inline-code"></block>:</block>
  <block id="5656da44562ac70934e97182890aa356" category="inline-link-macro">NetApp E-Series 호스트 컬렉션의 문서입니다</block>
  <block id="62a3f60b673661ad66352505cb4f5f47" category="paragraph">자세한 내용은 를 참조하십시오 <block ref="9ec6c7f8da9119d3e119ae207cfbe732" category="inline-link-macro-rx"></block> 사용 중인 인터페이스 유형/프로토콜의 경우.</block>
  <block id="7b56de51b6636ae6d5c0129d3aa799db" category="summary">그룹 변수(group_vars)를 사용하여 일반 파일 노드 구성을 지정합니다.</block>
  <block id="db3a70a0b14fbd38f2ad1025900202fe" category="paragraph">모든 파일 노드에 대해 사과해야 하는 구성은 에 정의되어 있습니다<block ref="4003590e6e5408f8e5272e50f909dfac" prefix=" " category="inline-code"></block>. 일반적으로 다음과 같은 기능이 있습니다.</block>
  <block id="8a78a1a399a517e776a6453f500e5c3c" category="list-text">각 파일 노드에 연결 및 로그인하는 방법에 대한 세부 정보</block>
  <block id="d749e2ca3efe2efbf2d8495c53fa6cb8" category="list-text">공통 네트워킹 구성</block>
  <block id="01166eafe622404b58002e5aa76ca528" category="list-text">자동 재부팅이 허용되는지 여부</block>
  <block id="109b40c80787d84c2b222ada208f2967" category="list-text">방화벽 및 SELinux 상태를 구성하는 방법</block>
  <block id="cd29db396a81799f9eb0187ecae937b1" category="list-text">경고 및 펜싱을 포함한 클러스터 구성</block>
  <block id="8b4f60df6198db9d4eb1c6bbb19def6d" category="list-text">성능 튜닝:</block>
  <block id="8ae73df7c749e2eb45a156f0c39fcc04" category="list-text">공통 BeeGFS 서비스 구성</block>
  <block id="787446c6f7e5e0f4a50705b5035eba79" category="admonition">이 파일에 설정된 옵션은 혼합 하드웨어 모델을 사용 중이거나 각 노드에 대해 다른 암호를 사용하는 경우와 같이 개별 파일 노드에서도 정의할 수 있습니다. 개별 파일 노드의 구성은 이 파일의 구성보다 우선합니다.</block>
  <block id="0971602076ba9dff100f7cfc2d9e6059" category="paragraph">파일을 만듭니다<block ref="4003590e6e5408f8e5272e50f909dfac" prefix=" " category="inline-code"></block> 다음과 같이 채웁니다.</block>
  <block id="84531cf8a820148a6599e174baf94979" category="list-text">Ansible Control 노드가 원격 호스트에서 인증해야 하는 방법을 나타냅니다.</block>
  <block id="2d33afd54604fb6475c44a1bc47fe2b1" category="admonition">특히 프로덕션 환경에서는 암호를 일반 텍스트로 저장하지 마십시오. 대신 Ansible Vault를 사용하십시오(참조 <block ref="37147a1e5d41497ae56472e8a2868a2a" category="inline-link-macro-rx"></block>) 또는 을 누릅니다<block ref="13d87b4892426ec19bdc58a4643d3104" prefix=" " category="inline-code"></block> 옵션을 클릭합니다. 를 누릅니다<block ref="f2bf771afbc16045e1951ded58c56f98" prefix=" " category="inline-code"></block> 이(가) 이미 루트이므로 필요에 따라 를 생략할 수 있습니다<block ref="424240cd4e5c359372b7f199431603d5" prefix=" " category="inline-code"></block>.</block>
  <block id="0a94da3169c04bc12f2c561654269433" category="list-text">이더넷 또는 InfiniBand 인터페이스(예: 클러스터 IP)에서 정적 IP를 구성하고 여러 인터페이스가 동일한 IP 서브넷에 있는 경우(예: ib0이 192.168.1.10/24를 사용하고 ib1이 192.168.1.11/24를 사용 중인 경우) 멀티홈 지원이 제대로 작동하려면 추가 IP 라우팅 테이블 및 규칙을 설정해야 합니다. 다음과 같이 제공된 네트워크 인터페이스 구성 후크를 활성화하기만 하면 됩니다.</block>
  <block id="502d35f94d5c17779c9050bbed75f65f" category="list-text">클러스터를 구축할 때 스토리지 프로토콜에 따라 노드를 재부팅하여 원격 블록 장치(E-Series 볼륨)를 쉽게 검색하거나 다른 구성 요소를 적용해야 할 수 있습니다. 기본적으로 노드를 재부팅하기 전에 프롬프트가 표시되지만 다음을 지정하여 노드를 자동으로 다시 시작할 수 있습니다.</block>
  <block id="ff31dc05d095d346c18f3e8f2d758fe0" category="list-text">재부팅 후 기본적으로 블록 장치 및 기타 서비스가 준비되도록 하려면 Ansible이 시스템이 준비될 때까지 기다립니다<block ref="dbd7cb25a43d1cd2bbc3bac871dad694" prefix=" " category="inline-code"></block> 에 도달한 후 배포를 계속합니다. NVMe/IB가 사용 중인 일부 시나리오에서는 이 시간이 부족하여 원격 장치를 초기화, 검색 및 연결할 수 없습니다. 이로 인해 자동화된 배포가 조기에 계속 진행되어 실패할 수 있습니다. NVMe/IB를 사용할 때 이를 방지하려면 다음을 정의합니다.</block>
  <block id="c41782825542f82199bd141519f37211" category="list-text">BeeGFS 및 HA 클러스터 서비스가 통신하려면 다양한 방화벽 포트가 필요합니다. 첫 번째 명령을 수동으로 구성하지 않는 한(권장하지 않음) 필요한 방화벽 영역을 만들고 포트를 자동으로 열리도록 다음을 지정합니다.</block>
  <block id="2514951e199c5ba1bae751dec2faccfa" category="list-text">이때 SELinux는 지원되지 않으며, 특히 RDMA를 사용하는 경우 충돌을 피하기 위해 상태를 비활성화로 설정하는 것이 좋습니다. SELinux가 비활성화되었는지 확인하려면 다음을 설정합니다.</block>
  <block id="97a322f05bd6e92c24c84cd8a09de904" category="list-text">파일 노드가 통신할 수 있도록 인증을 구성하고 조직의 정책에 따라 필요에 따라 기본값을 조정합니다.</block>
  <block id="7d49ca11d08f7d0ad6093098705db056" category="list-text">을 기반으로 합니다 <block ref="357e0adc4a9895d7fb0741a56cb66937" category="inline-link-macro-rx"></block> 섹션에서 이 파일 시스템에 대한 BeeGFS 관리 IP를 지정합니다.</block>
  <block id="d6521cd21608c38eda94ff4b2607ebac" category="list-text">원하는 경우 e-메일 알림 활성화:</block>
  <block id="369512731d385e76ab6ae5702e43d88e" category="list-text">펜싱을 사용하는 것이 좋습니다. 그렇지 않으면 기본 노드에 장애가 발생할 때 보조 노드에서 서비스가 시작되지 않도록 차단할 수 있습니다.</block>
  <block id="679f9b26ee84fb8a265eb6a80d1141b0" category="list-text">다음을 지정하여 펜싱을 전역적으로 활성화합니다.</block>
  <block id="2b86513417433b960c2a9628820cce70" category="inline-link-macro">클러스터 속성</block>
  <block id="a4a918a45181164207929d52aec36aec" category="inline-link-macro">기본값</block>
  <block id="bcc67e5cda8ee1e21250342139467d00" category="list-text">지원되는 모든 사항을 기록해 둡니다 <block ref="1f696c148c590f4530f1598592f9a4b4" category="inline-link-macro-rx"></block> 필요한 경우 여기에서 지정할 수도 있습니다. BeeGFS HA 역할이 다양한 테스트를 거친 상태로 배송되므로 이러한 기능을 조정할 필요가 없습니다 <block ref="d630d35a07d393b0d4bb83a7523d1703" category="inline-link-macro-rx"></block>.</block>
  <block id="8cb3e998c7b1e4cbe36289f2177363b5" category="list-text">그런 다음 펜싱 에이전트를 선택하고 구성합니다.</block>
  <block id="bc6b3ed04c45895c341d99b6765c1caa" category="list-text">옵션 1: APC PDU(Power Distribution Unit)를 사용하여 펜싱 활성화하기:</block>
  <block id="94ebb967d1a890978b9758e3f2aac3bb" category="list-text">옵션 2: Lenovo XCC(및 기타 BMC)에서 제공하는 Redfish API를 사용하여 펜싱을 활성화하려면</block>
  <block id="7f2e85da597afbbb84c30c58c72fc4a2" category="inline-link-macro">RedHat 문서</block>
  <block id="18c5e5e72191184c4e18d312bc7fafef" category="list-text">기타 펜싱 에이전트 구성에 대한 자세한 내용은 를 참조하십시오 <block ref="611005f72b088bb8cef495741d6f0861" category="inline-link-macro-rx"></block>.</block>
  <block id="3a6d72343adc910bbcf2be9191e40f88" category="list-text">BeeGFS HA 역할은 다양한 튜닝 매개 변수를 적용하여 성능을 더욱 최적화할 수 있습니다. 여기에는 커널 메모리 활용도 최적화 및 블록 디바이스 입출력 등이 포함됩니다. 이 역할은 합당한 일련의 역할을 수행합니다 <block ref="d9492c5c01c77d55ea71bf758fca3c1e" category="inline-link-macro-rx"></block> NetApp E-Series 블록 노드에서 테스트를 기반으로 하지만 기본적으로 다음 사항을 지정하지 않으면 적용되지 않습니다.</block>
  <block id="1242eea64a7ebfd7464359e597a4ec62" category="inline-link-macro">성능 튜닝 매개 변수</block>
  <block id="dbfad90b96c293c6b7b2b93be168cfd5" category="list-text">필요한 경우 여기에서 기본 성능 튜닝에 대한 변경 사항도 지정합니다. 전체 내용을 참조하십시오 <block ref="66aaf5e6618940d3ade7aede35016480" category="inline-link-macro-rx"></block> 설명서를 참조하십시오.</block>
  <block id="e535abe8b416a666cd34177ff6bbe395" category="list-text">BeeGFS 서비스에 사용되는 부동 IP 주소(논리 인터페이스라고도 함)가 파일 노드 간에 페일오버할 수 있도록 모든 네트워크 인터페이스의 이름이 일관되게 지정되어야 합니다. 기본적으로 네트워크 인터페이스 이름은 동일한 PCIe 슬롯에 네트워크 어댑터가 설치된 동일한 서버 모델에서도 일관된 이름을 생성한다는 보장이 없는 커널에 의해 생성됩니다. 이 기능은 장비를 구축하고 생성된 인터페이스 이름을 알 수 있도록 하기 전에 인벤토리를 생성할 때도 유용합니다. 서버 또는 의 블록 다이어그램을 기반으로 일관된 장치 이름을 보장합니다<block ref="6efa276570b668a53eaf7bf29c69d544" prefix=" " category="inline-code"></block> 출력에서 원하는 PCIe 주소-논리 인터페이스 매핑을 다음과 같이 지정합니다.</block>
  <block id="b577b9bc7da15f148c6521018b1c26f7" category="list-text">InfiniBand(IPoIB) 네트워크 인터페이스의 경우:</block>
  <block id="10b951f140b750e6d3b9a61a2aa51fc1" category="list-text">이더넷 네트워크 인터페이스의 경우:</block>
  <block id="e71729643558be7be36227d3edb537a5" category="admonition">인터페이스의 이름을 바꿀 때(이름을 바꿀 수 없음) 충돌을 방지하려면 eth0, ens9f0, ib0 또는 ibs4f0과 같은 잠재적인 기본 이름을 사용하지 않아야 합니다. 일반적인 명명 규칙은 이더넷 또는 InfiniBand의 경우 'e' 또는 'i'를 사용하고 그 뒤에 PCIe 슬롯 번호와 해당 포트를 나타내는 문자를 사용하는 것입니다. 예를 들어 슬롯 3에 설치된 InfiniBand 어댑터의 두 번째 포트는 i3b입니다.</block>
  <block id="62e75ccd7f725aa6905f33580950953f" category="admonition">검증된 파일 노드 모델을 사용하는 경우 를 클릭합니다 <block ref="3d76a23cff20eb55b7795ee99a64cc43" category="inline-link-macro-rx"></block> PCIe 주소와 논리적 포트 매핑의 예</block>
  <block id="49d63ad68018ca272cf3bfe9a0843371" category="list-text">선택적으로 클러스터의 모든 BeeGFS 서비스에 적용할 구성을 지정합니다. 기본 설정 값을 찾을 수 있습니다 <block ref="a57cc720fc0e96a52cf3201e2484ee55" category="inline-link-macro-rx"></block>, 및 서비스별 구성은 다른 곳에서 지정됩니다.</block>
  <block id="1644ff30bfdd323dac0e52e1620614b2" category="list-text">BeeGFS 관리 서비스:</block>
  <block id="c9c23b537bdcdcf7e82ad149d3e28ab1" category="list-text">BeeGFS 메타데이터 서비스:</block>
  <block id="b292484ec320b2afcb3a63fdbff30bd3" category="list-text">BeeGFS 스토리지 서비스:</block>
  <block id="69e81fdce48c1bfa30329304eaa6d50d" category="inline-link-macro">연결 인증</block>
  <block id="d636cd57abce18fc564705e1931029aa" category="list-text">BeeGFS 7.2.7 및 7.3.1 <block ref="770c4b58b3b364c4ac52cf5cc555453f" category="inline-link-macro-rx"></block> 구성 또는 명시적으로 비활성화해야 합니다. Ansible 기반 배포를 사용하여 다음과 같은 몇 가지 방법으로 이를 구성할 수 있습니다.</block>
  <block id="2beb66fd9b0c065cfc742ee53ee1055d" category="list-text">기본적으로 배포는 연결 인증을 자동으로 구성하고 을 생성합니다<block ref="cd304377fdc20285a5aa94e55ae85aa7" prefix=" " category="inline-code"></block> 모든 파일 노드에 배포되고 BeeGFS 서비스와 함께 사용됩니다. 이 파일은 또한 의 Ansible 제어 노드에 배치/유지됩니다<block ref="eee2923df30539b680421ca53d7c066b" prefix=" " category="inline-code"></block> 이 파일 시스템을 액세스해야 하는 클라이언트에서 재사용하기 위해 안전하게 유지해야 하는 경우</block>
  <block id="a6eacd255bbcfb7c0ed5589f3f4b3b80" category="list-text">새 키 지정을 생성하려면 다음을 지정합니다<block ref="34efb4240137e7a93d7ad83bde309514" prefix=" " category="inline-code"></block> Ansible 플레이북을 실행할 때, 참고 의 경우 이 작업은 무시됩니다<block ref="8b76cf2fb65e09dad03ca686be5cd464" prefix=" " category="inline-code"></block> 정의됩니다.</block>
  <block id="4d93b986f0992f2770f494a3ced4bd11" category="inline-link-macro">BeeGFS HA 역할입니다</block>
  <block id="ce622ce5379468ed5a0a2f78bbabe2ab" category="list-text">고급 옵션은 에 포함된 기본값 전체 목록을 참조하십시오 <block ref="ef9c73fbbdc1b0f81755fa896cdced03" category="inline-link-macro-rx"></block>.</block>
  <block id="ca03fa9d55c2bc9aa4bb21f10949f48a" category="list-text">에서 다음을 정의하여 사용자 지정 암호를 사용할 수 있습니다<block ref="3cd295e6aaa39e2510aff65b801cc5ab" prefix=" " category="inline-code"></block>:</block>
  <block id="00d80f50123e52756def9093de1ba2aa" category="list-text">연결 인증은 완전히 비활성화할 수 있습니다(권장하지 않음).</block>
  <block id="b8a5eb74062e4ce8ebe0914712be3ae2" category="paragraph">을 클릭합니다 <block ref="632283d8f4d8d92337070d81c0b8ed5f" category="inline-link-macro-rx"></block> 일반 파일 노드 구성을 나타내는 전체 인벤토리 파일의 예</block>
  <block id="74acf7796c51f1f58661f8cf66f5b969" category="section-title">NetApp EF600 블록 노드에서 HDR(200GB) InfiniBand 사용:</block>
  <block id="9e152ebb462ebe95f96d2711a934ec01" category="paragraph">EF600에서 HDR(200GB) InfiniBand를 사용하려면 서브넷 관리자가 가상화를 지원해야 합니다. 스위치를 사용하여 파일 및 블록 노드를 연결하는 경우 전체 패브릭의 서브넷 관리자 관리자에서 이 기능을 활성화해야 합니다.</block>
  <block id="11f007a0a372dd0901653de91029d3d8" category="inline-link-macro">파일 노드 스토리지 인터페이스를 구성하는 중입니다</block>
  <block id="7d8267855776cbf28fdb280b86e18730" category="paragraph">블록 및 파일 노드가 InfiniBand를 사용하여 직접 연결된 경우 의 인스턴스입니다<block ref="d21519b2c7af8ce90e382199384a8c06" prefix=" " category="inline-code"></block> 블록 노드에 직접 연결된 각 인터페이스에 대해 각 파일 노드에 구성되어야 합니다. 이 작업은 를 지정하여 수행합니다<block ref="a983fd54df8f83bdfdc5756fe288aa56" prefix=" " category="inline-code"></block> 시기 <block ref="b7aaae639ec3dcbad23b6be7de000276" category="inline-link-macro-rx"></block>.</block>
  <block id="458626752c0cbe26a6b491b0f013e5e6" category="paragraph">현재 의 받은 편지함 버전입니다<block ref="d21519b2c7af8ce90e382199384a8c06" prefix=" " category="inline-code"></block> 지원되는 Linux 배포판과 함께 제공되지만 가상화를 지원하지 않습니다. 대신 의 버전을 설치하고 구성해야 합니다<block ref="d21519b2c7af8ce90e382199384a8c06" prefix=" " category="inline-code"></block> Mellanox OpenFabrics Enterprise Distribution(OFED)에서 Ansible을 사용한 구축도 여전히 지원되지만, 몇 가지 추가 단계가 필요합니다.</block>
  <block id="b13b4c123d075f5df5e6f618489fde5f" category="inline-link-macro">기술 요구 사항</block>
  <block id="42bc30626d8bda33040bd0a59cebee54" category="list-text">curl 또는 원하는 도구를 사용하여 에 나열된 OpenSM 버전의 패키지를 다운로드합니다 <block ref="ae114c21b1e7dc7681f7c73b9450ef94" category="inline-link-macro-rx"></block> 섹션을 Mellanox 웹 사이트에서 으로 이동합니다<block ref="4d67f7bc650c0237a4f14903bb4e32de" prefix=" " category="inline-code"></block> 디렉토리. 예를 들면 다음과 같습니다.</block>
  <block id="df1f716d0a26eb697eb7605722643850" category="list-text">아래에서<block ref="4003590e6e5408f8e5272e50f909dfac" prefix=" " category="inline-code"></block> 다음 구성을 정의합니다.</block>
  <block id="c25698c0b0a8b21ec89a22a39d05b4e4" category="summary">호스트 변수(host_vars)를 사용하여 개별 블록 노드의 구성을 지정합니다.</block>
  <block id="007670379f88b0b437948cd7ffd18854" category="doc">개별 블록 노드를 구성합니다</block>
  <block id="c04b45b2e867c15ec034a753c3caad42" category="paragraph">이 섹션에서는 를 채우는 방법을 설명합니다<block ref="e401274046660da23cecf42c63b0dc71" prefix=" " category="inline-code"></block> 클러스터에 있는 각 블록 노드에 대한 파일입니다. 이러한 파일에는 특정 블록 노드에 고유한 설정만 포함되어야 합니다. 여기에는 일반적으로 다음이 포함됩니다.</block>
  <block id="718e1c8b260f855e4dfed258432c772c" category="list-text">시스템 이름(System Manager에 표시됨)</block>
  <block id="d6535083366c5efbc468368177b26a11" category="list-text">컨트롤러 중 하나에 대한 HTTPS URL(REST API를 사용하여 시스템을 관리하는 데 사용됨)</block>
  <block id="d34a9e5f2aea0e08afe426c3db560f6f" category="list-text">이 블록 노드에 연결하기 위해 사용하는 스토리지 프로토콜 파일 노드</block>
  <block id="ac7d8826ccdecec74ae70f73a19ab9d6" category="list-text">IP 주소(필요한 경우)와 같은 HIC(호스트 인터페이스 카드) 포트 구성</block>
  <block id="46180093758c495f215bf2ac0b7a86d4" category="paragraph">에 정의된 IP 주소 지정 체계를 참조합니다 <block ref="357e0adc4a9895d7fb0741a56cb66937" category="inline-link-macro-rx"></block> 섹션에서 클러스터의 각 블록 노드에 대해 파일을 생성합니다<block ref="9a669560bf11c3e8770f91d615f47c78" prefix=" " category="inline-code"></block> 다음과 같이 채웁니다.</block>
  <block id="80eb8027c5428b5220f76ca5617cdbef" category="list-text">맨 위에서 컨트롤러 중 하나에 대한 시스템 이름과 HTTPS URL을 지정합니다.</block>
  <block id="81788ba0d7d02d81c063dbca621ba11b" category="inline-link-macro">프로토콜</block>
  <block id="d1ac4a3f6cf15e4c501caf76560363b8" category="list-text">를 선택합니다 <block ref="42254e7bd4c71b16c1c0d21e675ced23" category="inline-link-macro-rx"></block> 파일 노드는 를 사용하여 이 블록 노드에 접속합니다.</block>
  <block id="c2e9d327966d74c358df1c68e849c85b" category="list-text">지원되는 프로토콜:<block ref="9df22f196a33acd0b372fe502de51211" prefix=" " category="inline-code"></block>,<block ref="39eea648dab96b0ee6022dabb38bc420" prefix=" " category="inline-code"></block>,<block ref="e05fe30750d3ea262a610d17ebc07019" prefix=" " category="inline-code"></block>,<block ref="a8a64cef262a04de4872b68b63ab7cd8" prefix=" " category="inline-code"></block>,<block ref="7aee267b2c70d17165e6fa56dc01795a" prefix=" " category="inline-code"></block>,<block ref="11104f7e32c1e7884522b538834ffd9a" prefix=" " category="inline-code"></block>,<block ref="0ab2fb14820281e536188e7478368635" prefix=" " category="inline-code"></block>,<block ref="99e6ba7d601220dd39e915ce4c6ff74c" prefix=" " category="inline-code"></block>,<block ref="384fddfa43cdca25e66ad1b9a278e6c7" prefix=" " category="inline-code"></block>.</block>
  <block id="0c5c276a533c6231e1004931dde34c40" category="list-text">사용 중인 프로토콜에 따라 HIC 포트는 추가 구성이 필요할 수 있습니다. 필요한 경우 HIC 포트 구성을 정의하여 각 컨트롤러 구성의 상위 항목이 각 컨트롤러의 물리적 가장 왼쪽 포트 및 하단 포트가 가장 오른쪽 포트와 대응하도록 해야 합니다. 모든 포트는 현재 사용되지 않는 경우에도 유효한 구성이 필요합니다.</block>
  <block id="95e06a898133e12b42adf8c80aafb2f7" category="admonition">EF600 블록 노드와 함께 HDR(200GB) InfiniBand 또는 200GB RoCE를 사용하는 경우에는 아래 섹션도 참조하십시오.</block>
  <block id="2a6f3123e92916a549d4843b0432ee15" category="list-text">iSCSI의 경우:</block>
  <block id="b405e253b7123d507b950877cb495779" category="list-text">iSER의 경우:</block>
  <block id="3becb61841658038a043e3eca2dc705e" category="list-text">NVMe/IB의 경우:</block>
  <block id="5f42fe6193c58ec9a447a090be2e17b8" category="list-text">NVMe/RoCE의 경우:</block>
  <block id="4b9c9e1cc0a87604a342176becdb9d29" category="list-text">FC 및 SAS 프로토콜은 추가 구성이 필요하지 않습니다. SRP가 올바르게 권장되지 않습니다.</block>
  <block id="55876228853abf632dec9346a4f372ec" category="inline-link-macro">문서화</block>
  <block id="d487c72028a8f41291fa35df82cfe348" category="paragraph">iSCSI CHAP 구성 기능을 포함하여 HIC 포트 및 호스트 프로토콜을 구성하는 추가 옵션은 을 참조하십시오 <block ref="03b4e8c5a2a4120cb0ea20ad53010d79" category="inline-link-macro-rx"></block> SANtricity 컬렉션에 포함되어 있습니다. 참고 BeeGFS를 구축할 때 스토리지 풀, 볼륨 구성 및 스토리지 용량 할당의 기타 측면은 다른 위치에 구성되며 이 파일에 정의하면 안 됩니다.</block>
  <block id="ca752ddde33be986f431e89edb589ac1" category="paragraph">을 클릭합니다 <block ref="4b43b7669fad4b5b712c0fa73fdf7e2c" category="inline-link-macro-rx"></block> 단일 블록 노드를 나타내는 전체 인벤토리 파일의 예</block>
  <block id="bb3b75abe4dc6581c40f5061474bb17f" category="section-title">HDR(200GB) InfiniBand 또는 200GB RoCE와 NetApp EF600 블록 노드 사용:</block>
  <block id="f8de92059efc82f4fcf167cc78595c49" category="paragraph">EF600에서 HDR(200GB) InfiniBand를 사용하려면 각 물리적 포트에 대해 두 번째 "가상" IP를 구성해야 합니다. 다음은 이중 포트 InfiniBand HDR HIC가 장착된 EF600을 구성하는 올바른 방법의 예입니다.</block>
  <block id="2636cdb2e4c8c163e637fb4b1be7ef57" category="summary">그룹 변수(group_vars)를 사용하여 일반 블록 노드 구성을 지정합니다.</block>
  <block id="42379f3693325579ec45c17436f3fa30" category="doc">일반 블록 노드 구성을 지정합니다</block>
  <block id="f3b82d936104a57a294cfa3abe47b556" category="paragraph">모든 블록 노드에 대해 사과해야 하는 구성은 에 정의되어 있습니다<block ref="7bc866ffde9914c7ef21768fcf6f0683" prefix=" " category="inline-code"></block>. 일반적으로 다음과 같은 기능이 있습니다.</block>
  <block id="8265488ffd9c98f3bf95687c608f6db9" category="list-text">Ansible 제어 노드를 블록 노드로 사용되는 E-Series 스토리지 시스템에 연결하는 방법에 대한 자세한 정보</block>
  <block id="e6a6b0e56e4888732076684459908257" category="list-text">노드에서 실행해야 하는 펌웨어, NVSRAM 및 드라이브 펌웨어 버전</block>
  <block id="432cd2d056edf811cddfd42fe9367df2" category="list-text">캐시 설정, 호스트 구성 및 볼륨 프로비저닝 방법에 대한 설정을 포함한 글로벌 구성</block>
  <block id="b34cde4ef9da9f08725d6c62977d706a" category="admonition">이 파일에 설정된 옵션은 혼합 하드웨어 모델을 사용 중이거나 각 노드에 대해 다른 암호를 사용하는 경우와 같이 개별 블록 노드에서도 정의할 수 있습니다. 개별 블록 노드의 구성은 이 파일의 구성보다 우선합니다.</block>
  <block id="6afa815954c372aee339049211ead69a" category="paragraph">파일을 만듭니다<block ref="7bc866ffde9914c7ef21768fcf6f0683" prefix=" " category="inline-code"></block> 다음과 같이 채웁니다.</block>
  <block id="35604a35256cdb2079414a606f693bc3" category="list-text">Ansible은 SSH를 사용하여 블록 노드에 연결하지 않고 REST API를 사용합니다. 이를 위해 다음을 설정해야 합니다.</block>
  <block id="c4cb5f6ece988910c4cb1a90025fb6fd" category="list-text">각 노드를 관리할 사용자 이름과 암호를 지정합니다. 사용자 이름은 선택적으로 생략할 수 있으며 기본적으로 admin이 됩니다. 그렇지 않으면 관리자 권한이 있는 계정을 지정할 수 있습니다. 또한 SSL 인증서를 확인해야 하는지 무시해야 하는지 여부를 지정합니다.</block>
  <block id="4b47eaf1cc2e42fd7841edf5ee136cf9" category="admonition">암호를 일반 텍스트로 나열하는 것은 권장되지 않습니다. Ansible 볼트를 사용하거나 을 제공합니다<block ref="b59049923d63016545b743560345fa56" prefix=" " category="inline-code"></block> VAR을(를) 사용하여 Ansible을 실행하는 경우</block>
  <block id="7a48384bf61ccc1cd67f79e20b2946b0" category="list-text">노드에 설치할 컨트롤러 펌웨어, NVSRAM 및 드라이브 펌웨어를 선택적으로 지정합니다. 이러한 파일은 로 다운로드해야 합니다<block ref="93501a11e921083efbd154e0cdff5f10" prefix=" " category="inline-code"></block> Ansible을 실행하기 전 디렉토리: E-Series 컨트롤러 펌웨어 및 NVSRAM을 다운로드할 수 있습니다 <block ref="66d434b6c80c5839cd158404e9040bf6" category="inline-link-macro-rx"></block> 및 드라이브 펌웨어를 업데이트합니다 <block ref="289e1473afcefdacfca9006e22cec3f7" category="inline-link-macro-rx"></block>:</block>
  <block id="9f068c46b4a825d808c2c9767e358bf4" category="admonition">이 구성을 지정하면 Ansible이 추가 프롬프트 없이 컨트롤러 재부팅(필요한 경우)을 비롯한 모든 펌웨어를 자동으로 업데이트합니다. 이는 BeeGFS/호스트 입출력에 영향을 줄 수 있지만 일시적으로 성능이 저하될 수 있습니다.</block>
  <block id="e34a3cd38452267edb183f6fec7d3128" category="list-text">글로벌 시스템 구성 기본값을 조정합니다. 여기에 나열된 옵션과 값은 NetApp 기반의 BeeGFS에 일반적으로 권장되지만 필요한 경우 조정할 수 있습니다.</block>
  <block id="959afa15d8283f663da6fb31c0931335" category="list-text">글로벌 볼륨 프로비저닝 기본값을 구성합니다. 여기에 나열된 옵션과 값은 NetApp 기반의 BeeGFS에 일반적으로 권장되지만 필요한 경우 조정할 수 있습니다.</block>
  <block id="36aa3776a01484babb7b935f0790e38d" category="list-text">필요한 경우 Ansible에서 스토리지 풀 및 볼륨 그룹을 위한 드라이브를 선택하는 순서를 조정하고 다음 모범 사례를 염두에 두십시오.</block>
  <block id="9ddcb68f677516aceffc3293429a25e8" category="list-text">관리 및/또는 메타데이터 볼륨에 먼저 사용되어야 하는 (잠재적으로 작은) 드라이브와 스토리지 볼륨을 나열합니다.</block>
  <block id="6857ed48db753853948c52afd2297877" category="list-text">디스크 쉘프/드라이브 엔클로저 모델을 기준으로 사용 가능한 드라이브 채널 간에 드라이브 선택 순서를 조정해야 합니다. 예를 들어 EF600과 확장 없는 경우 드라이브 0-11은 드라이브 채널 1에 있고 드라이브 12-23은 드라이브 채널에 있습니다. 따라서 드라이브 선택의 균형을 맞추는 전략은 선택입니다<block ref="22527cd74d7cc7f48375817974dc1712" prefix=" " category="inline-code"></block> 99:0, 99:23, 99:1, 99:22 등 하나 이상의 엔클로저가 있는 경우 첫 번째 숫자는 드라이브 쉘프 ID를 나타냅니다.</block>
  <block id="1f28da07b9b1480e254e0e0fe280f3a2" category="paragraph">을 클릭합니다 <block ref="85c5b5287ec04e7c836b5655b59fd26c" category="inline-link-macro-rx"></block> 일반 블록 노드 구성을 나타내는 전체 인벤토리 파일의 예</block>
  <block id="e20d89701cb46cf38953e6dc25a2dc3d" category="summary">inventory.yml 파일을 사용하여 각 BeeGFS 서비스를 실행할 수 있는 파일 노드를 지정합니다.</block>
  <block id="02e4c76e0e6e5414c70765451a79b37c" category="doc">BeeGFS 서비스를 파일 노드에 매핑합니다</block>
  <block id="3e99717578ba1478873bc5c3269e4086" category="paragraph">를 사용하여 각 BeeGFS 서비스를 실행할 수 있는 파일 노드를 지정합니다<block ref="d28e452e49fc926f32af1d87afcff3ce" prefix=" " category="inline-code"></block> 파일.</block>
  <block id="24c07a5a77746e85d21882c88bdd5b03" category="paragraph">이 섹션에서는 을 생성하는 방법을 안내합니다<block ref="d28e452e49fc926f32af1d87afcff3ce" prefix=" " category="inline-code"></block> 파일. 여기에는 모든 블록 노드를 나열하고 각 BeeGFS 서비스를 실행할 수 있는 파일 노드를 지정하는 작업이 포함됩니다.</block>
  <block id="5ee7bf1a42518812c2b87b463bf96a31" category="paragraph">파일을 만듭니다<block ref="d28e452e49fc926f32af1d87afcff3ce" prefix=" " category="inline-code"></block> 다음과 같이 채웁니다.</block>
  <block id="7aec62cda467a76d024911e74e1fec38" category="list-text">파일 상단에서 표준 Ansible 인벤토리 구조를 생성합니다.</block>
  <block id="5923f18af043b9957bf5541e595cc0f5" category="list-text">이 HA 클러스터에 참여하는 모든 블록 노드를 포함하는 그룹을 생성합니다.</block>
  <block id="b084d86d2b539345bcda62aaa5bceb0f" category="list-text">클러스터의 모든 BeeGFS 서비스를 포함할 그룹과 해당 서비스를 실행할 파일 노드를 생성합니다.</block>
  <block id="eec391bff48a7ed3bbf30e3280fbe9e3" category="list-text">클러스터의 각 BeeGFS 서비스에 대해 해당 서비스를 실행해야 하는 기본 파일 노드 및 보조 파일 노드를 정의합니다.</block>
  <block id="e26a68a8ce5809998083f351bf56677e" category="paragraph">을 클릭합니다 <block ref="00544a89e642f3f5a354362c58d52f2e" category="inline-link-macro-rx"></block> 전체 재고 파일의 예</block>
  <block id="9df40d55a663f7c179e328bf937587fe" category="summary">BeeGFS 서비스는 그룹 변수(group_VAR)를 사용하여 구성됩니다.</block>
  <block id="29ee3861e1e5ac6fa4281c3c3fddd958" category="doc">BeeGFS 메타데이터 서비스를 정의합니다</block>
  <block id="60513084f53d0d484c55e212d6a9248e" category="paragraph">이 섹션에서는 BeeGFS 메타데이터 서비스 정의에 대해 설명합니다. 특정 파일 시스템에 대한 HA 클러스터에 이 유형의 서비스가 하나 이상 있어야 합니다. 이 서비스를 구성하는 데는 다음 사항이 포함됩니다.</block>
  <block id="ef1af77af85196869032232af1a07f87" category="list-text">서비스 유형(메타데이터)</block>
  <block id="164d597920f7afac5bd1bc14b783ff41" category="list-text">이 BeeGFS 서비스에만 적용해야 하는 구성을 정의합니다.</block>
  <block id="9e4755a30f0ec19b232cf1ce068ab8d4" category="list-text">이 서비스에 연결할 수 있는 하나 이상의 부동 IP(논리 인터페이스)를 구성합니다.</block>
  <block id="fc266b5cc64e2d259e49bb24b0c186d0" category="list-text">이 서비스에 대한 데이터를 저장할 볼륨 위치/방법 지정(BeeGFS 메타데이터 타겟)</block>
  <block id="4494ebe8f3eb1cbaae48657b9f5a6ae3" category="paragraph">를 참조합니다 <block ref="357e0adc4a9895d7fb0741a56cb66937" category="inline-link-macro-rx"></block> 섹션에서 파일을 만듭니다<block ref="3ffe66d0860049a5a100c385493d4997" prefix=" " category="inline-code"></block> 클러스터의 각 메타데이터 서비스에 대해 다음을 채웁니다.</block>
  <block id="9cef1e732270bc660ef17d29df58c49c" category="list-text">이 파일이 BeeGFS 메타데이터 서비스에 대한 구성을 나타냅니다.</block>
  <block id="d1bbe7b3631d4fdecc7637f7f28f2cd9" category="list-text">이 BeeGFS 서비스에만 적용해야 하는 구성을 정의합니다. 최소한 원하는 TCP 및 UDP 포트를 지정해야 하지만 에서 지원되는 구성 매개 변수는 모두 지정해야 합니다<block ref="672e512128cc9536bcf9f16964b20c49" prefix=" " category="inline-code"></block> 또한 포함될 수 있습니다. 참고 다음 매개 변수는 자동으로/다른 위치에 구성되며 여기에서 지정하면 안 됩니다.<block ref="6ea5464abdaaa0243bf0db8481a9a52b" prefix=" " category="inline-code"></block>,<block ref="dbca95678907e2f2bf827d44042c16c5" prefix=" " category="inline-code"></block>,<block ref="6097b6e95af2579f2147a330c21f7b59" prefix=" " category="inline-code"></block>,<block ref="1c285a92de2348d33dd1fc333fb66c45" prefix=" " category="inline-code"></block>,<block ref="7f8e8358da4bb8d8e7f6f717ad9eb0e9" prefix=" " category="inline-code"></block>, 및<block ref="b61a9cecccc8e8db252dd5200883c7cc" prefix=" " category="inline-code"></block>.</block>
  <block id="71529044e633eb2a4b25c87eb3ea0358" category="list-text">다른 서비스 및 클라이언트가 이 서비스에 연결하는 데 사용할 하나 이상의 부동 IP를 구성합니다. 이렇게 하면 BeeGFS가 자동으로 설정됩니다<block ref="7f8e8358da4bb8d8e7f6f717ad9eb0e9" prefix=" " category="inline-code"></block> 옵션):</block>
  <block id="db6bbb0bcb13fc624704b26d5d879534" category="list-text">선택적으로, 나가는 통신에 사용할 수 있는 하나 이상의 허용된 IP 서브넷을 지정합니다(이 경우 BeeGFS가 자동으로 설정됩니다)<block ref="b61a9cecccc8e8db252dd5200883c7cc" prefix=" " category="inline-code"></block> 옵션):</block>
  <block id="d3de182528701519a47cbe276590393a" category="list-text">다음 지침에 따라 이 서비스가 데이터를 저장할 BeeGFS 메타데이터 타겟을 지정합니다. 이렇게 하면 가 자동으로 구성됩니다<block ref="dbca95678907e2f2bf827d44042c16c5" prefix=" " category="inline-code"></block> 옵션):</block>
  <block id="e0f52cfdc30da3e272257c8783119a56" category="list-text">여러 BeeGFS 서비스/타겟에 동일한 스토리지 풀 또는 볼륨 그룹 이름을 사용할 수 있으므로 동일한 스토리지 풀 또는 볼륨 그룹 이름을 사용하기만 하면 됩니다<block ref="b068931cc450442b63f5b3d276ea4297" prefix=" " category="inline-code"></block>,<block ref="2d0e37110968341728e47095df64a19c" prefix=" " category="inline-code"></block>,<block ref="48658e2ad8eaaf7daff452601ea618db" prefix=" " category="inline-code"></block>, 및<block ref="e241a8daa5b8e1af3b82b1e1a8ec24a9" prefix=" " category="inline-code"></block> 각 서비스에 대한 구성(각 서비스에 대해 나열된 볼륨은 서로 달라야 함)</block>
  <block id="94028cf43ef8dc903051e90ad2eec0bb" category="list-text">볼륨 크기는 스토리지 풀/볼륨 그룹의 백분율로 지정해야 하며, 특정 스토리지 풀/볼륨 그룹을 사용하는 모든 서비스/볼륨에서 합계가 100을 초과해서는 안 됩니다. 참고 SSD를 사용할 때는 SSD 성능과 마모 수명을 최대화하기 위해 볼륨 그룹에 일부 여유 공간을 남겨 두는 것이 좋습니다(클릭) <block ref="99b1e1c34bffd297f45567902e8c3aee" category="inline-link-macro-rx"></block> 자세한 내용 참조).</block>
  <block id="339c4b049c3a7e5cdf355daceda6f43a" category="list-text">을 클릭합니다 <block ref="0a71609ed00bd9652e70cd5b106f9ae3" category="inline-link-macro-rx"></block> 에서 사용할 수 있는 전체 구성 옵션 목록을 확인하십시오<block ref="8ca968d07b3817015da8919c700152f5" prefix=" " category="inline-code"></block>. 과 같은 일부 옵션을 확인합니다<block ref="9ed39e2ea931586b6a985a6942ef573e" prefix=" " category="inline-code"></block>,<block ref="67b3dba8bc6778101892eb77249db32e" prefix=" " category="inline-code"></block>,<block ref="99bd6603c88a46584bf9b94ffab3d6c9" prefix=" " category="inline-code"></block>,<block ref="db137bf87e9c1a766b82885236ac8b87" prefix=" " category="inline-code"></block>, 및<block ref="7951c85f8306dda4792beb0e6a356282" prefix=" " category="inline-code"></block> 및 볼륨 이름은 자동으로 생성되며 여기에서 지정할 수 없습니다.</block>
  <block id="df5fc0ef6e9aaec0f45d18fdd7ee8f12" category="paragraph">을 클릭합니다 <block ref="c59646481b474fffe5bc2a736ab8653d" category="inline-link-macro-rx"></block> BeeGFS 메타데이터 서비스를 나타내는 전체 인벤토리 파일의 예</block>
  <block id="0badcf73673abd8a3f15cc4e386caafa" category="doc">BeeGFS 스토리지 서비스를 정의합니다</block>
  <block id="624bf455f36c44a126036391cd39a75c" category="paragraph">이 섹션에서는 BeeGFS 스토리지 서비스 정의를 안내합니다. 특정 파일 시스템에 대한 HA 클러스터에 이 유형의 서비스가 하나 이상 있어야 합니다. 이 서비스를 구성하는 데는 다음 사항이 포함됩니다.</block>
  <block id="e03fff2a92d72a09b4f9f5d0e895d1fd" category="list-text">서비스 유형(스토리지)</block>
  <block id="e5e9883649f056a718503df3542a70d4" category="list-text">이 서비스에 대한 데이터를 저장할 볼륨 위치/방법 지정(BeeGFS 스토리지 타겟)</block>
  <block id="cdfd2c4f30392a3ec71bccb64a57b50c" category="paragraph">를 참조합니다 <block ref="357e0adc4a9895d7fb0741a56cb66937" category="inline-link-macro-rx"></block> 섹션에서 파일을 만듭니다<block ref="a16ac980b359b788a73d8add9202cc6f" prefix=" " category="inline-code"></block> 클러스터의 각 스토리지 서비스에 대해 다음과 같이 채웁니다.</block>
  <block id="204caa9915a25307074d637daed7faba" category="list-text">이 파일이 BeeGFS 스토리지 서비스에 대한 구성을 나타냅니다.</block>
  <block id="d03efed3ebed6860068fb8a5123ef4c6" category="list-text">이 BeeGFS 서비스에만 적용해야 하는 구성을 정의합니다. 최소한 원하는 TCP 및 UDP 포트를 지정해야 하지만 에서 지원되는 구성 매개 변수는 모두 지정해야 합니다<block ref="8a87bdd1964512794d560f1af3699fa1" prefix=" " category="inline-code"></block> 또한 포함될 수 있습니다. 참고 다음 매개 변수는 자동으로/다른 위치에 구성되며 여기에서 지정하면 안 됩니다.<block ref="6ea5464abdaaa0243bf0db8481a9a52b" prefix=" " category="inline-code"></block>,<block ref="facec0675a87a8e14bef255e83e40f1e" prefix=" " category="inline-code"></block>,<block ref="6097b6e95af2579f2147a330c21f7b59" prefix=" " category="inline-code"></block>,<block ref="1c285a92de2348d33dd1fc333fb66c45" prefix=" " category="inline-code"></block>,<block ref="7f8e8358da4bb8d8e7f6f717ad9eb0e9" prefix=" " category="inline-code"></block>, 및<block ref="b61a9cecccc8e8db252dd5200883c7cc" prefix=" " category="inline-code"></block>.</block>
  <block id="b0e2ab52d86028182775498a8ba8dcc3" category="list-text">다음 지침에 따라 이 서비스가 데이터를 저장할 BeeGFS 스토리지 타겟을 지정합니다. 이 경우에도 가 자동으로 구성됩니다<block ref="facec0675a87a8e14bef255e83e40f1e" prefix=" " category="inline-code"></block> 옵션):</block>
  <block id="b18c6fe32d4f2f076f7c708ea5be89c1" category="paragraph">을 클릭합니다 <block ref="7bc3fba5853c696254cf4264774b5d50" category="inline-link-macro-rx"></block> BeeGFS 스토리지 서비스를 나타내는 전체 인벤토리 파일의 예</block>
  <block id="973cf6ca298b6ecfb5f2f3290ca4cd2f" category="doc">BeeGFS 관리 서비스를 정의합니다</block>
  <block id="a461b810f49c26d9dc6d92a1e3a344bc" category="paragraph">이 섹션에서는 BeeGFS 관리 서비스 정의에 대해 설명합니다. 특정 파일 시스템에 대한 HA 클러스터에는 이 유형의 서비스 하나만 있어야 합니다. 이 서비스를 구성하는 데는 다음 사항이 포함됩니다.</block>
  <block id="a9da9d90de8c8b13991c884b03f76658" category="list-text">서비스 유형(관리)</block>
  <block id="b966cc65076783762d4b37aff48e5a1f" category="list-text">이 서비스에 대한 데이터를 저장할 볼륨 위치/방법 지정(BeeGFS 관리 타겟)</block>
  <block id="88f6eb5599f1011262d2e828fed66c41" category="paragraph">새 파일을 만듭니다<block ref="096c36ebf1ab8bf90e099d6808eb57d0" prefix=" " category="inline-code"></block> 을 참조하십시오 <block ref="357e0adc4a9895d7fb0741a56cb66937" category="inline-link-macro-rx"></block> 섹션을 다음과 같이 채웁니다.</block>
  <block id="66969fa0d9af9f38ebaa31ea1c4b7051" category="list-text">이 파일이 BeeGFS 관리 서비스의 구성을 나타냅니다.</block>
  <block id="968fc19eb9be6283a0d5f79c8536f855" category="list-text">이 BeeGFS 서비스에만 적용해야 하는 구성을 정의합니다. 할당량을 설정해야 하는 경우가 아니면 일반적으로 관리 서비스에 필요하지 않지만 에서 지원되는 구성 매개 변수는 필요하지 않습니다<block ref="025b9ec9690bfeefef6aedbac6e66c87" prefix=" " category="inline-code"></block> 포함될 수 있습니다. 참고 다음 매개 변수는 자동으로/다른 위치에 구성되며 여기에서 지정하면 안 됩니다.<block ref="02a09b36e77ebbfe1d499e597daef0d5" prefix=" " category="inline-code"></block>,<block ref="6097b6e95af2579f2147a330c21f7b59" prefix=" " category="inline-code"></block>,<block ref="1c285a92de2348d33dd1fc333fb66c45" prefix=" " category="inline-code"></block>,<block ref="7f8e8358da4bb8d8e7f6f717ad9eb0e9" prefix=" " category="inline-code"></block>, 및<block ref="b61a9cecccc8e8db252dd5200883c7cc" prefix=" " category="inline-code"></block>.</block>
  <block id="8e19ae7e081dee60d1c86f207028684b" category="list-text">다음 지침에 따라 이 서비스가 데이터를 저장할 BeeGFS 관리 대상을 지정합니다.</block>
  <block id="1511cb861f1160e48d8e9c07e416cd1a" category="paragraph">을 클릭합니다 <block ref="ffb907e2c03168946e1e4d8df77e6e36" category="inline-link-macro-rx"></block> BeeGFS 관리 서비스를 나타내는 전체 인벤토리 파일의 예</block>
  <block id="234c05131256028f5ab7ea9b87261ff3" category="summary">Ansible 인벤토리는 원하는 BeeGFS HA 클러스터를 정의하는 구성 파일 세트입니다.</block>
  <block id="e520383c76f5e72226ebb572b987380c" category="doc">Ansible 인벤토리 개요</block>
  <block id="7a1eabc3deb7fd02ceb1e16eafc41073" category="inline-link-macro">인벤토리</block>
  <block id="283c77f47e33325beac16dfcff1fbdc4" category="inline-link-macro">하위 디렉토리/파일</block>
  <block id="3a6e55a49a2cdf7c86076b810d565fc2" category="paragraph">을 구성하기 위한 표준 Ansible 관행을 따르는 것이 좋습니다 <block ref="6c37acba8ff27fe32f3259d928e2df83" category="inline-link-macro-rx"></block>을 참조하십시오 <block ref="0b746a370389b97701184b02d91b44b0" category="inline-link-macro-rx"></block> 전체 재고를 한 파일에 저장하는 대신</block>
  <block id="21c8e198e85188d23c3e8ec1332bc84c" category="paragraph">단일 BeeGFS HA 클러스터의 Ansible 인벤토리는 다음과 같이 구성됩니다.</block>
  <block id="d79b9038c2ea4a7f408423c177fcd3c2" category="paragraph"><block ref="d79b9038c2ea4a7f408423c177fcd3c2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8c57469570cfaa1ea4910df225230163" category="admonition">단일 BeeGFS 파일 시스템이 여러 HA 클러스터에 걸쳐 있을 수 있으므로 대규모 설치의 경우 여러 Ansible 재고가 있을 수 있습니다. 일반적으로 문제를 피하기 위해 여러 HA 클러스터를 단일 Ansible 인벤토리로 정의하지 않는 것이 좋습니다.</block>
  <block id="1b1ad4049313d49cd09961eea7b62a6f" category="list-text">Ansible 제어 노드에서 구축할 BeeGFS 클러스터의 Ansible 인벤토리가 포함된 빈 디렉토리를 생성합니다.</block>
  <block id="697c53131c77d1cf7ff864d4f02aca2d" category="list-text">파일 시스템에 여러 HA 클러스터가 포함될 수 있는 경우 먼저 파일 시스템에 대한 디렉토리를 생성한 다음 각 HA 클러스터를 나타내는 인벤토리에 대한 하위 디렉토리를 생성하는 것이 좋습니다. 예를 들면 다음과 같습니다.</block>
  <block id="aa4b0754e84122851b5c983186feaa49" category="list-text">구축할 HA 클러스터의 인벤토리가 포함된 디렉토리에서 두 개의 디렉토리를 생성합니다<block ref="96fa973cda8809ad84f646e3d8fbbc1c" prefix=" " category="inline-code"></block> 및<block ref="3342582e194d63e4c91b56623752c9c6" prefix=" " category="inline-code"></block> 두 개의 파일이 있습니다<block ref="d28e452e49fc926f32af1d87afcff3ce" prefix=" " category="inline-code"></block> 및<block ref="2f78c4e27feaf25ffb33d97e8ff7e7a6" prefix=" " category="inline-code"></block>.</block>
  <block id="20034aab6a0bc59dc9804ff9d5960982" category="paragraph">다음 섹션에서는 이러한 각 파일의 내용을 정의하는 방법을 설명합니다.</block>
  <block id="cd3a8919c565c37be6e50322a583eac4" category="summary">Ansible 재고를 구축하기 전에 파일 시스템 배포를 계획하십시오.</block>
  <block id="6ec9184bd478b3b836d1c92fa51f1baa" category="paragraph">파일 시스템을 구축하기 전에 클러스터에서 실행 중인 모든 파일 노드, 블록 노드 및 BeeGFS 서비스에 필요한 IP 주소, 포트 및 기타 구성을 정의해야 합니다. 정확한 구성은 클러스터의 아키텍처에 따라 다르지만 이 섹션에서는 일반적으로 적용되는 모범 사례와 후속 단계를 정의합니다.</block>
  <block id="229ad1ff2fa862e1fa317520fe78ad42" category="list-text">IP 기반 스토리지 프로토콜(예: iSER, iSCSI, NVMe/IB 또는 NVMe/RoCE)을 사용하여 파일 노드를 블록 노드에 연결하는 경우, 각 구성 요소에 대해 다음 워크시트를 작성하십시오. 단일 빌딩 블록의 각 직접 접속은 고유한 서브넷을 가져야 하며, 클라이언트-서버 접속에 사용되는 서브넷과 중복되지 않아야 합니다.</block>
  <block id="0611f793ccd40e910f3d7f82c1bb6d66" category="cell">가상 IP(HDR IB를 사용하는 EF600용)</block>
  <block id="6d68d27a364d17c3c6b36281d161a34e" category="cell">&lt;HOSTNAME&gt;</block>
  <block id="2feb1f8d58fa960c8d2635cb910ad7ec" category="cell">&lt;PORT&gt;</block>
  <block id="a87d961719c43a8065ad6f09b292f547" category="cell">&lt;IP/SUBNET&gt;</block>
  <block id="5d52f332806d779c548497e97b6050ed" category="admonition">각 빌딩 블록의 파일 및 블록 노드가 직접 연결된 경우 여러 빌딩 블록에 동일한 IP/스키마를 재사용할 수 있습니다.</block>
  <block id="0eca8abaad32a83698b54d0fcea93ad3" category="list-text">스토리지 네트워크에 InfiniBand 또는 RoCE(RDMA over Converged Ethernet)를 사용하는 경우, 다음 워크시트를 작성하여 HA 클러스터 서비스, BeeGFS 파일 서비스 및 클라이언트가 통신할 수 있는 IP 범위를 결정하십시오.</block>
  <block id="0c2bd0118b2766abe77c40b1bd393b44" category="cell">BeeGFS 클러스터 IP</block>
  <block id="c4aa072ba75aa28cd14308257fee1a08" category="cell">&lt;INTERFACE(s)&gt;</block>
  <block id="65b5aefed3041b5dccc318ffe87431b7" category="cell">&lt;RANGE&gt;</block>
  <block id="1ec0a19ea7a783b022b53265dd90c383" category="cell">&lt;IP(s)&gt;</block>
  <block id="0353e2599d6ca03a78f42855abe0a6f4" category="list-text">단일 IP 서브넷을 사용하는 경우 워크시트가 하나만 필요합니다. 그렇지 않으면 두 번째 서브넷에 대한 워크시트도 작성하십시오.</block>
  <block id="c19e3d6f1cb2b9ed96d0553ef0363080" category="list-text">위의 내용을 토대로 클러스터의 각 구성 요소에 대해 실행할 BeeGFS 서비스를 정의하는 다음 워크시트를 작성하십시오. 각 서비스에 대해 기본 설정/보조 파일 노드, 네트워크 포트, 부동 IP, NUMA 영역 할당(필요한 경우) 및 대상에 사용할 블록 노드를 지정합니다. 워크시트를 작성할 때 다음 지침을 참조하십시오.</block>
  <block id="501d4d9b0f3910c0d30a4a828247f2b0" category="list-text">BeeGFS 서비스 중 하나를 지정합니다<block ref="5670713387ceeca6a99ea4c5d6381de9" prefix=" " category="inline-code"></block>,<block ref="adc521b987f8d17684929a7814fb39a6" prefix=" " category="inline-code"></block>, 또는<block ref="13e9e938499f52dc5dd76a5f625aef19" prefix=" " category="inline-code"></block> 여기서 ID는 이 파일 시스템에서 해당 유형의 모든 BeeGFS 서비스에 대한 고유 번호입니다. 이 규칙은 각 서비스를 구성하는 파일을 생성하는 동안 다음 섹션에서 이 워크시트를 간단하게 참조할 수 있도록 합니다.</block>
  <block id="d5164729d98e85db7b7cb0282c74163d" category="list-text">BeeGFS 서비스의 포트는 특정 구성 요소 전체에서 고유해야 합니다. 포트 충돌을 방지하기 위해 동일한 포트 번호의 서비스를 동일한 파일 노드에서 실행할 수 없도록 합니다.</block>
  <block id="8a18a5a52ba3b55c805c94f8ac3889c9" category="list-text">필요한 서비스가 둘 이상의 블록 노드 및/또는 스토리지 풀의 볼륨을 사용할 수 있는 경우(모든 볼륨을 동일한 컨트롤러가 소유할 필요는 없음) 또한 여러 서비스에서 동일한 블록 노드 및/또는 스토리지 풀 구성을 공유할 수 있습니다(개별 볼륨은 이후 섹션에서 정의).</block>
  <block id="80a7df0cf1674016cc4cc2588c911429" category="cell">BeeGFS 서비스(파일 이름)</block>
  <block id="5515295c9721b17faa0365ab7a888791" category="cell">파일 노드</block>
  <block id="7428caa4314139d517357edc7bd85e13" category="cell">&lt;SERVICE TYPE&gt;_&lt;ID&gt;.대칭</block>
  <block id="05dbd6a9ac1e738536c568b9c76b6d9f" category="cell">&lt;PREFERRED FILE NODE&gt; &lt;SECONDARY FILE NODE(s)&gt;</block>
  <block id="ce434f7769160d97da3ed0d746a4d983" category="cell">&lt;INTERFACE&gt;:&lt;IP/SUBNET&gt; &lt;INTERFACE&gt;:&lt;IP/SUBNET&gt;</block>
  <block id="0f9b262f92ad6ba4a547abbe4c98c80b" category="cell">&lt;NUMA NODE/ZONE&gt;</block>
  <block id="9746b3183301bae601d6d3e7479f01f9" category="cell">&lt;BLOCK NODE&gt;</block>
  <block id="b95d182f851d32de39590b07917d6dc2" category="cell">&lt;STORAGE POOL/VOLUME GROUP&gt;</block>
  <block id="fe1341a187350b5203bdf2c08baa2ac8" category="cell">&lt;A OR B&gt;</block>
  <block id="78ff65afbf92a15cd30dea91aefc1e9b" category="inline-link-macro">모범 사례</block>
  <block id="b7121c47f4a8776d685a934610733179" category="inline-link-macro">BeeGFS 구성 요소를 정의합니다</block>
  <block id="08c2f9ff46580776f9142eb9c3d6b0e0" category="paragraph">표준 규칙, 모범 사례 및 작성된 예제 워크시트에 대한 자세한 내용은 을 참조하십시오 <block ref="6c990eb84b6c73f7ec3bccc8ae7c61c0" category="inline-link-macro-rx"></block> 및 <block ref="64afa0eccccf9220480b7ad5801765a6" category="inline-link-macro-rx"></block> NetApp 검증 아키텍처의 BeeGFS 섹션:</block>
  <block id="0d4f2647b7895adb046a3392c35f6828" category="summary">NetApp에서 BeeGFS를 실행하는 데 사용되는 하드웨어를 설치하고 케이블을 연결하는 데 필요한 단계입니다.</block>
  <block id="7cb1df0e9acb4e346f49d40865ebd99f" category="doc">하드웨어 설치 및 케이블 연결</block>
  <block id="d0dde32750edec525fffdeacdfe54a80" category="section-title">설치 계획</block>
  <block id="694daa4aca75c61a285846a5ec0b4b0c" category="paragraph">각 BeeGFS 파일 시스템은 몇 개의 블록 노드에서 제공하는 백엔드 스토리지를 사용하여 BeeGFS 서비스를 실행하는 몇 개의 파일 노드로 구성됩니다. 파일 노드는 하나 이상의 고가용성 클러스터로 구성되어 BeeGFS 서비스에 대한 내결함성을 제공합니다. 각 블록 노드는 이미 액티브/액티브 HA 쌍입니다. 각 HA 클러스터에서 지원되는 파일 노드의 최소 수는 3개이고, 각 클러스터에서 지원되는 파일 노드의 최대 수는 10개입니다. BeeGFS 파일 시스템은 함께 작동하여 단일 파일 시스템 네임스페이스를 제공하는 여러 독립 HA 클러스터를 구축함으로써 10개 노드 이상으로 확장할 수 있습니다.</block>
  <block id="bb4d2a6e482d18af607ee0f07c23d049" category="paragraph">일반적으로 각 HA 클러스터는 몇 개의 파일 노드(x86 서버)가 일부 블록 노드(일반적으로 E-Series 스토리지 시스템)에 직접 연결되는 일련의 "구성 요소"로 구축됩니다. 이 구성은 비대칭형 클러스터를 생성하며, BeeGFS 서비스는 BeeGFS 타겟에 사용되는 백엔드 블록 스토리지에 대한 액세스 권한이 있는 특정 파일 노드에서만 실행할 수 있습니다. 각 구성 요소에서 파일-블록 노드와 직접 연결에 사용되는 스토리지 프로토콜의 균형은 특정 설치 요구 사항에 따라 달라집니다.</block>
  <block id="f1fafc095d6233cf2f9c8d299f6427bb" category="paragraph">대체 HA 클러스터 아키텍처는 파일 노드와 블록 노드 간에 스토리지 패브릭(SAN이라고도 함)을 사용하여 대칭 클러스터를 설정합니다. 따라서 특정 HA 클러스터의 모든 파일 노드에서 BeeGFS 서비스를 실행할 수 있습니다. 일반적으로 대칭형 클러스터는 추가 SAN 하드웨어로 인해 비용 효율적이지 않기 때문에 이 문서에서는 하나 이상의 빌딩 블록으로 구성된 일련의 비대칭 클러스터를 사용한다고 가정합니다.</block>
  <block id="edda5f6836a1cf72ee14894e512b7707" category="admonition">설치를 계속하기 전에 특정 BeeGFS 구축에 대해 원하는 파일 시스템 아키텍처를 충분히 이해해야 합니다.</block>
  <block id="767202c8efedcb9c8edf20f9fce9818d" category="section-title">랙 하드웨어</block>
  <block id="14511f2f5564650d129ca7cabc333278" category="inline-link-macro">블록</block>
  <block id="d5e81e99079cfbb27d893365b01c6733" category="paragraph">설치를 계획할 때 각 구성 요소에 있는 모든 장비가 인접한 랙 유닛에 랙에 장착되어 있어야 합니다. 각 구성 요소에서 파일 노드를 바로 블록 노드 위에 랙에 마운트하는 것이 모범 사례입니다. 파일 및 의 모델에 대한 설명서를 따릅니다 <block ref="3876eb55ee0ffaac1627ebbb7ea8fad8" category="inline-link-macro-rx"></block> 레일 및 하드웨어를 랙에 설치할 때 사용 중인 노드입니다.</block>
  <block id="39979c4d8cb83fc0443baa4ff7f48f07" category="paragraph">단일 구성 요소 예:</block>
  <block id="53536705172b0f4e5a21ed9d9fc90a82" category="inline-image-macro">구성 요소 예</block>
  <block id="ca5a698e3f013f50588c49da25109e06" category="paragraph"><block ref="ca5a698e3f013f50588c49da25109e06" category="inline-image-macro-rx" type="image"></block></block>
  <block id="98ac29120ce31a8b9f17cc6bcad239b1" category="paragraph">각 HA 클러스터에 여러 개의 구성 요소가 있고 파일 시스템에 여러 HA 클러스터가 있는 대규모 BeeGFS 설치의 예:</block>
  <block id="4ffad59982a5f378d3b3c700a5c67ab0" category="inline-image-macro">BeeGFS 구축 예</block>
  <block id="10f70f19704206d8c2cee1fae42f7dea" category="paragraph"><block ref="10f70f19704206d8c2cee1fae42f7dea" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bdc136e73217b9254f82f3e521e32772" category="section-title">케이블 파일 및 블록 노드</block>
  <block id="f6f19d063d8a1cc74be9ed77236d08df" category="inline-link-macro">NetApp 검증 아키텍처에서 2세대 BeeGFS 기반</block>
  <block id="db4f6b855be71292c9b3189eb2262efb" category="paragraph">일반적으로 E-Series 블록 노드의 HIC 포트를 파일 노드의 지정된 호스트 채널 어댑터(InfiniBand 프로토콜의 경우) 또는 호스트 버스 어댑터(파이버 채널 및 기타 프로토콜의 경우) 포트에 직접 연결합니다. 이러한 접속을 설정하는 정확한 방법은 원하는 파일 시스템 아키텍처에 따라 달라집니다. 예를 들면 다음과 같습니다 <block ref="8f90ef59daa0d8291cb239d8abcbaf5e" category="inline-link-macro-rx"></block>:</block>
  <block id="7abaa17b7cccf26fc7842558cbe75332" category="inline-image-macro">노드 케이블 연결을 차단하는 BeeGFS 파일 예</block>
  <block id="d396a30c828f1c32943bda80a19c5f6e" category="paragraph"><block ref="d396a30c828f1c32943bda80a19c5f6e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="40bc85e53495ab0b176af4ef17ea6072" category="section-title">클라이언트 네트워크에 파일 노드를 케이블로 연결합니다</block>
  <block id="1899ae951504892f3420f88e3162b84d" category="paragraph">각 파일 노드에는 BeeGFS 클라이언트 트래픽용으로 지정된 몇 개의 InfiniBand 또는 이더넷 포트가 있습니다. 아키텍처에 따라 각 파일 노드는 고성능 클라이언트/스토리지 네트워크에 하나 이상의 연결을 갖게 되며, 이중화 및 대역폭 향상을 위해 여러 스위치에 연결할 수 있습니다. 다음은 이중화된 네트워크 스위치를 사용하는 클라이언트 케이블 연결의 예입니다. 이 때 어두운 녹색으로 강조 표시된 포트와 밝은 녹색으로 강조 표시된 포트는 별도의 스위치에 연결됩니다.</block>
  <block id="fc65aa085b4e51500efefd3612c95154" category="inline-image-macro">BeeGFS 클라이언트 케이블 연결의 예</block>
  <block id="971ecb443b0122884394e2d0f475486a" category="paragraph"><block ref="971ecb443b0122884394e2d0f475486a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="90a31af51bc017a18f8f032fa49cf901" category="section-title">연결 관리 네트워킹 및 전원</block>
  <block id="b213f1ea719142ad3112dd64e712e06a" category="paragraph">대역내 및 대역외 네트워크에 필요한 네트워크 연결을 설정합니다.</block>
  <block id="2f967ed85c3e532e8aee39997f97a27c" category="paragraph">각 파일 및 블록 노드가 중복성을 위해 여러 전원 분배 장치에 연결되어 있는지 확인하기 위해 모든 전원 공급 장치를 연결합니다(사용 가능한 경우).</block>
  <block id="90791b7e8bfac5f0631992c1a7269f5e" category="summary">파일 시스템을 배포 및 관리하기 위해 Ansible 제어 노드를 설정합니다.</block>
  <block id="9cdd817721bc924d0da9d43995b6cf7d" category="doc">Ansible Control Node 설정</block>
  <block id="31996051b4f5b99834fd90885ae099c1" category="paragraph">Ansible 제어 노드는 클러스터를 관리하는 데 사용되는 물리적 또는 가상 Linux 시스템입니다. 다음 요구 사항을 충족해야 합니다.</block>
  <block id="b4851e92b19af0c5c82447fc0937709d" category="inline-link-macro">요구 사항</block>
  <block id="f9f0cf5dce62e750681c867304153570" category="list-text">를 참조하십시오 <block ref="2ce06b74e1489f63ffccf27e38243dd4" category="inline-link-macro-rx"></block> Ansible, Python 및 기타 추가 Python 패키지의 설치 버전을 비롯한 BeeGFS HA 역할의 경우</block>
  <block id="5f4740da5b8ab13112ebf332f879cc6e" category="list-text">공무원도 만나세요 <block ref="37e11d19f014e84f10fff4770a09b235" category="inline-link-macro-rx"></block> 운영 체제 버전을 포함합니다.</block>
  <block id="2bce5080fcc3d6b8a54a49745dd28d52" category="list-text">모든 파일 및 블록 노드에 대한 SSH 및 HTTPS 액세스 권한 보유</block>
  <block id="63115803566871887df2b7864b03edba" category="paragraph">자세한 설치 단계를 찾을 수 있습니다 <block ref="84ce541b3fd5c60f6335f3a2ccb7ca82" category="inline-link-macro-rx"></block>.</block>
  <block id="9635e0061cd355a35e70799e909727af" category="summary">Ansible을 실행하기 전에 파일 및 블록 노드를 설정하는 데 필요한 수동 단계</block>
  <block id="f5878e619c266b2ac6254dd1e4d95bfb" category="doc">파일 및 블록 노드 설정</block>
  <block id="d3f9f418681aaa08eb617366f4e167e0" category="section-title">베이스보드 관리 컨트롤러(BMC) 구성</block>
  <block id="d387b972fad59cf81f9a534bd8f6c654" category="paragraph">서비스 프로세서라고도 하는 베이스보드 관리 컨트롤러(BMC)는 다양한 서버 플랫폼에 내장되어 운영 체제가 설치되어 있지 않거나 액세스할 수 없는 경우에도 원격 액세스를 제공할 수 있는 대역외 관리 기능의 일반 이름입니다. 공급업체는 일반적으로 고유한 브랜딩으로 이 기능을 마케팅합니다. 예를 들어, Lenovo SR665에서 BMC는 Lenovo XClarity Controller(XCC)라고 합니다.</block>
  <block id="9f9fca437c1db2135d8b5e17bdc36ff6" category="paragraph">서버 공급업체의 설명서에 따라 이 기능에 액세스하는 데 필요한 모든 라이센스를 활성화하고 BMC가 네트워크에 연결되고 원격 액세스에 맞게 구성되었는지 확인합니다.</block>
  <block id="d4519b3f996eace0908217fda1966da8" category="admonition">Redfish를 사용하여 BMC 기반 펜싱을 사용하려면 Redfish가 활성화되어 있고 파일 노드에 설치된 OS에서 BMC 인터페이스에 액세스할 수 있어야 합니다. BMC와 운영 체제가 동일한 물리적 네트워크 인터페이스를 공유하는 경우 네트워크 스위치에 특별한 구성이 필요할 수 있습니다.</block>
  <block id="f9fa015b01242f44a7319213f0a01ff2" category="section-title">시스템 설정을 조정합니다</block>
  <block id="93f3e5d94e30643aac7f8755a6dcfeb4" category="inline-link-macro">파일 노드 모델을 확인했습니다</block>
  <block id="eb1a924be6e65601b1d6529fe8917db5" category="paragraph">시스템 설정(BIOS/UEFI) 인터페이스를 사용하여 성능을 최대화하도록 설정이 설정되어 있는지 확인합니다. 정확한 설정과 최적의 값은 사용 중인 서버 모델에 따라 달라집니다. 에 대한 지침이 제공됩니다 <block ref="7b8ecd3bdebb7b3647e8c8482129e950" category="inline-link-macro-rx"></block>, 그렇지 않으면 해당 모델에 따라 서버 공급업체의 설명서 및 모범 사례를 참조하십시오.</block>
  <block id="b9a7b8c50025e62b9e91f9baf3ba2304" category="section-title">운영 체제를 설치합니다</block>
  <block id="9c116e10343ac4205ebd3cb830c40df8" category="paragraph">나열된 파일 노드 요구 사항에 따라 지원되는 운영 체제를 설치합니다 <block ref="e53a200e1bdbb9fa297205d4a1608879" category="inline-link-macro-rx"></block>. Linux 배포판에 따라 아래의 추가 단계를 참조하십시오.</block>
  <block id="a82007c47b25723539a00ff94e8b3d27" category="section-title">RedHat</block>
  <block id="5ab261ccc77c613b4430d72688133ef7" category="paragraph">RedHat 서브스크립션 관리자를 사용하여 시스템을 등록 및 구독하여 공식 Red Hat 리포지토리에서 필요한 패키지를 설치하고 지원되는 Red Hat 버전으로 업데이트를 제한할 수 있습니다.<block ref="77a4421cc9f01b777ceaeda595865c3c" prefix=" " category="inline-code"></block>. 자세한 내용은 을 참조하십시오<block ref="2e2e1be81972e19947d90393d5319b6e" category="inline-link-rx"></block> 및 <block ref="bbd834e2960f33a50fb102fd4d31a6d9" category="inline-link-rx"></block>.</block>
  <block id="9a7877d2d6f43233661b52c31362cb32" category="paragraph">고가용성을 위해 필요한 패키지가 포함된 Red Hat 리포지토리를 활성화합니다.</block>
  <block id="5ea84babe2cd259121a70aff2652769b" category="section-title">관리 네트워크를 구성합니다</block>
  <block id="45f7cb03ff15b64d9405b68be6bdcc97" category="paragraph">운영 체제의 대역 내 관리를 허용하는 데 필요한 네트워크 인터페이스를 구성합니다. 정확한 단계는 사용 중인 특정 Linux 배포 및 버전에 따라 다릅니다.</block>
  <block id="6c2e3de482271e18e34375218bcbbfcd" category="admonition">SSH가 활성화되어 있고 Ansible 제어 노드에서 모든 관리 인터페이스에 액세스할 수 있는지 확인합니다.</block>
  <block id="ab2b3440ca9e61bb50d98cdd593fea31" category="section-title">HCA 및 HBA 펌웨어를 업데이트합니다</block>
  <block id="6f1e172b7de497aa7887fcbcb7ee6023" category="paragraph">모든 HBA 및 HCA가 에 나열된 지원되는 펌웨어 버전을 실행하고 있는지 확인합니다 <block ref="8b59326e9a63a3b8d68c843e238b964b" category="inline-link-macro-rx"></block> 필요한 경우 업그레이드합니다. NVIDIA ConnectX 어댑터에 대한 추가 권장 사항을 찾을 수 있습니다 <block ref="e53a200e1bdbb9fa297205d4a1608879" category="inline-link-macro-rx"></block>.</block>
  <block id="48206a73aaea76911a94b52a97986f4a" category="section-title">블록 노드</block>
  <block id="76752be68c87426437dc7d4a501b481c" category="inline-link-macro">E-Series와 함께 가동 및 운영합니다</block>
  <block id="871d3d62a8d11ed96c7c911ca5961c83" category="paragraph">의 단계를 따릅니다 <block ref="4525dc880e156901740411dc7fd56b26" category="inline-link-macro-rx"></block> 각 블록 노드 컨트롤러에서 관리 포트를 구성하고 선택적으로 각 시스템의 스토리지 어레이 이름을 설정합니다.</block>
  <block id="20c7fe47a0acb373f79e663a36dd1e25" category="admonition">Ansible 제어 노드에서 모든 블록 노드에 액세스할 수 있도록 보장하는 추가 구성은 필요하지 않습니다. 나머지 시스템 구성은 Ansible을 사용하여 적용/유지합니다.</block>
  <block id="40df644de3579bec4038eafb77eb26fe" category="summary">선택적으로 Ansible을 사용하여 BeeGFS 클라이언트를 구성하고 파일 시스템을 마운트할 수 있습니다.</block>
  <block id="107dafc3c3dfc88c15a7700fd40a35dc" category="doc">BeeGFS 클라이언트를 구축합니다</block>
  <block id="fc9048a17c6ddc968465bcc02c0ea486" category="inline-link-macro">Ansible 역할</block>
  <block id="dcce328dbfa187984479bbc5ace17bf2" category="paragraph">BeeGFS 파일 시스템을 액세스하려면 파일 시스템을 마운트해야 하는 각 노드에서 BeeGFS 클라이언트를 설치 및 구성해야 합니다. 이 섹션에서는 사용 가능한 를 사용하여 이러한 작업을 수행하는 방법을 설명합니다 <block ref="0ceebef54e9df7cedfb22dd6dcf5ed37" category="inline-link-macro-rx"></block>.</block>
  <block id="2106244b87f596d4fefd89f77dae13da" category="section-title">클라이언트 인벤토리 파일을 생성합니다</block>
  <block id="7dc2ac40c1549980b4ac09d940856f47" category="list-text">아래에서<block ref="4d729f58293c8a48f1f8d918cdd1d28f" prefix=" " category="inline-code"></block>에서 각 BeeGFS 클라이언트에 대한 파일을 생성합니다<block ref="a0253f5b8f5dd7be8b02cda13da40729" prefix=" " category="inline-code"></block> 다음 콘텐츠를 사용하여 환경에 맞는 올바른 정보로 자리 표시자 텍스트를 입력합니다.</block>
  <block id="689b0940ce8c21b1ecd3dafd9cc19d56" category="list-text">선택적으로 NetApp E-Series 호스트 컬렉션의 역할을 사용하여 클라이언트가 BeeGFS 파일 노드에 연결할 수 있도록 InfiniBand 또는 이더넷 인터페이스를 구성하려면 다음 중 하나를 포함합니다.</block>
  <block id="825f3be2c17c36c0e4901143db982773" category="list-text">새 파일을 만듭니다<block ref="c28f9364916e661fea858844d2b96b81" prefix=" " category="inline-code"></block> 그리고 Ansible이 각 클라이언트에 연결하는 데 사용해야 하는 사용자 지정과 Ansible이 권한 에스컬레이션을 위해 사용해야 하는 암호(이 경우 필요)를 지정합니다<block ref="f2bf771afbc16045e1951ded58c56f98" prefix=" " category="inline-code"></block> 루트 또는 sudo 권한 보유):</block>
  <block id="c5a4ae1aa23001e8780b413f175b50b3" category="admonition">암호를 일반 텍스트로 저장하지 마십시오. 대신 Ansible Vault를 사용하십시오(참조 <block ref="f2e33a881c3eb75b68333af99119c0b8" category="inline-link-macro-rx"></block> Ansible Vault로 콘텐츠 암호화)를 사용하거나 을 사용합니다<block ref="13d87b4892426ec19bdc58a4643d3104" prefix=" " category="inline-code"></block> 옵션을 클릭합니다.</block>
  <block id="848f64fc57104cb2b416f6102d34e699" category="list-text">에 있습니다<block ref="c28f9364916e661fea858844d2b96b81" prefix=" " category="inline-code"></block> File(파일): 에 BeeGFS 클라이언트로 구성해야 하는 모든 호스트를 나열합니다<block ref="fc2e11772a55c48ed2b4ec7bc5d94664" prefix=" " category="inline-code"></block> 그룹화한 다음 인라인 주석을 참조하여 시스템에서 BeeGFS 클라이언트 커널 모듈을 구축하는 데 필요한 추가 구성을 제거합니다.</block>
  <block id="743c079a390bacd58f1ec66c241c688e" category="admonition">Mellanox OFED 드라이버를 사용할 때 Beegfs_client_OFED_Include_path가 Linux 설치를 위한 올바른 "헤더 포함 경로"를 가리키는지 확인하십시오. 자세한 내용은 의 BeeGFS 설명서를 참조하십시오 <block ref="a36a0245ff208157cbdf93cd51fc1311" category="inline-link-macro-rx"></block>.</block>
  <block id="c378775497a55638adcb42719d8daddb" category="list-text">에 있습니다<block ref="c28f9364916e661fea858844d2b96b81" prefix=" " category="inline-code"></block> 파일, 이전에 정의한 모든 파일 아래에 마운트할 BeeGFS 파일 시스템을 나열합니다<block ref="b63119da730344b345cdc8f62a4711e9" prefix=" " category="inline-code"></block>:</block>
  <block id="508ccac845ca75d6cdda20dfa455a2bd" category="inline-link-macro">공통 파일 노드 구성</block>
  <block id="eeaa045faacfe7ac3ff3c860c9ddb470" category="list-text">BeeGFS 7.2.7 및 7.3.1 <block ref="770c4b58b3b364c4ac52cf5cc555453f" category="inline-link-macro-rx"></block> 구성 또는 명시적으로 비활성화해야 합니다. 를 지정할 때 연결 기반 인증을 구성하는 방법에 따라 다릅니다 <block ref="24f8b4d23bbf0a3339e16ecc2414c31b" category="inline-link-macro-rx"></block>클라이언트 구성을 조정해야 할 수 있습니다.</block>
  <block id="a7d7def0ef1d6627e10199d423565e7e" category="list-text">기본적으로 HA 클러스터 배포는 연결 인증을 자동으로 구성하고 를 생성합니다<block ref="cd304377fdc20285a5aa94e55ae85aa7" prefix=" " category="inline-code"></block> 이 정보는 에서 Ansible 제어 노드에 배치/유지됩니다<block ref="eee2923df30539b680421ca53d7c066b" prefix=" " category="inline-code"></block>. 기본적으로 BeeGFS 클라이언트 역할은 에 정의된 클라이언트에 이 파일을 읽고 배포하도록 설정되어 있습니다<block ref="c28f9364916e661fea858844d2b96b81" prefix=" " category="inline-code"></block>추가 조치가 필요하지 않습니다.</block>
  <block id="2c96dc448de9d0218bb361afae4689c8" category="inline-link-macro">BeeGFS 클라이언트 역할입니다</block>
  <block id="cb7223c9ecb20da5826418267937cb4b" category="list-text">고급 옵션은 에 포함된 기본값 전체 목록을 참조하십시오 <block ref="1507a901cf67edf9930d46c852b1993d" category="inline-link-macro-rx"></block>.</block>
  <block id="f4c29fbb6bcbcc6c55ae76c0a5254687" category="list-text">을 사용하여 사용자 지정 암호를 지정하도록 선택한 경우<block ref="8b76cf2fb65e09dad03ca686be5cd464" prefix=" " category="inline-code"></block> 에서 지정합니다<block ref="c28f9364916e661fea858844d2b96b81" prefix=" " category="inline-code"></block> 파일 또한:</block>
  <block id="2f01d79351dcc30d05b4a5a46dee42df" category="list-text">을 사용하여 연결 기반 인증을 완전히 사용하지 않도록 선택하는 경우<block ref="6c8dd8672ca377e74101ad236282225a" prefix=" " category="inline-code"></block>에서 를 지정합니다<block ref="c28f9364916e661fea858844d2b96b81" prefix=" " category="inline-code"></block> 파일 또한:</block>
  <block id="4debabcfd87e8aaf710a4ef0b5fc0fbc" category="inline-link-macro">전체 BeeGFS 클라이언트 문서</block>
  <block id="be564dd8130b7faafb95d140037162bb" category="paragraph">지원되는 매개 변수의 전체 목록과 추가 세부 정보는 를 참조하십시오 <block ref="28ce7a1eece2b507c973d3cca2a82121" category="inline-link-macro-rx"></block>. 클라이언트 인벤토리의 전체 예제를 보려면 을 클릭합니다 <block ref="b0d51f66522ad4d9697fdf435a95c97a" category="inline-link-macro-rx"></block>.</block>
  <block id="da7e04a55b40629ae3a62baa9635b36d" category="section-title">BeeGFS Client Playbook File을 생성합니다</block>
  <block id="964a26fa475bbef370601a9a9fb613cb" category="list-text">새 파일을 만듭니다<block ref="34bd6e27c43e6508a64d0a1bf093c7d2" prefix=" " category="inline-code"></block></block>
  <block id="ac25f4ce0e4e52459d58c2db4ebda280" category="list-text">선택 사항: NetApp E-Series Host Collection의 역할을 사용하여 클라이언트가 BeeGFS 파일 시스템에 연결할 수 있도록 인터페이스를 구성하려면 구성 중인 인터페이스 유형에 해당하는 역할을 가져옵니다.</block>
  <block id="9f7ee0cead06efb0babbaca7b021e3ed" category="list-text">InfiniBand(IPoIB)를 사용하는 경우:</block>
  <block id="54b431528476178eb45a6c2570eff415" category="list-text">RoCE(RDMA over Converged Ethernet)를 사용 중인 경우:</block>
  <block id="ea7cb942473ffddb52c2661da2f3b951" category="list-text">를 사용 중인 경우 이더넷(TCP 전용, RDMA 없음)을 사용합니다.</block>
  <block id="975fc05779caaf583c3a8ab6b5c5adf1" category="list-text">마지막으로 BeeGFS 클라이언트 역할을 가져와 클라이언트 소프트웨어를 설치하고 파일 시스템 마운트를 설정합니다.</block>
  <block id="02870b17064b23fcbf2e080b9624fd6d" category="paragraph">클라이언트 플레이북의 전체 예제를 보려면 을 클릭합니다 <block ref="dee50bfc7f141fd7ad52d525c94ac7f5" category="inline-link-macro-rx"></block>.</block>
  <block id="354895762186e608f5675b1498c26501" category="section-title">BeeGFS Client Playbook을 실행합니다</block>
  <block id="831a82eacd2203b1049bc6c01826fbef" category="paragraph">클라이언트를 설치/구축하고 BeeGFS를 마운트하려면 다음 명령을 실행합니다.</block>
  <block id="31a21a1e42c30056168ee5a4cca695a9" category="summary">Playbook을 사용하여 BeeGFS HA 클러스터를 구축하기 위해 실행해야 할 작업을 지정합니다.</block>
  <block id="aca5a5a6b413ed0913ad90f87766df63" category="paragraph">이 섹션에서는 NetApp에서 BeeGFS를 구축/관리하는 데 사용되는 표준 플레이북을 취합하는 방법에 대해 설명합니다.</block>
  <block id="b3254ab5c14c4bb06dbb987f8ee20900" category="section-title">Ansible 플레이북을 작성합니다</block>
  <block id="dc1e1a7b77e4fce07756f071e5ec7d8b" category="paragraph">파일을 만듭니다<block ref="2f78c4e27feaf25ffb33d97e8ff7e7a6" prefix=" " category="inline-code"></block> 다음과 같이 채웁니다.</block>
  <block id="a3b34c0871dc2fd51eec5559b68f709d" category="inline-link-macro">재생</block>
  <block id="3b4e65c5ca327e9a010b0e69fb90e476" category="list-text">먼저 작업 집합(일반적으로 라고 함)을 정의합니다 <block ref="6d76655a02e5cb4ca885a92d78a5ab31" category="inline-link-macro-rx"></block>) NetApp E-Series 블록 노드에서만 실행되어야 합니다. 일시 중지 작업을 사용하여 설치를 실행하기 전에 메시지를 표시한 다음(우발적인 플레이북 실행을 피하기 위해) 을(를) 가져옵니다<block ref="504ead1cde99fc3bc223588114102919" prefix=" " category="inline-code"></block> 역할. 이 역할은 에 정의된 모든 일반 시스템 구성을 적용하는 작업을 처리합니다<block ref="7bc866ffde9914c7ef21768fcf6f0683" prefix=" " category="inline-code"></block> 있습니다<block ref="7011fddbea4410953d6718ccf9ef966a" prefix=" " category="inline-code"></block> 파일.</block>
  <block id="19c06a0dc65b61c783f73d77e193957e" category="list-text">모든 파일 및 블록 노드에 대해 실행할 플레이를 정의합니다.</block>
  <block id="25296aae8975fe74b18a42af79a293d3" category="list-text">이 플레이에서는 HA 클러스터를 구축하기 전에 실행해야 하는 "사전 작업" 세트를 선택적으로 정의할 수 있습니다. Python과 같은 필수 구성 요소를 확인/설치하는 데 유용할 수 있습니다. 제공된 Ansible 태그가 지원되는지 확인하는 등 비행 전 점검을 삽입할 수도 있습니다.</block>
  <block id="adcd434b091e5725531891ba91d50193" category="list-text">마지막으로, 이 플레이는 구축할 BeeGFS 버전에 대한 BeeGFS HA 역할을 가져옵니다.</block>
  <block id="d1b15e5b42308e0128908c431c40f477" category="inline-link-macro">업그레이드 가이드</block>
  <block id="7e10b750e783312f0439de308f7b7f5d" category="admonition">지원되는 각 주요 버전 BeeGFS에 대해 BeeGFS HA 역할이 유지됩니다. 따라서 사용자는 주/부 버전을 업그레이드할 시기를 선택할 수 있습니다. 현재 BeeGFS 7.3.x입니다 <block ref="b8974e83e3e52aff89dd9fef2fd40433" prefix="(" category="inline-code"></block>) 또는 BeeGFS 7.2.x <block ref="a89433e176d102073aaa272a94fc99a0" prefix="(" category="inline-code"></block>)가 지원됩니다. 기본적으로 두 역할 모두 릴리즈 시점에 최신 BeeGFS 패치 버전을 구축합니다. 하지만 사용자가 원할 경우 이를 무시하고 최신 패치를 배포할 수 있습니다. 최신 을 참조하십시오 <block ref="55cf38a4d7e02b8bb50d2f2516e38095" category="inline-link-macro-rx"></block> 를 참조하십시오.</block>
  <block id="cf0e39575a3cd74789827d1f8d28bcb0" category="list-text">선택 사항: 추가 작업을 정의하려면 작업이 에 지정되어야 하는지 여부를 염두에 두십시오<block ref="a181a603769c1f98ad927e7367c7aa51" prefix=" " category="inline-code"></block> 호스트(E-Series 스토리지 시스템 포함) 또는 파일 노드만 포함됩니다. 필요한 경우 를 사용하여 파일 노드를 대상으로 하는 새로운 플레이를 정의합니다<block ref="0c748da7ba6880eb7537e471415afd58" prefix=" " category="inline-code"></block>.</block>
  <block id="abd8b7e36cb7499818727f42837b0025" category="paragraph">을 클릭합니다 <block ref="01ba4d718d4b882a06a17b3dab000fe7" category="inline-link-macro-rx"></block> 전체 플레이북 파일의 예</block>
  <block id="c6def9892d45d8f594a1141d759cff35" category="section-title">NetApp Ansible Collections를 설치합니다</block>
  <block id="f996e211f2d82b62da74abbaa175d7bc" category="paragraph">Ansible용 BeeGFS 컬렉션 및 모든 종속 항목이 에 유지됩니다 <block ref="d8617fd1dfbd628e2360b843d6070e54" category="inline-link-macro-rx"></block>. Ansible 제어 노드에서 다음 명령을 실행하여 최신 버전을 설치합니다.</block>
  <block id="9a603171be277ec1f9319dc83b272723" category="paragraph">일반적으로 권장하지는 않지만 컬렉션의 특정 버전을 설치할 수도 있습니다.</block>
  <block id="cb5da77fc5fc3c2fdb8aeff46789a9ca" category="section-title">Playbook을 실행합니다</block>
  <block id="440d2c1c46f7c70d35f630781d07e912" category="paragraph">이 포함된 Ansible 제어 노드의 디렉토리에서<block ref="d28e452e49fc926f32af1d87afcff3ce" prefix=" " category="inline-code"></block> 및<block ref="2f78c4e27feaf25ffb33d97e8ff7e7a6" prefix=" " category="inline-code"></block> 파일을 실행하고 다음과 같이 플레이북을 실행합니다.</block>
  <block id="b7a14d8dfd866e91a40ba8804324679a" category="paragraph">클러스터의 크기에 따라 초기 구축에는 20분 이상 걸릴 수 있습니다. 어떠한 이유로든 구축에 실패하는 경우, 잘못된 케이블 연결, 노드 시작 등 문제를 해결하고 Ansible 플레이북을 다시 시작하십시오.</block>
  <block id="bdc9f2542f62454c22369d7525b55e74" category="paragraph">지정할 때 <block ref="24f8b4d23bbf0a3339e16ecc2414c31b" category="inline-link-macro-rx"></block>기본 옵션을 선택하여 Ansible에서 연결 기반 인증을 자동으로 관리하도록 할 경우, a<block ref="6097b6e95af2579f2147a330c21f7b59" prefix=" " category="inline-code"></block> 공유 비밀로 사용되는 은 에서 확인할 수 있습니다<block ref="8e9df790452dc085676f10b7754aa94b" prefix=" " category="inline-code"></block> (기본값). 파일 시스템에 액세스해야 하는 모든 클라이언트는 이 공유 암호를 사용해야 합니다. 이 작업은 클라이언트가 를 사용하여 구성된 경우 자동으로 처리됩니다 <block ref="a21671c2fbc0de7b779bee85584513db" category="inline-link-macro-rx"></block>.</block>
  <block id="86cd3363bcd965ea6807e544cdb56311" category="summary">시스템을 운영 환경에 배치하기 전에 파일 시스템 구축을 확인하십시오.</block>
  <block id="0c947320dda2aecdd9ad8baca329d8a9" category="doc">BeeGFS 구축을 확인합니다</block>
  <block id="9f4d5d32220ec3141c624637c9a8b89f" category="paragraph">BeeGFS 파일 시스템을 운영 환경에 배치하기 전에 몇 가지 검증 검사를 수행하십시오.</block>
  <block id="09b37befd9a82a1583041aaff8b9a03a" category="list-text">모든 클라이언트에 로그인하고 다음을 실행하여 모든 예상 노드가 존재하고 연결 가능한지, 불일치 또는 보고된 다른 문제가 없는지 확인합니다.</block>
  <block id="a1729ed32ceab91f7ef692e7af48a6b8" category="list-text">전체 클러스터를 종료한 다음 재시작합니다. 모든 파일 노드에서 다음을 실행합니다.</block>
  <block id="989e28705c44d76a13ea323790377850" category="list-text">각 노드를 스탠바이에 배치하고 BeeGFS 서비스가 보조 노드로 페일오버할 수 있는지 확인합니다. 이 작업을 수행하려면 파일 노드에 로그인하고 다음을 실행합니다.</block>
  <block id="ba2b2e2a9229fbcedccdb09d825096ee" category="inline-link-macro">설계 Verification</block>
  <block id="3c8e1266f80cdbaf6dd8600cff74e6a5" category="list-text">IOR 및 MDTest와 같은 성능 벤치마킹 툴을 사용하여 파일 시스템 성능이 기대에 부합하는지 확인합니다. BeeGFS에 사용되는 일반적인 테스트 및 매개 변수의 예는 에서 찾을 수 있습니다 <block ref="0ec650ae704c14f404555ee540b16de5" category="inline-link-macro-rx"></block> 섹션: NetApp 검증 아키텍처의 BeeGFS</block>
  <block id="fdb55059a4337ca76c138af7ad303efa" category="paragraph">특정 현장/설치에 대해 정의된 수용 기준에 따라 추가 테스트를 수행해야 합니다.</block>
  <block id="71a6b27b610785178635f3c7fea0dc9c" category="summary">Ansible을 사용하여 BeeGFS HA 클러스터 구축 및 관리</block>
  <block id="03d8a35d2c337d83e9a0c791c0bde873" category="doc">Ansible 플레이북 개요</block>
  <block id="dd3429f2a44e55e208032b591c258877" category="paragraph">이전 섹션에서는 BeeGFS HA 클러스터를 나타내는 Ansible 재고를 구축하는 데 필요한 단계를 안내했습니다. 이 섹션에서는 클러스터를 구축 및 관리하기 위해 NetApp에서 개발한 Ansible 자동화를 소개합니다.</block>
  <block id="531369b10b19be4aa811f6b1b1abfc32" category="section-title">Ansible: 주요 개념</block>
  <block id="c4c6df2bdb8451df5f63cc2602cd3266" category="paragraph">진행하기 전에 Ansible의 몇 가지 주요 개념을 숙지하는 것이 좋습니다.</block>
  <block id="0a4d7a775f170dc43fae102dc8eed0f1" category="list-text">Ansible 인벤토리에 대해 실행할 작업은 * 플레이북 * 으로 알려진 내용에 정의됩니다.</block>
  <block id="503c50788505311e2737ca28bcfc6d1b" category="list-text">Ansible에서 수행하는 대부분의 작업은 * idemtiple * 으로 설계되어 여러 번 실행할 수 있으므로, 원하는 구성/상태가 중단 없이 적용되었는지, 불필요한 업데이트를 하지 않고 그대로 적용되는지를 확인할 수 있습니다.</block>
  <block id="fb3edd793b0a4233a87fc2742a893d8d" category="list-text">Ansible에서 실행할 수 있는 가장 작은 단위는 * 모듈 * 입니다.</block>
  <block id="d30cef0e8eb4eaf16c7181329c0d06bd" category="list-text">일반적인 플레이북에서는 여러 모듈을 사용합니다.</block>
  <block id="424107bb38bc62e70c34a281a355ca1d" category="list-text">예: 패키지 다운로드, 구성 파일 업데이트, 서비스 시작/활성화</block>
  <block id="b34cf1156d6d4fc5d2020447509756c9" category="list-text">NetApp은 모듈을 분산하여 NetApp E-Series 시스템을 자동화합니다.</block>
  <block id="a5a68481f09270734c66ad9ff1dcd0af" category="list-text">복잡한 자동화는 하나의 역할로 더 잘 패키징됩니다.</block>
  <block id="4eac750d0b9763378029ed193c50648c" category="list-text">기본적으로 재사용 가능한 플레이북을 배포하기 위한 표준 형식입니다.</block>
  <block id="caa4d8cd3e05670bd54bb0281f679498" category="list-text">NetApp은 Linux 호스트 및 BeeGFS 파일 시스템에 대한 역할을 분산합니다.</block>
  <block id="1aa532e3c0c6ac72094492dd5d4ad8fa" category="section-title">Ansible용 BeeGFS HA 역할: 주요 개념</block>
  <block id="8313d0dcd5307c834d7d37f194d4ea32" category="inline-link-macro">BeeGFS용 NetApp E-Series Ansible 컬렉션</block>
  <block id="8694b9bbf06f92b8fb6a129f90967b56" category="paragraph">NetApp에서 각 버전의 BeeGFS를 구축 및 관리하는 데 필요한 모든 자동화 기능이 Ansible 역할로 패키지되어 의 일부로 배포됩니다 <block ref="0d95f34d028d609c5e44d4c47f78ca03" category="inline-link-macro-rx"></block>:</block>
  <block id="e14542ae9d29391a92cc14f6b44e67fd" category="list-text">이 역할은 * 설치 프로그램 * 과 BeeGFS용 최신 * 구축/관리 * 엔진 사이의 어딘가에 있다고 생각할 수 있습니다.</block>
  <block id="3bcab18a67a5ea90f159f8f472ab0f9d" category="list-text">최신 인프라를 코드 사례 및 철학으로 적용하여 모든 규모의 스토리지 인프라 관리를 단순화합니다.</block>
  <block id="82877b38f579bedd3acfc034e6aa2a8e" category="inline-link-macro">구베기도</block>
  <block id="ec0d4c87ba519deb5bdc3bec080e5fc1" category="list-text">와 유사합니다 <block ref="e56eacf8ed0ebfb267e63f1ff54fa855" category="inline-link-macro-rx"></block> Project에서는 전체 Kubernetes 배포를 구축/유지 관리하여 컴퓨팅 인프라를 확장할 수 있습니다.</block>
  <block id="34681b6b5fc6e725199f30a154956754" category="list-text">NetApp에서 NetApp 솔루션에서 BeeGFS를 패키징, 배포 및 유지 관리하는 데 사용하는 * 소프트웨어 정의 * 형식입니다.</block>
  <block id="3c359db1a2bcb271a8a28e3381057655" category="list-text">전체 Linux 배포판이나 큰 이미지를 배포할 필요 없이 "어플라이언스와 유사한" 환경을 조성하기 위해 노력합니다.</block>
  <block id="ebc3365fe74d7c659b1f0298995f6d39" category="list-text">지능형 Pacemaker/BeeGFS 통합을 제공하는 맞춤형 BeeGFS 타겟, IP 주소, 모니터링을 위해 NetApp에서 작성한 OCF(Open Cluster Framework) 규격 클러스터 리소스 에이전트가 포함되어 있습니다.</block>
  <block id="8af5165ce6aabae36357e63702ba3fbf" category="list-text">이 역할은 단순히 "자동화"를 구축하는 것이 아니라 다음을 포함한 전체 파일 시스템 수명주기를 관리하는 데 사용됩니다.</block>
  <block id="444e2df3560fe0281204fd385d895403" category="list-text">서비스별 또는 클러스터 전체 구성 변경 및 업데이트 적용</block>
  <block id="61ef90c42824e8e8c92d69c04046a94b" category="list-text">하드웨어 문제가 해결된 후 클러스터 복구 및 복구 자동화</block>
  <block id="bb8450666975061db9804d65dbb5afbf" category="list-text">BeeGFS 및 NetApp 볼륨을 사용한 광범위한 테스트 결과를 기준으로 설정된 기본값으로 성능 조정을 단순화합니다.</block>
  <block id="fded9f625af9335e3b78e65d6fd6abac" category="list-text">구성 드리프트 확인 및 수정</block>
  <block id="16a4e0aca277107b3401d2d33d4e5c00" category="inline-link-macro">BeeGFS 클라이언트</block>
  <block id="1c82d73e983ef595a7c60ff4647716a7" category="paragraph">NetApp은 또한 Ansible 역할을 제공합니다 <block ref="b6cde77df9fbd5f549a35216e2ea351f" category="inline-link-macro-rx"></block>필요에 따라 BeeGFS를 설치하고 파일 시스템을 컴퓨팅/GPU/로그인 노드에 마운트하는 데 사용할 수 있습니다.</block>
  <block id="33abf34a1ac99d306f38ad532ed75170" category="inline-link-macro">사용 설명서</block>
  <block id="15c6822a2ade4cd67d3e96c043806b65" category="paragraph">이 업데이트는 권장 펌웨어를 번들로 제공하는 mlxup 도구 버전을 다운로드하여 실행하면 됩니다. 이 도구는 에서 다운로드할 수 있습니다<block ref="d22fd7ba0031fc3b862dce4cf129cfa5" category="inline-link-rx"></block> (<block ref="841da9e9d7f929a00ebef7288ee21ef7" category="inline-link-macro-rx"></block>)를 클릭합니다.</block>
  <block id="55f7d3580cdac035324d4348b9dac05b" category="inline-link-macro">BeeGFS 클러스터 관리</block>
  <block id="0d06184de569870cd5818ae2e6c4a6ac" category="admonition">를 참조하십시오 <block ref="0671020dd7d3d7a323a3eef6d8b61659" category="inline-link-macro-rx"></block> BeeGFS HA(고가용성) 클러스터와의 상호 작용과 관련된 용어 및 개념에 대한 자세한 내용은 섹션을 참조하십시오.</block>
  <block id="3e3cee1fd1e1de5762df25400f62794a" category="paragraph">파일 시스템을 사용해야 하는 애플리케이션을 실행하는 HPC 클러스터의 노드 컴퓨팅 또는 GPU 노드라고도 합니다.</block>
  <block id="67d6c06d21e47a4c86e1be15e327370e" category="paragraph">스토리지 네트워크/클라이언트 네트워크</block>
  <block id="7829f14ded222e6be0bb1a1d28e8f977" category="paragraph">클라이언트가 BeeGFS 파일 시스템과 통신하는 데 사용되는 네트워크입니다. 이 네트워크는 종종 병렬 MPI(Message Passing Interface)와 HPC 클러스터 노드 간의 기타 응용 프로그램 통신에 사용되는 동일한 네트워크입니다.</block>
  <block id="d02afad2b9d23614832a35187b8296bf" category="summary">이 사이트에서는 NetApp에서 BeeGFS를 구축 및 관리하는 방법에 대해 설명합니다.</block>
  <block id="f3ea919081d7ce9021ea4cd631632407" category="paragraph">이 사이트에서는 NetApp NVA(Verified Architecture)와 맞춤형 아키텍처를 모두 사용하여 NetApp에서 BeeGFS를 구축 및 관리하는 방법을 설명합니다. NVA 설계는 철저한 테스트를 거쳐 고객에게 구축 위험을 최소화하고 시장 출시 기간을 단축할 수 있는 참조 구성 및 사이징 지침을 제공합니다. 또한 NetApp에서는 NetApp 하드웨어에서 실행되는 맞춤형 BeeGFS 아키텍처를 지원하므로 고객과 파트너가 다양한 요구사항에 맞춰 파일 시스템을 유연하게 설계할 수 있습니다. 두 접근 방식 모두 Ansible을 구축하여 다양한 하드웨어에서 모든 규모의 BeeGFS를 관리하는 어플라이언스 방식의 접근 방식을 제공합니다.</block>
  <block id="2146c9256a2a3883605731032b6b8015" category="sidebar">검증된 아키텍처를 사용합니다</block>
  <block id="2c9d17683bf440abca82add607aa6a61" category="sidebar">초기 설정</block>
  <block id="2186112c2fe23afc42ab96c76b10633c" category="sidebar">하드웨어를 설치하고 케이블을 연결합니다</block>
  <block id="d2c71dbf224d233986fd9fee484a1bff" category="sidebar">BeeGFS 파일 시스템을 정의합니다</block>
  <block id="d2b9bae490422ee64c78a0825f1c1d47" category="sidebar">파일 및 블록 노드 정의</block>
  <block id="e0f1083c7a219d40d5f2cce31e733837" category="sidebar">개별 파일 노드를 구성합니다</block>
  <block id="aaadb61f664f163c98ebee0c9c962dda" category="sidebar">개별 블록 노드를 구성합니다</block>
  <block id="2c6acfbd0549df84a730e9135dfa642a" category="sidebar">공통 파일 노드 구성을 지정합니다</block>
  <block id="de1a5ef51d1a1d949b60789be3110709" category="sidebar">공통 블록 노드 구성을 지정합니다</block>
  <block id="8283d5b2387e743d14bda00c2176d402" category="sidebar">BeeGFS 서비스를 정의합니다</block>
  <block id="4ea9c51458de5a50fcfc6ed1d6731376" category="sidebar">BeeGFS 관리 서비스</block>
  <block id="fc0c3d42b552d41c96b314b10a5d8322" category="sidebar">BeeGFS 메타데이터 서비스입니다</block>
  <block id="941fb85375314e8f03181252062f8321" category="sidebar">BeeGFS 스토리지 서비스입니다</block>
  <block id="67f0f9eb53d18fde2907a79ffc52ab62" category="sidebar">BeeGFS 파일 시스템을 구축합니다</block>
  <block id="7d980eb0cd911c4219870701e3c4ffce" category="sidebar">BeeGFS 클러스터 관리</block>
  <block id="58f82a4575a638ca0eba992df08c4d2b" category="sidebar">Ansible과 PC를 사용해야 하는 경우</block>
  <block id="28ee8cbd43fb9f7530f5ac7d2afa73c8" category="sidebar">재구성 및 업데이트</block>
  <block id="bbfb06821b506d64fdaee613711657d4" category="sidebar">서비스 및 유지 관리</block>
  <block id="52009bb7ee17227f566cd26a02caee56" category="inline-link-macro"><block ref="52009bb7ee17227f566cd26a02caee56" category="inline-link-rx"></block></block>
  <block id="a1a9afcf552a769c282769271829889a" category="paragraph"><block ref="a1a9afcf552a769c282769271829889a" category="inline-link-macro-rx"></block></block>
  <block id="f99aa604031e5049799e73b5c3748a98" category="inline-link-macro"><block ref="f99aa604031e5049799e73b5c3748a98" category="inline-link-rx"></block></block>
  <block id="5d545fe5152641e2ebe654e336e520e5" category="paragraph"><block ref="5d545fe5152641e2ebe654e336e520e5" category="inline-link-macro-rx"></block></block>
  <block id="88e5eabd3917048b6927c42496b98f86" category="inline-link-macro"><block ref="88e5eabd3917048b6927c42496b98f86" category="inline-link-rx"></block></block>
  <block id="dd38f906b37d412de7d1c1dcf4cbf31c" category="paragraph"><block ref="dd38f906b37d412de7d1c1dcf4cbf31c" category="inline-link-macro-rx"></block></block>
  <block id="8acb58cbd50ef1b468a020ee0bd351d3" category="inline-link-macro"><block ref="8acb58cbd50ef1b468a020ee0bd351d3" category="inline-link-rx"></block></block>
  <block id="2352c4e1f4d0024ade0869e00e6243f4" category="paragraph"><block ref="2352c4e1f4d0024ade0869e00e6243f4" category="inline-link-macro-rx"></block></block>
</blocks>